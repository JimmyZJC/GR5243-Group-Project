{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GR5243 Group Project\n",
    "##### Xingchen Ji, Yuting Wang, Hongyi Xu, and Jiacan Zhou"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = pd.read_csv(\"../Data/RTA.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Data Cleaning and Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) Handling Missing Data and Invalid Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'Histogram of Accident Severity'),\n",
       " Text(0.5, 0, 'Accident Severity')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eta[\"Accident_severity\"].value_counts()\n",
    "sns.histplot(eta[\"Accident_severity\"]).set(title = \"Histogram of Accident Severity\", xlabel = \"Accident Severity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta.drop([\"Service_year_of_vehicle\", \"Defect_of_vehicle\", \"Work_of_casuality\", \"Fitness_of_casuality\"], axis = 1, inplace = True)\n",
    "eta.drop([\"Time\", \"Weather_conditions\", \"Casualty_class\", \"Sex_of_casualty\", \"Age_band_of_casualty\", \"Casualty_severity\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [col for col in eta.columns]\n",
    "categorical.remove(\"Number_of_vehicles_involved\")\n",
    "categorical.remove(\"Number_of_casualties\")\n",
    "categorical.remove(\"Accident_severity\")\n",
    "numerical = [\"Number_of_vehicles_involved\", \"Number_of_casualties\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta.dropna(subset = categorical, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "eta_fs = eta.copy()\n",
    "eta_fs[numerical] = scaler.fit_transform(eta_fs[numerical])\n",
    "y_cgan = eta_fs[\"Accident_severity\"]\n",
    "y_cgan = pd.get_dummies(y_cgan, columns = [\"Accident_severity\"])\n",
    "y = y_cgan.to_numpy(dtype = np.float32)\n",
    "X_cgan = pd.get_dummies(eta_fs, columns = categorical)\n",
    "X_cgan = X_cgan.drop(\"Accident_severity\", axis = 1)\n",
    "X = X_cgan.to_numpy(dtype = np.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) Data Augmentation by CGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "class NumericalDGenerator(nn.Module):\n",
    "    def __init__(self, noise_dim, label_dim, output_dim, hidden_dim):\n",
    "        super(NumericalDGenerator, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(noise_dim + label_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        x = torch.cat([noise, labels], dim = 1)\n",
    "        return self.layers(x)\n",
    "\n",
    "class CategoricalGenerator(nn.Module):\n",
    "    def __init__(self, noise_dim, label_dim, output_dim, hidden_dim):\n",
    "        super(CategoricalGenerator, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(noise_dim + label_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        x = torch.cat([noise, labels], dim = 1)\n",
    "        return self.layers(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, label_dim, num_output_numerical, num_output_categorical, hidden_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.numerical_gen = NumericalDGenerator(noise_dim, label_dim, num_output_numerical, hidden_dim)\n",
    "        self.categorical_gen = CategoricalGenerator(noise_dim, label_dim, num_output_categorical, hidden_dim)\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        numerical_data = self.numerical_gen(noise, labels)\n",
    "        categorical_data = self.categorical_gen(noise, labels)\n",
    "        return torch.cat([numerical_data, categorical_data], dim = 1)\n",
    "\n",
    "class NumericalDiscriminator(nn.Module):\n",
    "    def __init__(self, input_dim, label_dim, hidden_dim):\n",
    "        super(NumericalDiscriminator, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim + label_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self, noise, labels):\n",
    "        x = torch.cat([noise, labels], dim = 1)\n",
    "        return self.layers(x)\n",
    "\n",
    "class CategoricalDiscriminator(nn.Module):\n",
    "    def __init__(self, input_dim, label_dim, hidden_dim):\n",
    "        super(CategoricalDiscriminator, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim + label_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self, noise, labels):\n",
    "        x = torch.cat([noise, labels], dim = 1)\n",
    "        return self.layers(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, label_dim, num_input_numerical, num_input_categorical, hidden_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.num_input_numerical = num_input_numerical\n",
    "        self.numerical_disc = NumericalDiscriminator(num_input_numerical, label_dim, hidden_dim)\n",
    "        self.categorical_disc = CategoricalDiscriminator(num_input_categorical, label_dim, hidden_dim)\n",
    "        self.final_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, data, labels):\n",
    "        numerical_data, categorical_data = data[:, :self.num_input_numerical], data[:, self.num_input_numerical:]\n",
    "        numerical_fetaure = self.numerical_disc(numerical_data, labels)\n",
    "        categorical_feature = self.categorical_disc(categorical_data, labels)\n",
    "        features = torch.cat([numerical_fetaure, categorical_feature], dim = 1)\n",
    "        return self.final_layer(features)\n",
    "\n",
    "def train_cgan(generator, discriminator, train_loader, device, gen_opt, disc_opt, num_epochs, noise_dim):\n",
    "    criterion = nn.BCELoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (real_data, labels) in enumerate(train_loader):\n",
    "            real_data, labels = real_data.to(device), labels.to(device)\n",
    "            batch_size = real_data.size(0)\n",
    "\n",
    "            disc_opt.zero_grad()\n",
    "            noise = torch.randn(batch_size, noise_dim, device = device)\n",
    "            fake_data = generator(noise, labels.to(device))\n",
    "            real_output = discriminator(real_data, labels.to(device))\n",
    "            fake_output = discriminator(fake_data.detach(), labels.to(device))\n",
    "            d_loss = criterion(real_output, torch.ones_like(real_output)) + criterion(fake_output, torch.zeros_like(fake_output))\n",
    "            d_loss.backward()\n",
    "            disc_opt.step()\n",
    "\n",
    "            gen_opt.zero_grad()\n",
    "            fake_output = discriminator(fake_data, labels.to(device))\n",
    "            g_loss = criterion(fake_output, torch.ones_like(fake_output))\n",
    "            g_loss.backward()\n",
    "            gen_opt.step()\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Generator Loss: {g_loss.item()}, Discriminator Loss: {d_loss.item()}\")\n",
    "    return g_loss.item()\n",
    "\n",
    "def bayesian_optimization_cgan(train_loader, device, noise_dim, label_dim, num_numerical, num_categorical):\n",
    "    def objective(params):\n",
    "        num_epochs, gen_hidden_dim, disc_hidden_dim, gen_lr, disc_lr, gen_beta1, disc_beta1 = params\n",
    "\n",
    "        generator = Generator(noise_dim, label_dim, num_numerical, num_categorical, gen_hidden_dim).to(device)\n",
    "        discriminator = Discriminator(label_dim, num_numerical, num_categorical, disc_hidden_dim).to(device)\n",
    "        gen_optimizer = optim.Adam(generator.parameters(), gen_lr, betas = (gen_beta1, 0.999))\n",
    "        disc_optimizer = optim.Adam(discriminator.parameters(), lr = disc_lr, betas = (disc_beta1, 0.999))\n",
    "\n",
    "        gloss = train_cgan(generator, discriminator, train_loader, device, gen_optimizer, disc_optimizer, num_epochs, noise_dim)\n",
    "        return -gloss\n",
    "\n",
    "    search_space = [\n",
    "        Integer(30, 100),\n",
    "        Integer(128, 512),\n",
    "        Integer(128, 512),\n",
    "        Real(1e-5, 1, prior=\"log-uniform\"),\n",
    "        Real(1e-5, 1, prior=\"log-uniform\"),\n",
    "        Real(0.0, 0.999),\n",
    "        Real(0.0, 0.999)\n",
    "    ]\n",
    "\n",
    "    result = gp_minimize(\n",
    "        func = objective,\n",
    "        dimensions = search_space,\n",
    "        n_calls = 50,\n",
    "        random_state = 233,\n",
    "        n_jobs = 12,\n",
    "        verbose = 1\n",
    "    )\n",
    "    \n",
    "    best_params = {\n",
    "        \"num_epochs\": result.x[0],\n",
    "        \"gen_hidden_dim\": result.x[1],\n",
    "        \"disc_hidden_dim\": result.x[2],\n",
    "        \"gen_lr\": result.x[3],\n",
    "        \"disc_lr\": result.x[4],\n",
    "        \"gen_beta1\": result.x[5],\n",
    "        \"disc_beta1\": result.x[6],\n",
    "    }\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Epoch: 1/64, Generator Loss: 4.9745774269104, Discriminator Loss: 0.01737961359322071\n",
      "Epoch: 2/64, Generator Loss: 5.243973731994629, Discriminator Loss: 0.013038907200098038\n",
      "Epoch: 3/64, Generator Loss: 3.9847285747528076, Discriminator Loss: 0.06308191269636154\n",
      "Epoch: 4/64, Generator Loss: 3.831009864807129, Discriminator Loss: 0.09471689164638519\n",
      "Epoch: 5/64, Generator Loss: 5.250096321105957, Discriminator Loss: 0.026962514966726303\n",
      "Epoch: 6/64, Generator Loss: 4.864640712738037, Discriminator Loss: 0.040539905428886414\n",
      "Epoch: 7/64, Generator Loss: 4.492305755615234, Discriminator Loss: 0.06789693236351013\n",
      "Epoch: 8/64, Generator Loss: 5.47452974319458, Discriminator Loss: 0.025067616254091263\n",
      "Epoch: 9/64, Generator Loss: 6.412323951721191, Discriminator Loss: 0.012873212806880474\n",
      "Epoch: 10/64, Generator Loss: 7.496582508087158, Discriminator Loss: 0.0032569956965744495\n",
      "Epoch: 11/64, Generator Loss: 7.325807094573975, Discriminator Loss: 0.005544302519410849\n",
      "Epoch: 12/64, Generator Loss: 8.376080513000488, Discriminator Loss: 0.0009165450464934111\n",
      "Epoch: 13/64, Generator Loss: 8.819262504577637, Discriminator Loss: 0.0007102833478711545\n",
      "Epoch: 14/64, Generator Loss: 8.590730667114258, Discriminator Loss: 0.0009271415183320642\n",
      "Epoch: 15/64, Generator Loss: 8.161124229431152, Discriminator Loss: 0.0007006257656030357\n",
      "Epoch: 16/64, Generator Loss: 8.129383087158203, Discriminator Loss: 0.001110047334805131\n",
      "Epoch: 17/64, Generator Loss: 7.895450115203857, Discriminator Loss: 0.0019512063590809703\n",
      "Epoch: 18/64, Generator Loss: 7.545407295227051, Discriminator Loss: 0.0009366848971694708\n",
      "Epoch: 19/64, Generator Loss: 8.361270904541016, Discriminator Loss: 0.00437470106408\n",
      "Epoch: 20/64, Generator Loss: 8.287796020507812, Discriminator Loss: 0.0005736353923566639\n",
      "Epoch: 21/64, Generator Loss: 7.811733245849609, Discriminator Loss: 0.002435414120554924\n",
      "Epoch: 22/64, Generator Loss: 6.852886199951172, Discriminator Loss: 0.002843705238774419\n",
      "Epoch: 23/64, Generator Loss: 7.530440330505371, Discriminator Loss: 0.002805834636092186\n",
      "Epoch: 24/64, Generator Loss: 8.181076049804688, Discriminator Loss: 0.001857212046161294\n",
      "Epoch: 25/64, Generator Loss: 7.209285736083984, Discriminator Loss: 0.0010416264412924647\n",
      "Epoch: 26/64, Generator Loss: 6.693653583526611, Discriminator Loss: 0.0029905440751463175\n",
      "Epoch: 27/64, Generator Loss: 7.931496620178223, Discriminator Loss: 0.0031721163541078568\n",
      "Epoch: 28/64, Generator Loss: 8.119741439819336, Discriminator Loss: 0.001432596007362008\n",
      "Epoch: 29/64, Generator Loss: 8.573078155517578, Discriminator Loss: 0.0024623635690659285\n",
      "Epoch: 30/64, Generator Loss: 8.467835426330566, Discriminator Loss: 0.0003506317443680018\n",
      "Epoch: 31/64, Generator Loss: 9.871729850769043, Discriminator Loss: 0.0003484242770355195\n",
      "Epoch: 32/64, Generator Loss: 9.012072563171387, Discriminator Loss: 0.0005729926051571965\n",
      "Epoch: 33/64, Generator Loss: 9.708518981933594, Discriminator Loss: 0.0006925943307578564\n",
      "Epoch: 34/64, Generator Loss: 10.353995323181152, Discriminator Loss: 0.00014791559078730643\n",
      "Epoch: 35/64, Generator Loss: 10.048371315002441, Discriminator Loss: 0.0005747632822021842\n",
      "Epoch: 36/64, Generator Loss: 10.426287651062012, Discriminator Loss: 0.00016424170462414622\n",
      "Epoch: 37/64, Generator Loss: 10.894607543945312, Discriminator Loss: 6.416951509891078e-05\n",
      "Epoch: 38/64, Generator Loss: 10.377961158752441, Discriminator Loss: 0.00020015492918901145\n",
      "Epoch: 39/64, Generator Loss: 10.730368614196777, Discriminator Loss: 5.9849735407624394e-05\n",
      "Epoch: 40/64, Generator Loss: 11.652904510498047, Discriminator Loss: 0.000171285355463624\n",
      "Epoch: 41/64, Generator Loss: 10.968709945678711, Discriminator Loss: 7.889977132435888e-05\n",
      "Epoch: 42/64, Generator Loss: 11.070066452026367, Discriminator Loss: 7.062538497848436e-05\n",
      "Epoch: 43/64, Generator Loss: 10.484153747558594, Discriminator Loss: 0.00011095187801402062\n",
      "Epoch: 44/64, Generator Loss: 9.876251220703125, Discriminator Loss: 0.000563497596886009\n",
      "Epoch: 45/64, Generator Loss: 9.788905143737793, Discriminator Loss: 0.0005523394793272018\n",
      "Epoch: 46/64, Generator Loss: 9.340315818786621, Discriminator Loss: 0.00017058308003470302\n",
      "Epoch: 47/64, Generator Loss: 9.486564636230469, Discriminator Loss: 0.00022293426445685327\n",
      "Epoch: 48/64, Generator Loss: 8.308838844299316, Discriminator Loss: 0.01066344603896141\n",
      "Epoch: 49/64, Generator Loss: 9.144990921020508, Discriminator Loss: 0.00020956200023647398\n",
      "Epoch: 50/64, Generator Loss: 8.25809097290039, Discriminator Loss: 0.0006041079759597778\n",
      "Epoch: 51/64, Generator Loss: 8.35948371887207, Discriminator Loss: 0.00047195350634865463\n",
      "Epoch: 52/64, Generator Loss: 9.232147216796875, Discriminator Loss: 0.0004336363053880632\n",
      "Epoch: 53/64, Generator Loss: 10.138240814208984, Discriminator Loss: 4.925124085275456e-05\n",
      "Epoch: 54/64, Generator Loss: 11.040745735168457, Discriminator Loss: 0.00011311590060358867\n",
      "Epoch: 55/64, Generator Loss: 9.31014347076416, Discriminator Loss: 0.0003148192190565169\n",
      "Epoch: 56/64, Generator Loss: 8.593422889709473, Discriminator Loss: 0.0004160304961260408\n",
      "Epoch: 57/64, Generator Loss: 9.837542533874512, Discriminator Loss: 8.44186288304627e-05\n",
      "Epoch: 58/64, Generator Loss: 9.87998104095459, Discriminator Loss: 0.00017686182400211692\n",
      "Epoch: 59/64, Generator Loss: 8.900247573852539, Discriminator Loss: 0.00032778605236671865\n",
      "Epoch: 60/64, Generator Loss: 9.926957130432129, Discriminator Loss: 0.0005248204106464982\n",
      "Epoch: 61/64, Generator Loss: 9.661506652832031, Discriminator Loss: 0.0006512359832413495\n",
      "Epoch: 62/64, Generator Loss: 8.905585289001465, Discriminator Loss: 0.0006320911343209445\n",
      "Epoch: 63/64, Generator Loss: 10.829687118530273, Discriminator Loss: 4.777703361469321e-05\n",
      "Epoch: 64/64, Generator Loss: 10.365999221801758, Discriminator Loss: 0.0002792346349451691\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 17.3285\n",
      "Function value obtained: -10.3660\n",
      "Current minimum: -10.3660\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Epoch: 1/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 21.4381\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -10.3660\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Epoch: 1/46, Generator Loss: 1.8944761753082275, Discriminator Loss: 0.5999263525009155\n",
      "Epoch: 2/46, Generator Loss: 2.563241720199585, Discriminator Loss: 0.24784058332443237\n",
      "Epoch: 3/46, Generator Loss: 5.747238636016846, Discriminator Loss: 0.20478886365890503\n",
      "Epoch: 4/46, Generator Loss: 4.9319539070129395, Discriminator Loss: 0.19248032569885254\n",
      "Epoch: 5/46, Generator Loss: 4.226541519165039, Discriminator Loss: 0.14063702523708344\n",
      "Epoch: 6/46, Generator Loss: 4.724664211273193, Discriminator Loss: 0.054418083280324936\n",
      "Epoch: 7/46, Generator Loss: 5.942253589630127, Discriminator Loss: 0.08038565516471863\n",
      "Epoch: 8/46, Generator Loss: 5.019744396209717, Discriminator Loss: 0.02685781940817833\n",
      "Epoch: 9/46, Generator Loss: 4.822388172149658, Discriminator Loss: 0.023607883602380753\n",
      "Epoch: 10/46, Generator Loss: 5.717615604400635, Discriminator Loss: 0.013225429691374302\n",
      "Epoch: 11/46, Generator Loss: 5.430601596832275, Discriminator Loss: 0.023306304588913918\n",
      "Epoch: 12/46, Generator Loss: 6.380216598510742, Discriminator Loss: 0.013217858970165253\n",
      "Epoch: 13/46, Generator Loss: 8.09437084197998, Discriminator Loss: 0.01716616377234459\n",
      "Epoch: 14/46, Generator Loss: 5.818456649780273, Discriminator Loss: 0.017548181116580963\n",
      "Epoch: 15/46, Generator Loss: 5.9010329246521, Discriminator Loss: 0.014914428815245628\n",
      "Epoch: 16/46, Generator Loss: 10.193931579589844, Discriminator Loss: 0.0014109858311712742\n",
      "Epoch: 17/46, Generator Loss: 7.005537509918213, Discriminator Loss: 0.020361024886369705\n",
      "Epoch: 18/46, Generator Loss: 6.771363258361816, Discriminator Loss: 0.0021175160072743893\n",
      "Epoch: 19/46, Generator Loss: 6.205183982849121, Discriminator Loss: 0.02976956218481064\n",
      "Epoch: 20/46, Generator Loss: 6.485722064971924, Discriminator Loss: 0.03964441269636154\n",
      "Epoch: 21/46, Generator Loss: 7.3007283210754395, Discriminator Loss: 0.0015732715837657452\n",
      "Epoch: 22/46, Generator Loss: 13.151300430297852, Discriminator Loss: 1.4080480468692258e-05\n",
      "Epoch: 23/46, Generator Loss: 9.276434898376465, Discriminator Loss: 0.002217395231127739\n",
      "Epoch: 24/46, Generator Loss: 6.307725429534912, Discriminator Loss: 0.0038920966908335686\n",
      "Epoch: 25/46, Generator Loss: 5.876148223876953, Discriminator Loss: 0.003683915128931403\n",
      "Epoch: 26/46, Generator Loss: 6.735395908355713, Discriminator Loss: 0.02539294771850109\n",
      "Epoch: 27/46, Generator Loss: 6.507742881774902, Discriminator Loss: 0.009147084318101406\n",
      "Epoch: 28/46, Generator Loss: 7.763779163360596, Discriminator Loss: 0.0014041803078725934\n",
      "Epoch: 29/46, Generator Loss: 7.443137168884277, Discriminator Loss: 0.0007809870294295251\n",
      "Epoch: 30/46, Generator Loss: 6.1192169189453125, Discriminator Loss: 0.004306489136070013\n",
      "Epoch: 31/46, Generator Loss: 6.730540752410889, Discriminator Loss: 0.002507123164832592\n",
      "Epoch: 32/46, Generator Loss: 9.429210662841797, Discriminator Loss: 0.0010104463435709476\n",
      "Epoch: 33/46, Generator Loss: 6.624798774719238, Discriminator Loss: 0.0056807310320436954\n",
      "Epoch: 34/46, Generator Loss: 10.767657279968262, Discriminator Loss: 0.1255212128162384\n",
      "Epoch: 35/46, Generator Loss: 7.291112422943115, Discriminator Loss: 0.01311017107218504\n",
      "Epoch: 36/46, Generator Loss: 7.833077907562256, Discriminator Loss: 0.0007178004016168416\n",
      "Epoch: 37/46, Generator Loss: 10.554250717163086, Discriminator Loss: 0.03559938073158264\n",
      "Epoch: 38/46, Generator Loss: 8.609663963317871, Discriminator Loss: 0.010900763794779778\n",
      "Epoch: 39/46, Generator Loss: 13.593976020812988, Discriminator Loss: 0.25985243916511536\n",
      "Epoch: 40/46, Generator Loss: 5.554718017578125, Discriminator Loss: 0.0412994883954525\n",
      "Epoch: 41/46, Generator Loss: 6.888803958892822, Discriminator Loss: 0.0017282726475968957\n",
      "Epoch: 42/46, Generator Loss: 5.3439249992370605, Discriminator Loss: 0.022816862910985947\n",
      "Epoch: 43/46, Generator Loss: 10.36347484588623, Discriminator Loss: 0.03342605009675026\n",
      "Epoch: 44/46, Generator Loss: 5.525662899017334, Discriminator Loss: 0.023839153349399567\n",
      "Epoch: 45/46, Generator Loss: 9.658388137817383, Discriminator Loss: 0.0016339528374373913\n",
      "Epoch: 46/46, Generator Loss: 5.972404956817627, Discriminator Loss: 0.003767563495784998\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 11.5317\n",
      "Function value obtained: -5.9724\n",
      "Current minimum: -10.3660\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Epoch: 1/42, Generator Loss: 0.7785446047782898, Discriminator Loss: 1.6480107307434082\n",
      "Epoch: 2/42, Generator Loss: 0.6393285393714905, Discriminator Loss: 1.4958281517028809\n",
      "Epoch: 3/42, Generator Loss: 0.6944429874420166, Discriminator Loss: 1.4475011825561523\n",
      "Epoch: 4/42, Generator Loss: 0.7436379790306091, Discriminator Loss: 1.4094440937042236\n",
      "Epoch: 5/42, Generator Loss: 0.6951181888580322, Discriminator Loss: 1.3907026052474976\n",
      "Epoch: 6/42, Generator Loss: 0.6847047209739685, Discriminator Loss: 1.4268150329589844\n",
      "Epoch: 7/42, Generator Loss: 0.7071164846420288, Discriminator Loss: 1.4449410438537598\n",
      "Epoch: 8/42, Generator Loss: 0.6585637331008911, Discriminator Loss: 1.379181146621704\n",
      "Epoch: 9/42, Generator Loss: 0.7243114113807678, Discriminator Loss: 1.4421467781066895\n",
      "Epoch: 10/42, Generator Loss: 0.6380609273910522, Discriminator Loss: 1.4862022399902344\n",
      "Epoch: 11/42, Generator Loss: 0.6719373464584351, Discriminator Loss: 1.372999906539917\n",
      "Epoch: 12/42, Generator Loss: 0.6940906047821045, Discriminator Loss: 1.426936149597168\n",
      "Epoch: 13/42, Generator Loss: 0.7005169987678528, Discriminator Loss: 1.4141216278076172\n",
      "Epoch: 14/42, Generator Loss: 0.6381688714027405, Discriminator Loss: 1.4464359283447266\n",
      "Epoch: 15/42, Generator Loss: 0.6449146866798401, Discriminator Loss: 1.4294850826263428\n",
      "Epoch: 16/42, Generator Loss: 0.7042709589004517, Discriminator Loss: 1.40494966506958\n",
      "Epoch: 17/42, Generator Loss: 0.7319927215576172, Discriminator Loss: 1.3460400104522705\n",
      "Epoch: 18/42, Generator Loss: 0.7543694972991943, Discriminator Loss: 1.374124526977539\n",
      "Epoch: 19/42, Generator Loss: 0.8604223132133484, Discriminator Loss: 1.3514673709869385\n",
      "Epoch: 20/42, Generator Loss: 0.7688813209533691, Discriminator Loss: 1.3384897708892822\n",
      "Epoch: 21/42, Generator Loss: 0.5299662947654724, Discriminator Loss: 1.5587996244430542\n",
      "Epoch: 22/42, Generator Loss: 0.4412514269351959, Discriminator Loss: 1.5516812801361084\n",
      "Epoch: 23/42, Generator Loss: 0.6657536029815674, Discriminator Loss: 1.4426414966583252\n",
      "Epoch: 24/42, Generator Loss: 0.5583125948905945, Discriminator Loss: 1.4685962200164795\n",
      "Epoch: 25/42, Generator Loss: 0.7765753269195557, Discriminator Loss: 1.363071322441101\n",
      "Epoch: 26/42, Generator Loss: 0.9652787446975708, Discriminator Loss: 1.1691688299179077\n",
      "Epoch: 27/42, Generator Loss: 0.5608862638473511, Discriminator Loss: 1.5447309017181396\n",
      "Epoch: 28/42, Generator Loss: 0.0227616298943758, Discriminator Loss: 4.618022441864014\n",
      "Epoch: 29/42, Generator Loss: 1.321619987487793, Discriminator Loss: 0.7972836494445801\n",
      "Epoch: 30/42, Generator Loss: 1.6600544452667236, Discriminator Loss: 1.2680821418762207\n",
      "Epoch: 31/42, Generator Loss: 3.695452928543091, Discriminator Loss: 0.43943464756011963\n",
      "Epoch: 32/42, Generator Loss: 5.578214168548584, Discriminator Loss: 0.021312011405825615\n",
      "Epoch: 33/42, Generator Loss: 5.898351192474365, Discriminator Loss: 0.6048696637153625\n",
      "Epoch: 34/42, Generator Loss: 4.7769389152526855, Discriminator Loss: 0.05667862296104431\n",
      "Epoch: 35/42, Generator Loss: 5.318617343902588, Discriminator Loss: 0.05643908679485321\n",
      "Epoch: 36/42, Generator Loss: 5.469213008880615, Discriminator Loss: 0.07729105651378632\n",
      "Epoch: 37/42, Generator Loss: 6.4601006507873535, Discriminator Loss: 0.007460495922714472\n",
      "Epoch: 38/42, Generator Loss: 6.827842712402344, Discriminator Loss: 0.001997357001528144\n",
      "Epoch: 39/42, Generator Loss: 7.194204807281494, Discriminator Loss: 0.001554396701976657\n",
      "Epoch: 40/42, Generator Loss: 7.421004772186279, Discriminator Loss: 0.0012659789063036442\n",
      "Epoch: 41/42, Generator Loss: 6.7634406089782715, Discriminator Loss: 0.0034133163280785084\n",
      "Epoch: 42/42, Generator Loss: 7.534473419189453, Discriminator Loss: 0.001224907347932458\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 10.3320\n",
      "Function value obtained: -7.5345\n",
      "Current minimum: -10.3660\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Epoch: 1/96, Generator Loss: 5.111019611358643, Discriminator Loss: 0.1134219616651535\n",
      "Epoch: 2/96, Generator Loss: 3.8623576164245605, Discriminator Loss: 0.15764166414737701\n",
      "Epoch: 3/96, Generator Loss: 8.703408241271973, Discriminator Loss: 0.042402662336826324\n",
      "Epoch: 4/96, Generator Loss: 4.537398338317871, Discriminator Loss: 0.14169511198997498\n",
      "Epoch: 5/96, Generator Loss: 7.347670078277588, Discriminator Loss: 0.003930991515517235\n",
      "Epoch: 6/96, Generator Loss: 7.355298042297363, Discriminator Loss: 0.01059527974575758\n",
      "Epoch: 7/96, Generator Loss: 5.861913681030273, Discriminator Loss: 0.01608351431787014\n",
      "Epoch: 8/96, Generator Loss: 5.974454879760742, Discriminator Loss: 0.03400732949376106\n",
      "Epoch: 9/96, Generator Loss: 7.144019603729248, Discriminator Loss: 0.015158682130277157\n",
      "Epoch: 10/96, Generator Loss: 7.0235466957092285, Discriminator Loss: 0.0048326486721634865\n",
      "Epoch: 11/96, Generator Loss: 6.417217254638672, Discriminator Loss: 0.01808803528547287\n",
      "Epoch: 12/96, Generator Loss: 7.083610534667969, Discriminator Loss: 0.0027766460552811623\n",
      "Epoch: 13/96, Generator Loss: 11.851784706115723, Discriminator Loss: 0.0002272560668643564\n",
      "Epoch: 14/96, Generator Loss: 7.082005500793457, Discriminator Loss: 0.004494212567806244\n",
      "Epoch: 15/96, Generator Loss: 9.908692359924316, Discriminator Loss: 0.005720012821257114\n",
      "Epoch: 16/96, Generator Loss: 13.064043045043945, Discriminator Loss: 0.0004380219615995884\n",
      "Epoch: 17/96, Generator Loss: 10.353901863098145, Discriminator Loss: 0.0001278686395380646\n",
      "Epoch: 18/96, Generator Loss: 9.372550010681152, Discriminator Loss: 0.0004002977511845529\n",
      "Epoch: 19/96, Generator Loss: 6.523966312408447, Discriminator Loss: 0.0062813302502036095\n",
      "Epoch: 20/96, Generator Loss: 11.348377227783203, Discriminator Loss: 0.002915845951065421\n",
      "Epoch: 21/96, Generator Loss: 9.391508102416992, Discriminator Loss: 0.026716873049736023\n",
      "Epoch: 22/96, Generator Loss: 10.7358980178833, Discriminator Loss: 3.73736911569722e-05\n",
      "Epoch: 23/96, Generator Loss: 48.842185974121094, Discriminator Loss: 1.0838037269422784e-05\n",
      "Epoch: 24/96, Generator Loss: 45.80982971191406, Discriminator Loss: 3.2170823942578863e-06\n",
      "Epoch: 25/96, Generator Loss: 45.77748489379883, Discriminator Loss: 1.084110226656776e-05\n",
      "Epoch: 26/96, Generator Loss: 45.41951370239258, Discriminator Loss: 4.9661844968795776e-05\n",
      "Epoch: 27/96, Generator Loss: 45.28643035888672, Discriminator Loss: 3.637235568021424e-05\n",
      "Epoch: 28/96, Generator Loss: 45.020626068115234, Discriminator Loss: 6.711979949614033e-07\n",
      "Epoch: 29/96, Generator Loss: 45.28825759887695, Discriminator Loss: 2.1437693931147805e-07\n",
      "Epoch: 30/96, Generator Loss: 44.95292282104492, Discriminator Loss: 3.0353419333550846e-07\n",
      "Epoch: 31/96, Generator Loss: 45.09140396118164, Discriminator Loss: 6.291138561209664e-07\n",
      "Epoch: 32/96, Generator Loss: 44.92034912109375, Discriminator Loss: 3.0307710403576493e-05\n",
      "Epoch: 33/96, Generator Loss: 44.67094039916992, Discriminator Loss: 7.102550512172456e-07\n",
      "Epoch: 34/96, Generator Loss: 44.53476333618164, Discriminator Loss: 1.0117772575313211e-07\n",
      "Epoch: 35/96, Generator Loss: 44.54731369018555, Discriminator Loss: 7.012321390220677e-08\n",
      "Epoch: 36/96, Generator Loss: 44.314857482910156, Discriminator Loss: 4.040037310915068e-06\n",
      "Epoch: 37/96, Generator Loss: 43.96931838989258, Discriminator Loss: 8.324912528223649e-07\n",
      "Epoch: 38/96, Generator Loss: 50.295631408691406, Discriminator Loss: 0.0006118927849456668\n",
      "Epoch: 39/96, Generator Loss: 6.8130669593811035, Discriminator Loss: 0.013073213398456573\n",
      "Epoch: 40/96, Generator Loss: 8.477036476135254, Discriminator Loss: 0.0007342063472606242\n",
      "Epoch: 41/96, Generator Loss: 9.952085494995117, Discriminator Loss: 6.221640796866268e-05\n",
      "Epoch: 42/96, Generator Loss: 10.263239860534668, Discriminator Loss: 5.680613685399294e-05\n",
      "Epoch: 43/96, Generator Loss: 10.987787246704102, Discriminator Loss: 4.291753430152312e-05\n",
      "Epoch: 44/96, Generator Loss: 13.52776050567627, Discriminator Loss: 1.4123666005616542e-05\n",
      "Epoch: 45/96, Generator Loss: 10.398741722106934, Discriminator Loss: 6.138659227872267e-05\n",
      "Epoch: 46/96, Generator Loss: 13.443087577819824, Discriminator Loss: 0.18935254216194153\n",
      "Epoch: 47/96, Generator Loss: 8.220139503479004, Discriminator Loss: 0.0021415792871266603\n",
      "Epoch: 48/96, Generator Loss: 7.601285457611084, Discriminator Loss: 0.002482255920767784\n",
      "Epoch: 49/96, Generator Loss: 9.035164833068848, Discriminator Loss: 0.0021113739348948\n",
      "Epoch: 50/96, Generator Loss: 8.398297309875488, Discriminator Loss: 0.000418888870626688\n",
      "Epoch: 51/96, Generator Loss: 8.656461715698242, Discriminator Loss: 0.00019763395539484918\n",
      "Epoch: 52/96, Generator Loss: 9.620094299316406, Discriminator Loss: 8.752265421207994e-05\n",
      "Epoch: 53/96, Generator Loss: 9.452199935913086, Discriminator Loss: 0.00032107430160976946\n",
      "Epoch: 54/96, Generator Loss: 8.922178268432617, Discriminator Loss: 0.00017257928266189992\n",
      "Epoch: 55/96, Generator Loss: 8.868746757507324, Discriminator Loss: 0.00021163385827094316\n",
      "Epoch: 56/96, Generator Loss: 9.331926345825195, Discriminator Loss: 0.0002990984939970076\n",
      "Epoch: 57/96, Generator Loss: 10.851898193359375, Discriminator Loss: 0.0002995061513502151\n",
      "Epoch: 58/96, Generator Loss: 10.733668327331543, Discriminator Loss: 2.5995264877565205e-05\n",
      "Epoch: 59/96, Generator Loss: 11.840946197509766, Discriminator Loss: 1.0545761142566334e-05\n",
      "Epoch: 60/96, Generator Loss: 10.69565200805664, Discriminator Loss: 2.9695360353798606e-05\n",
      "Epoch: 61/96, Generator Loss: 11.789133071899414, Discriminator Loss: 1.3534292520489544e-05\n",
      "Epoch: 62/96, Generator Loss: 12.772781372070312, Discriminator Loss: 4.616073510987917e-06\n",
      "Epoch: 63/96, Generator Loss: 13.118228912353516, Discriminator Loss: 8.848736797517631e-06\n",
      "Epoch: 64/96, Generator Loss: 13.277026176452637, Discriminator Loss: 3.1632735044695437e-06\n",
      "Epoch: 65/96, Generator Loss: 12.904166221618652, Discriminator Loss: 8.694703137734905e-05\n",
      "Epoch: 66/96, Generator Loss: 13.492341995239258, Discriminator Loss: 2.4245696295110974e-06\n",
      "Epoch: 67/96, Generator Loss: 13.855603218078613, Discriminator Loss: 4.606491074810037e-06\n",
      "Epoch: 68/96, Generator Loss: 14.05597972869873, Discriminator Loss: 9.53052335717075e-07\n",
      "Epoch: 69/96, Generator Loss: 14.136768341064453, Discriminator Loss: 7.30036799723166e-06\n",
      "Epoch: 70/96, Generator Loss: 14.394399642944336, Discriminator Loss: 6.14132943610457e-07\n",
      "Epoch: 71/96, Generator Loss: 12.648677825927734, Discriminator Loss: 5.135116225574166e-06\n",
      "Epoch: 72/96, Generator Loss: 13.73940372467041, Discriminator Loss: 2.4220316845458e-06\n",
      "Epoch: 73/96, Generator Loss: 14.137800216674805, Discriminator Loss: 8.311582178066601e-07\n",
      "Epoch: 74/96, Generator Loss: 14.418045043945312, Discriminator Loss: 6.6688612605503295e-06\n",
      "Epoch: 75/96, Generator Loss: 14.548966407775879, Discriminator Loss: 5.736858383897925e-07\n",
      "Epoch: 76/96, Generator Loss: 14.712133407592773, Discriminator Loss: 2.0149589090578957e-06\n",
      "Epoch: 77/96, Generator Loss: 14.847176551818848, Discriminator Loss: 1.8367454686085694e-06\n",
      "Epoch: 78/96, Generator Loss: 14.958381652832031, Discriminator Loss: 7.174801794462837e-06\n",
      "Epoch: 79/96, Generator Loss: 15.034205436706543, Discriminator Loss: 4.0824158986652037e-07\n",
      "Epoch: 80/96, Generator Loss: 15.08608627319336, Discriminator Loss: 3.578203973120253e-07\n",
      "Epoch: 81/96, Generator Loss: 15.191662788391113, Discriminator Loss: 1.1992446161457337e-05\n",
      "Epoch: 82/96, Generator Loss: 15.342140197753906, Discriminator Loss: 2.940965657671768e-07\n",
      "Epoch: 83/96, Generator Loss: 14.88365650177002, Discriminator Loss: 7.148690883695963e-07\n",
      "Epoch: 84/96, Generator Loss: 15.044206619262695, Discriminator Loss: 4.037078156216012e-07\n",
      "Epoch: 85/96, Generator Loss: 14.565364837646484, Discriminator Loss: 4.171113232587231e-06\n",
      "Epoch: 86/96, Generator Loss: 12.625509262084961, Discriminator Loss: 5.816852990392363e-06\n",
      "Epoch: 87/96, Generator Loss: 15.933937072753906, Discriminator Loss: 0.010389734990894794\n",
      "Epoch: 88/96, Generator Loss: 8.089448928833008, Discriminator Loss: 0.017006073147058487\n",
      "Epoch: 89/96, Generator Loss: 7.187548637390137, Discriminator Loss: 0.003079094924032688\n",
      "Epoch: 90/96, Generator Loss: 8.16927433013916, Discriminator Loss: 0.0004037038015667349\n",
      "Epoch: 91/96, Generator Loss: 6.332660675048828, Discriminator Loss: 0.008068879134953022\n",
      "Epoch: 92/96, Generator Loss: 8.832782745361328, Discriminator Loss: 0.00016854354180395603\n",
      "Epoch: 93/96, Generator Loss: 10.195279121398926, Discriminator Loss: 3.917534195352346e-05\n",
      "Epoch: 94/96, Generator Loss: 10.498011589050293, Discriminator Loss: 2.9270999220898375e-05\n",
      "Epoch: 95/96, Generator Loss: 10.826502799987793, Discriminator Loss: 2.1589257812593132e-05\n",
      "Epoch: 96/96, Generator Loss: 10.214224815368652, Discriminator Loss: 3.98985757783521e-05\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 24.2508\n",
      "Function value obtained: -10.2142\n",
      "Current minimum: -10.3660\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "Epoch: 1/42, Generator Loss: 6.420188903808594, Discriminator Loss: 0.04030587524175644\n",
      "Epoch: 2/42, Generator Loss: 6.858806133270264, Discriminator Loss: 0.004119875840842724\n",
      "Epoch: 3/42, Generator Loss: 8.768919944763184, Discriminator Loss: 0.0005336308968253434\n",
      "Epoch: 4/42, Generator Loss: 9.172290802001953, Discriminator Loss: 0.0003153192810714245\n",
      "Epoch: 5/42, Generator Loss: 9.089218139648438, Discriminator Loss: 0.0001908318663481623\n",
      "Epoch: 6/42, Generator Loss: 8.793641090393066, Discriminator Loss: 0.000695097609423101\n",
      "Epoch: 7/42, Generator Loss: 10.222640037536621, Discriminator Loss: 4.104304753127508e-05\n",
      "Epoch: 8/42, Generator Loss: 11.345173835754395, Discriminator Loss: 1.2730729395116214e-05\n",
      "Epoch: 9/42, Generator Loss: 11.884648323059082, Discriminator Loss: 9.351386324851774e-06\n",
      "Epoch: 10/42, Generator Loss: 10.904537200927734, Discriminator Loss: 2.332320946152322e-05\n",
      "Epoch: 11/42, Generator Loss: 12.511180877685547, Discriminator Loss: 5.440274435386527e-06\n",
      "Epoch: 12/42, Generator Loss: 17.115142822265625, Discriminator Loss: 1.905621758169218e-07\n",
      "Epoch: 13/42, Generator Loss: 17.46807098388672, Discriminator Loss: 2.699104584280576e-07\n",
      "Epoch: 14/42, Generator Loss: 17.86065673828125, Discriminator Loss: 1.1203715644114709e-07\n",
      "Epoch: 15/42, Generator Loss: 18.090660095214844, Discriminator Loss: 1.3588073954906577e-07\n",
      "Epoch: 16/42, Generator Loss: 18.15094757080078, Discriminator Loss: 7.213299113573157e-08\n",
      "Epoch: 17/42, Generator Loss: 18.696014404296875, Discriminator Loss: 7.419254899332373e-08\n",
      "Epoch: 18/42, Generator Loss: 18.411441802978516, Discriminator Loss: 5.523068224988492e-08\n",
      "Epoch: 19/42, Generator Loss: 19.728940963745117, Discriminator Loss: 1.1305238700742848e-07\n",
      "Epoch: 20/42, Generator Loss: 19.88494110107422, Discriminator Loss: 3.850681480344065e-07\n",
      "Epoch: 21/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 10.6033\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -10.3660\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "Epoch: 1/47, Generator Loss: 0.0, Discriminator Loss: 100.21366119384766\n",
      "Epoch: 2/47, Generator Loss: 0.0, Discriminator Loss: 100.06175231933594\n",
      "Epoch: 3/47, Generator Loss: 0.0, Discriminator Loss: 100.0223617553711\n",
      "Epoch: 4/47, Generator Loss: 0.0, Discriminator Loss: 100.01074981689453\n",
      "Epoch: 5/47, Generator Loss: 0.0, Discriminator Loss: 100.00548553466797\n",
      "Epoch: 6/47, Generator Loss: 0.0, Discriminator Loss: 100.00340270996094\n",
      "Epoch: 7/47, Generator Loss: 0.0, Discriminator Loss: 100.00234985351562\n",
      "Epoch: 8/47, Generator Loss: 0.0, Discriminator Loss: 100.00161743164062\n",
      "Epoch: 9/47, Generator Loss: 0.0, Discriminator Loss: 100.00103759765625\n",
      "Epoch: 10/47, Generator Loss: 0.0, Discriminator Loss: 100.00079345703125\n",
      "Epoch: 11/47, Generator Loss: 0.0, Discriminator Loss: 100.00057220458984\n",
      "Epoch: 12/47, Generator Loss: 0.0, Discriminator Loss: 100.00047302246094\n",
      "Epoch: 13/47, Generator Loss: 0.0, Discriminator Loss: 100.00037384033203\n",
      "Epoch: 14/47, Generator Loss: 0.0, Discriminator Loss: 100.00029754638672\n",
      "Epoch: 15/47, Generator Loss: 0.0, Discriminator Loss: 100.00025939941406\n",
      "Epoch: 16/47, Generator Loss: 0.0, Discriminator Loss: 100.0002212524414\n",
      "Epoch: 17/47, Generator Loss: 0.0, Discriminator Loss: 100.00019073486328\n",
      "Epoch: 18/47, Generator Loss: 0.0, Discriminator Loss: 100.00016784667969\n",
      "Epoch: 19/47, Generator Loss: 0.0, Discriminator Loss: 100.0001449584961\n",
      "Epoch: 20/47, Generator Loss: 0.0, Discriminator Loss: 100.00011444091797\n",
      "Epoch: 21/47, Generator Loss: 0.0, Discriminator Loss: 100.00011444091797\n",
      "Epoch: 22/47, Generator Loss: 0.0, Discriminator Loss: 100.0000991821289\n",
      "Epoch: 23/47, Generator Loss: 0.0, Discriminator Loss: 100.00009155273438\n",
      "Epoch: 24/47, Generator Loss: 0.0, Discriminator Loss: 100.00007629394531\n",
      "Epoch: 25/47, Generator Loss: 0.0, Discriminator Loss: 100.00006866455078\n",
      "Epoch: 26/47, Generator Loss: 0.0, Discriminator Loss: 100.00006103515625\n",
      "Epoch: 27/47, Generator Loss: 0.0, Discriminator Loss: 100.00006103515625\n",
      "Epoch: 28/47, Generator Loss: 0.0, Discriminator Loss: 100.00005340576172\n",
      "Epoch: 29/47, Generator Loss: 0.0, Discriminator Loss: 100.00005340576172\n",
      "Epoch: 30/47, Generator Loss: 0.0, Discriminator Loss: 100.00004577636719\n",
      "Epoch: 31/47, Generator Loss: 0.0, Discriminator Loss: 100.00003814697266\n",
      "Epoch: 32/47, Generator Loss: 0.0, Discriminator Loss: 100.00003814697266\n",
      "Epoch: 33/47, Generator Loss: 0.0, Discriminator Loss: 100.00003814697266\n",
      "Epoch: 34/47, Generator Loss: 0.0, Discriminator Loss: 100.00003051757812\n",
      "Epoch: 35/47, Generator Loss: 0.0, Discriminator Loss: 100.00003814697266\n",
      "Epoch: 36/47, Generator Loss: 0.0, Discriminator Loss: 100.00003051757812\n",
      "Epoch: 37/47, Generator Loss: 0.0, Discriminator Loss: 100.00003051757812\n",
      "Epoch: 38/47, Generator Loss: 0.0, Discriminator Loss: 100.00003051757812\n",
      "Epoch: 39/47, Generator Loss: 0.0, Discriminator Loss: 100.0000228881836\n",
      "Epoch: 40/47, Generator Loss: 0.0, Discriminator Loss: 100.0000228881836\n",
      "Epoch: 41/47, Generator Loss: 0.0, Discriminator Loss: 100.0000228881836\n",
      "Epoch: 42/47, Generator Loss: 0.0, Discriminator Loss: 100.0000228881836\n",
      "Epoch: 43/47, Generator Loss: 0.0, Discriminator Loss: 100.0000228881836\n",
      "Epoch: 44/47, Generator Loss: 0.0, Discriminator Loss: 100.0000228881836\n",
      "Epoch: 45/47, Generator Loss: 0.0, Discriminator Loss: 100.00001525878906\n",
      "Epoch: 46/47, Generator Loss: 0.0, Discriminator Loss: 100.00001525878906\n",
      "Epoch: 47/47, Generator Loss: 0.0, Discriminator Loss: 100.00001525878906\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 11.7993\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -10.3660\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "Epoch: 1/84, Generator Loss: 1.662661075592041, Discriminator Loss: 1.193640947341919\n",
      "Epoch: 2/84, Generator Loss: 2.5755832195281982, Discriminator Loss: 0.2939968705177307\n",
      "Epoch: 3/84, Generator Loss: 3.7239654064178467, Discriminator Loss: 0.11651434004306793\n",
      "Epoch: 4/84, Generator Loss: 5.86712121963501, Discriminator Loss: 0.012972918339073658\n",
      "Epoch: 5/84, Generator Loss: 4.680222988128662, Discriminator Loss: 0.06042705476284027\n",
      "Epoch: 6/84, Generator Loss: 0.32949528098106384, Discriminator Loss: 2.2663354873657227\n",
      "Epoch: 7/84, Generator Loss: 6.895566463470459, Discriminator Loss: 0.3931904435157776\n",
      "Epoch: 8/84, Generator Loss: 6.446809768676758, Discriminator Loss: 0.2056107223033905\n",
      "Epoch: 9/84, Generator Loss: 4.469409942626953, Discriminator Loss: 0.042081110179424286\n",
      "Epoch: 10/84, Generator Loss: 8.24286937713623, Discriminator Loss: 0.0010805734200403094\n",
      "Epoch: 11/84, Generator Loss: 9.590083122253418, Discriminator Loss: 0.04036898910999298\n",
      "Epoch: 12/84, Generator Loss: 4.653027057647705, Discriminator Loss: 0.06504790484905243\n",
      "Epoch: 13/84, Generator Loss: 19.74291229248047, Discriminator Loss: 0.18555916845798492\n",
      "Epoch: 14/84, Generator Loss: 4.375341415405273, Discriminator Loss: 0.20294325053691864\n",
      "Epoch: 15/84, Generator Loss: 5.077776908874512, Discriminator Loss: 0.07802420854568481\n",
      "Epoch: 16/84, Generator Loss: 5.018548965454102, Discriminator Loss: 0.025601979345083237\n",
      "Epoch: 17/84, Generator Loss: 6.235832691192627, Discriminator Loss: 0.09157762676477432\n",
      "Epoch: 18/84, Generator Loss: 9.5890531539917, Discriminator Loss: 0.04945520684123039\n",
      "Epoch: 19/84, Generator Loss: 6.431241989135742, Discriminator Loss: 0.03236496075987816\n",
      "Epoch: 20/84, Generator Loss: 7.372316837310791, Discriminator Loss: 0.010442892089486122\n",
      "Epoch: 21/84, Generator Loss: 7.165709495544434, Discriminator Loss: 0.0016065500676631927\n",
      "Epoch: 22/84, Generator Loss: 7.086601734161377, Discriminator Loss: 0.014684893190860748\n",
      "Epoch: 23/84, Generator Loss: 6.37046480178833, Discriminator Loss: 0.0027910135686397552\n",
      "Epoch: 24/84, Generator Loss: 6.690067291259766, Discriminator Loss: 0.029033571481704712\n",
      "Epoch: 25/84, Generator Loss: 6.258173942565918, Discriminator Loss: 0.006729059386998415\n",
      "Epoch: 26/84, Generator Loss: 20.272470474243164, Discriminator Loss: 0.1418057084083557\n",
      "Epoch: 27/84, Generator Loss: 15.58107852935791, Discriminator Loss: 0.002319952240213752\n",
      "Epoch: 28/84, Generator Loss: 6.659516334533691, Discriminator Loss: 0.025331279262900352\n",
      "Epoch: 29/84, Generator Loss: 6.318864345550537, Discriminator Loss: 0.009529168717563152\n",
      "Epoch: 30/84, Generator Loss: 2.244662046432495, Discriminator Loss: 5.14799165725708\n",
      "Epoch: 31/84, Generator Loss: 6.368072032928467, Discriminator Loss: 0.01007623691111803\n",
      "Epoch: 32/84, Generator Loss: 24.93067741394043, Discriminator Loss: 0.3466663658618927\n",
      "Epoch: 33/84, Generator Loss: 7.310103893280029, Discriminator Loss: 0.0019917613826692104\n",
      "Epoch: 34/84, Generator Loss: 6.086040496826172, Discriminator Loss: 0.005950151942670345\n",
      "Epoch: 35/84, Generator Loss: 6.995730400085449, Discriminator Loss: 0.0018639410845935345\n",
      "Epoch: 36/84, Generator Loss: 10.599113464355469, Discriminator Loss: 0.04225355386734009\n",
      "Epoch: 37/84, Generator Loss: 9.599334716796875, Discriminator Loss: 0.00020627028425224125\n",
      "Epoch: 38/84, Generator Loss: 33.29005813598633, Discriminator Loss: 6.497118010884151e-05\n",
      "Epoch: 39/84, Generator Loss: 30.327272415161133, Discriminator Loss: 6.067524736863561e-06\n",
      "Epoch: 40/84, Generator Loss: 11.021464347839355, Discriminator Loss: 3.1736835808260366e-05\n",
      "Epoch: 41/84, Generator Loss: 11.23690128326416, Discriminator Loss: 1.9174018234480172e-05\n",
      "Epoch: 42/84, Generator Loss: 11.022123336791992, Discriminator Loss: 6.597844185307622e-05\n",
      "Epoch: 43/84, Generator Loss: 12.523730278015137, Discriminator Loss: 1.0572794963081833e-05\n",
      "Epoch: 44/84, Generator Loss: 12.815694808959961, Discriminator Loss: 7.21704273018986e-05\n",
      "Epoch: 45/84, Generator Loss: 12.798036575317383, Discriminator Loss: 1.532227179268375e-05\n",
      "Epoch: 46/84, Generator Loss: 84.9878921508789, Discriminator Loss: 6.956714059924707e-05\n",
      "Epoch: 47/84, Generator Loss: 83.0267333984375, Discriminator Loss: 0.00013697345275431871\n",
      "Epoch: 48/84, Generator Loss: 82.3182144165039, Discriminator Loss: 3.8124767343106214e-06\n",
      "Epoch: 49/84, Generator Loss: 81.9127197265625, Discriminator Loss: 2.629681375765358e-06\n",
      "Epoch: 50/84, Generator Loss: 81.588623046875, Discriminator Loss: 2.4446060706395656e-05\n",
      "Epoch: 51/84, Generator Loss: 81.04866790771484, Discriminator Loss: 1.772152609191835e-05\n",
      "Epoch: 52/84, Generator Loss: 80.89726257324219, Discriminator Loss: 8.264703865279444e-06\n",
      "Epoch: 53/84, Generator Loss: 80.96968078613281, Discriminator Loss: 3.4969705211551627e-06\n",
      "Epoch: 54/84, Generator Loss: 80.70416259765625, Discriminator Loss: 2.4854555249476107e-06\n",
      "Epoch: 55/84, Generator Loss: 80.82395935058594, Discriminator Loss: 3.3362402973580174e-06\n",
      "Epoch: 56/84, Generator Loss: 80.87946319580078, Discriminator Loss: 3.926296267309226e-05\n",
      "Epoch: 57/84, Generator Loss: 80.39404296875, Discriminator Loss: 9.777269269761746e-07\n",
      "Epoch: 58/84, Generator Loss: 80.2535629272461, Discriminator Loss: 1.320617229794152e-05\n",
      "Epoch: 59/84, Generator Loss: 80.31668853759766, Discriminator Loss: 2.416978759356425e-06\n",
      "Epoch: 60/84, Generator Loss: 80.2010269165039, Discriminator Loss: 3.7177208014327334e-06\n",
      "Epoch: 61/84, Generator Loss: 80.09955596923828, Discriminator Loss: 3.750330961338477e-06\n",
      "Epoch: 62/84, Generator Loss: 79.92015075683594, Discriminator Loss: 3.756625517326029e-07\n",
      "Epoch: 63/84, Generator Loss: 79.96195983886719, Discriminator Loss: 4.571653335005976e-06\n",
      "Epoch: 64/84, Generator Loss: 79.724365234375, Discriminator Loss: 7.232789016597962e-07\n",
      "Epoch: 65/84, Generator Loss: 79.83826446533203, Discriminator Loss: 9.727158385430812e-07\n",
      "Epoch: 66/84, Generator Loss: 79.96354675292969, Discriminator Loss: 2.1257937987684272e-06\n",
      "Epoch: 67/84, Generator Loss: 80.02491760253906, Discriminator Loss: 1.5237172874549287e-06\n",
      "Epoch: 68/84, Generator Loss: 79.91185760498047, Discriminator Loss: 7.778972758387681e-06\n",
      "Epoch: 69/84, Generator Loss: 79.56731414794922, Discriminator Loss: 1.4986979977038573e-06\n",
      "Epoch: 70/84, Generator Loss: 79.79279327392578, Discriminator Loss: 2.5571653168299235e-06\n",
      "Epoch: 71/84, Generator Loss: 79.45677185058594, Discriminator Loss: 1.9945955500588752e-06\n",
      "Epoch: 72/84, Generator Loss: 79.73126220703125, Discriminator Loss: 4.570310011331458e-06\n",
      "Epoch: 73/84, Generator Loss: 79.49271392822266, Discriminator Loss: 1.0648948318703333e-06\n",
      "Epoch: 74/84, Generator Loss: 79.38724517822266, Discriminator Loss: 1.390022680425318e-05\n",
      "Epoch: 75/84, Generator Loss: 79.40631866455078, Discriminator Loss: 2.0867348666797625e-06\n",
      "Epoch: 76/84, Generator Loss: 79.5258560180664, Discriminator Loss: 1.6659872699165135e-06\n",
      "Epoch: 77/84, Generator Loss: 79.25021362304688, Discriminator Loss: 6.305375336523866e-06\n",
      "Epoch: 78/84, Generator Loss: 79.45764923095703, Discriminator Loss: 1.501745828136336e-06\n",
      "Epoch: 79/84, Generator Loss: 79.18075561523438, Discriminator Loss: 2.4904941255954327e-06\n",
      "Epoch: 80/84, Generator Loss: 79.1106948852539, Discriminator Loss: 2.67445875579142e-06\n",
      "Epoch: 81/84, Generator Loss: 79.5345230102539, Discriminator Loss: 4.916483703709673e-06\n",
      "Epoch: 82/84, Generator Loss: 79.30657958984375, Discriminator Loss: 9.576922366250074e-07\n",
      "Epoch: 83/84, Generator Loss: 79.3563232421875, Discriminator Loss: 1.2212226465635467e-06\n",
      "Epoch: 84/84, Generator Loss: 79.05992126464844, Discriminator Loss: 2.2940346866562322e-07\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 21.3497\n",
      "Function value obtained: -79.0599\n",
      "Current minimum: -79.0599\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "Epoch: 1/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 10.3692\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -79.0599\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "Epoch: 1/64, Generator Loss: 2.1660921573638916, Discriminator Loss: 0.6860308647155762\n",
      "Epoch: 2/64, Generator Loss: 4.76309061050415, Discriminator Loss: 0.19397114217281342\n",
      "Epoch: 3/64, Generator Loss: 5.68086051940918, Discriminator Loss: 0.1255306899547577\n",
      "Epoch: 4/64, Generator Loss: 8.355398178100586, Discriminator Loss: 0.008399670012295246\n",
      "Epoch: 5/64, Generator Loss: 7.748932838439941, Discriminator Loss: 0.002238266868516803\n",
      "Epoch: 6/64, Generator Loss: 8.267178535461426, Discriminator Loss: 0.03927678242325783\n",
      "Epoch: 7/64, Generator Loss: 8.573854446411133, Discriminator Loss: 0.004526963457465172\n",
      "Epoch: 8/64, Generator Loss: 6.533186912536621, Discriminator Loss: 0.052257418632507324\n",
      "Epoch: 9/64, Generator Loss: 10.208221435546875, Discriminator Loss: 0.0002312240394530818\n",
      "Epoch: 10/64, Generator Loss: 7.090350151062012, Discriminator Loss: 0.006080382037907839\n",
      "Epoch: 11/64, Generator Loss: 10.77696418762207, Discriminator Loss: 0.005103917792439461\n",
      "Epoch: 12/64, Generator Loss: 9.60462474822998, Discriminator Loss: 0.0015923308674246073\n",
      "Epoch: 13/64, Generator Loss: 8.657573699951172, Discriminator Loss: 0.00022357386478688568\n",
      "Epoch: 14/64, Generator Loss: 9.463973999023438, Discriminator Loss: 0.002640653168782592\n",
      "Epoch: 15/64, Generator Loss: 9.774081230163574, Discriminator Loss: 8.786618855083361e-05\n",
      "Epoch: 16/64, Generator Loss: 10.111783027648926, Discriminator Loss: 3.6435158108361065e-05\n",
      "Epoch: 17/64, Generator Loss: 9.618504524230957, Discriminator Loss: 0.00036810908932238817\n",
      "Epoch: 18/64, Generator Loss: 10.673112869262695, Discriminator Loss: 1.5963070836733095e-05\n",
      "Epoch: 19/64, Generator Loss: 11.398564338684082, Discriminator Loss: 0.0035734933335334063\n",
      "Epoch: 20/64, Generator Loss: 14.246094703674316, Discriminator Loss: 6.824867887189612e-05\n",
      "Epoch: 21/64, Generator Loss: 12.613617897033691, Discriminator Loss: 5.037928076490061e-06\n",
      "Epoch: 22/64, Generator Loss: 11.441474914550781, Discriminator Loss: 9.695118023955729e-06\n",
      "Epoch: 23/64, Generator Loss: 7.317995548248291, Discriminator Loss: 0.0011441914830356836\n",
      "Epoch: 24/64, Generator Loss: 10.638653755187988, Discriminator Loss: 0.009481924585998058\n",
      "Epoch: 25/64, Generator Loss: 18.565343856811523, Discriminator Loss: 2.102369035128504e-05\n",
      "Epoch: 26/64, Generator Loss: 12.172487258911133, Discriminator Loss: 0.0039020904805511236\n",
      "Epoch: 27/64, Generator Loss: 21.03485107421875, Discriminator Loss: 1.1116846332370756e-09\n",
      "Epoch: 28/64, Generator Loss: 10.62634563446045, Discriminator Loss: 0.0015155437868088484\n",
      "Epoch: 29/64, Generator Loss: 17.360342025756836, Discriminator Loss: 8.656008532170745e-08\n",
      "Epoch: 30/64, Generator Loss: 4.851145267486572, Discriminator Loss: 0.022366099059581757\n",
      "Epoch: 31/64, Generator Loss: 9.381399154663086, Discriminator Loss: 0.004789917729794979\n",
      "Epoch: 32/64, Generator Loss: 10.230125427246094, Discriminator Loss: 0.006456330418586731\n",
      "Epoch: 33/64, Generator Loss: 11.270852088928223, Discriminator Loss: 0.015974439680576324\n",
      "Epoch: 34/64, Generator Loss: 12.514965057373047, Discriminator Loss: 0.4380836486816406\n",
      "Epoch: 35/64, Generator Loss: 11.795228004455566, Discriminator Loss: 0.009831811301410198\n",
      "Epoch: 36/64, Generator Loss: 6.023400783538818, Discriminator Loss: 0.12241637706756592\n",
      "Epoch: 37/64, Generator Loss: 10.599514961242676, Discriminator Loss: 0.007350101135671139\n",
      "Epoch: 38/64, Generator Loss: 10.677689552307129, Discriminator Loss: 0.03410650044679642\n",
      "Epoch: 39/64, Generator Loss: 14.188477516174316, Discriminator Loss: 0.05796211212873459\n",
      "Epoch: 40/64, Generator Loss: 8.908917427062988, Discriminator Loss: 0.004177606198936701\n",
      "Epoch: 41/64, Generator Loss: 14.02408504486084, Discriminator Loss: 0.15880316495895386\n",
      "Epoch: 42/64, Generator Loss: 9.93418025970459, Discriminator Loss: 0.03739163652062416\n",
      "Epoch: 43/64, Generator Loss: 15.13049602508545, Discriminator Loss: 0.0009446030599065125\n",
      "Epoch: 44/64, Generator Loss: 35.90139389038086, Discriminator Loss: 1.2021111217563885e-08\n",
      "Epoch: 45/64, Generator Loss: 19.614912033081055, Discriminator Loss: 0.0003573209105525166\n",
      "Epoch: 46/64, Generator Loss: 23.23687744140625, Discriminator Loss: 0.10769083350896835\n",
      "Epoch: 47/64, Generator Loss: 17.66122055053711, Discriminator Loss: 0.04534665122628212\n",
      "Epoch: 48/64, Generator Loss: 6.572269916534424, Discriminator Loss: 0.01483808271586895\n",
      "Epoch: 49/64, Generator Loss: 9.59640121459961, Discriminator Loss: 0.031127840280532837\n",
      "Epoch: 50/64, Generator Loss: 10.013418197631836, Discriminator Loss: 0.000565354130230844\n",
      "Epoch: 51/64, Generator Loss: 7.682580947875977, Discriminator Loss: 0.0008641634485684335\n",
      "Epoch: 52/64, Generator Loss: 7.119540214538574, Discriminator Loss: 0.0014507861342281103\n",
      "Epoch: 53/64, Generator Loss: 26.820058822631836, Discriminator Loss: 0.062331896275281906\n",
      "Epoch: 54/64, Generator Loss: 11.669709205627441, Discriminator Loss: 0.06486443430185318\n",
      "Epoch: 55/64, Generator Loss: 22.966814041137695, Discriminator Loss: 0.6429597735404968\n",
      "Epoch: 56/64, Generator Loss: 10.606121063232422, Discriminator Loss: 0.00031071604462340474\n",
      "Epoch: 57/64, Generator Loss: 14.526952743530273, Discriminator Loss: 0.0008252813131548464\n",
      "Epoch: 58/64, Generator Loss: 9.172253608703613, Discriminator Loss: 0.0012344690039753914\n",
      "Epoch: 59/64, Generator Loss: 35.27220916748047, Discriminator Loss: 1.0445815860293806e-05\n",
      "Epoch: 60/64, Generator Loss: 19.069923400878906, Discriminator Loss: 6.527442110382253e-06\n",
      "Epoch: 61/64, Generator Loss: 16.894437789916992, Discriminator Loss: 1.0795389471240924e-07\n",
      "Epoch: 62/64, Generator Loss: 8.52169418334961, Discriminator Loss: 0.00023933373449835926\n",
      "Epoch: 63/64, Generator Loss: 8.619146347045898, Discriminator Loss: 0.0003513786941766739\n",
      "Epoch: 64/64, Generator Loss: 15.321172714233398, Discriminator Loss: 1.7394595488440245e-06\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 17.8168\n",
      "Function value obtained: -15.3212\n",
      "Current minimum: -79.0599\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Epoch: 1/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/93, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 23.1070\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -79.0599\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Epoch: 1/84, Generator Loss: 1.0169072151184082, Discriminator Loss: 0.9808196425437927\n",
      "Epoch: 2/84, Generator Loss: 6.1039252281188965, Discriminator Loss: 0.0354006290435791\n",
      "Epoch: 3/84, Generator Loss: 4.0820159912109375, Discriminator Loss: 0.04785479977726936\n",
      "Epoch: 4/84, Generator Loss: 7.768825054168701, Discriminator Loss: 0.0027468050830066204\n",
      "Epoch: 5/84, Generator Loss: 5.117733478546143, Discriminator Loss: 0.16499805450439453\n",
      "Epoch: 6/84, Generator Loss: 5.754446983337402, Discriminator Loss: 0.0262696985155344\n",
      "Epoch: 7/84, Generator Loss: 6.1327900886535645, Discriminator Loss: 0.5386226773262024\n",
      "Epoch: 8/84, Generator Loss: 5.709848403930664, Discriminator Loss: 0.008784274570643902\n",
      "Epoch: 9/84, Generator Loss: 6.446292877197266, Discriminator Loss: 0.09511934220790863\n",
      "Epoch: 10/84, Generator Loss: 5.339347839355469, Discriminator Loss: 0.029783066362142563\n",
      "Epoch: 11/84, Generator Loss: 6.993963718414307, Discriminator Loss: 0.014667967334389687\n",
      "Epoch: 12/84, Generator Loss: 6.821699142456055, Discriminator Loss: 0.011463731527328491\n",
      "Epoch: 13/84, Generator Loss: 6.780478000640869, Discriminator Loss: 0.030762305483222008\n",
      "Epoch: 14/84, Generator Loss: 8.165002822875977, Discriminator Loss: 0.004107789136469364\n",
      "Epoch: 15/84, Generator Loss: 5.87080192565918, Discriminator Loss: 0.06466599553823471\n",
      "Epoch: 16/84, Generator Loss: 10.556622505187988, Discriminator Loss: 0.009878505952656269\n",
      "Epoch: 17/84, Generator Loss: 9.414155960083008, Discriminator Loss: 0.010296080261468887\n",
      "Epoch: 18/84, Generator Loss: 11.276880264282227, Discriminator Loss: 0.1414080560207367\n",
      "Epoch: 19/84, Generator Loss: 9.711746215820312, Discriminator Loss: 0.15879733860492706\n",
      "Epoch: 20/84, Generator Loss: 10.533835411071777, Discriminator Loss: 0.7228376269340515\n",
      "Epoch: 21/84, Generator Loss: 11.591341972351074, Discriminator Loss: 0.01903514377772808\n",
      "Epoch: 22/84, Generator Loss: 12.44941234588623, Discriminator Loss: 0.13614629209041595\n",
      "Epoch: 23/84, Generator Loss: 7.0121002197265625, Discriminator Loss: 0.03378941863775253\n",
      "Epoch: 24/84, Generator Loss: 34.01931381225586, Discriminator Loss: 0.2784374952316284\n",
      "Epoch: 25/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 21.3056\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -79.0599\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Epoch: 1/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/85, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 21.4402\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -79.0599\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Epoch: 1/62, Generator Loss: 1.0327425003051758, Discriminator Loss: 1.048244833946228\n",
      "Epoch: 2/62, Generator Loss: 1.1070350408554077, Discriminator Loss: 1.310708999633789\n",
      "Epoch: 3/62, Generator Loss: 2.6144702434539795, Discriminator Loss: 0.8991120457649231\n",
      "Epoch: 4/62, Generator Loss: 2.117330551147461, Discriminator Loss: 0.45381128787994385\n",
      "Epoch: 5/62, Generator Loss: 3.2765467166900635, Discriminator Loss: 0.5717830657958984\n",
      "Epoch: 6/62, Generator Loss: 3.1624321937561035, Discriminator Loss: 0.2947559356689453\n",
      "Epoch: 7/62, Generator Loss: 2.172855854034424, Discriminator Loss: 0.5245863199234009\n",
      "Epoch: 8/62, Generator Loss: 3.1682591438293457, Discriminator Loss: 1.6426758766174316\n",
      "Epoch: 9/62, Generator Loss: 3.8796048164367676, Discriminator Loss: 0.23254215717315674\n",
      "Epoch: 10/62, Generator Loss: 3.2294211387634277, Discriminator Loss: 0.1396133154630661\n",
      "Epoch: 11/62, Generator Loss: 3.014545202255249, Discriminator Loss: 0.3591576814651489\n",
      "Epoch: 12/62, Generator Loss: 2.5265989303588867, Discriminator Loss: 0.26432865858078003\n",
      "Epoch: 13/62, Generator Loss: 5.299864292144775, Discriminator Loss: 0.19663101434707642\n",
      "Epoch: 14/62, Generator Loss: 3.0988149642944336, Discriminator Loss: 0.2625630795955658\n",
      "Epoch: 15/62, Generator Loss: 4.578709125518799, Discriminator Loss: 0.08254100382328033\n",
      "Epoch: 16/62, Generator Loss: 5.201533317565918, Discriminator Loss: 0.09600913524627686\n",
      "Epoch: 17/62, Generator Loss: 3.714704990386963, Discriminator Loss: 0.0645027756690979\n",
      "Epoch: 18/62, Generator Loss: 4.546377182006836, Discriminator Loss: 0.08639556169509888\n",
      "Epoch: 19/62, Generator Loss: 4.359284400939941, Discriminator Loss: 0.11269069463014603\n",
      "Epoch: 20/62, Generator Loss: 4.090927600860596, Discriminator Loss: 0.06974257528781891\n",
      "Epoch: 21/62, Generator Loss: 4.635008811950684, Discriminator Loss: 0.11542055010795593\n",
      "Epoch: 22/62, Generator Loss: 4.062789440155029, Discriminator Loss: 0.1070890724658966\n",
      "Epoch: 23/62, Generator Loss: 5.1656270027160645, Discriminator Loss: 0.02245117537677288\n",
      "Epoch: 24/62, Generator Loss: 6.3739705085754395, Discriminator Loss: 0.00394775252789259\n",
      "Epoch: 25/62, Generator Loss: 5.0904316902160645, Discriminator Loss: 0.026720166206359863\n",
      "Epoch: 26/62, Generator Loss: 5.077244758605957, Discriminator Loss: 0.0277448371052742\n",
      "Epoch: 27/62, Generator Loss: 5.506558895111084, Discriminator Loss: 0.02277904935181141\n",
      "Epoch: 28/62, Generator Loss: 5.766853332519531, Discriminator Loss: 0.020631704479455948\n",
      "Epoch: 29/62, Generator Loss: 6.530323505401611, Discriminator Loss: 0.003933423664420843\n",
      "Epoch: 30/62, Generator Loss: 5.779790878295898, Discriminator Loss: 0.025525886565446854\n",
      "Epoch: 31/62, Generator Loss: 4.935859203338623, Discriminator Loss: 0.04595501720905304\n",
      "Epoch: 32/62, Generator Loss: 5.52250337600708, Discriminator Loss: 0.02304653450846672\n",
      "Epoch: 33/62, Generator Loss: 5.1884589195251465, Discriminator Loss: 0.012904872186481953\n",
      "Epoch: 34/62, Generator Loss: 5.197610855102539, Discriminator Loss: 0.018640916794538498\n",
      "Epoch: 35/62, Generator Loss: 5.3379669189453125, Discriminator Loss: 0.01272232923656702\n",
      "Epoch: 36/62, Generator Loss: 5.4321608543396, Discriminator Loss: 0.018516087904572487\n",
      "Epoch: 37/62, Generator Loss: 6.090030193328857, Discriminator Loss: 0.017486467957496643\n",
      "Epoch: 38/62, Generator Loss: 7.922770023345947, Discriminator Loss: 0.0009344721329398453\n",
      "Epoch: 39/62, Generator Loss: 8.142516136169434, Discriminator Loss: 0.0018347753211855888\n",
      "Epoch: 40/62, Generator Loss: 8.801048278808594, Discriminator Loss: 0.0005794226890429854\n",
      "Epoch: 41/62, Generator Loss: 9.521513938903809, Discriminator Loss: 0.0001901596406241879\n",
      "Epoch: 42/62, Generator Loss: 9.019876480102539, Discriminator Loss: 0.0006594514707103372\n",
      "Epoch: 43/62, Generator Loss: 9.569107055664062, Discriminator Loss: 0.00015902426093816757\n",
      "Epoch: 44/62, Generator Loss: 9.883257865905762, Discriminator Loss: 0.00025088703841902316\n",
      "Epoch: 45/62, Generator Loss: 10.017145156860352, Discriminator Loss: 0.00017296214355155826\n",
      "Epoch: 46/62, Generator Loss: 10.498988151550293, Discriminator Loss: 0.0001002523276838474\n",
      "Epoch: 47/62, Generator Loss: 7.7679853439331055, Discriminator Loss: 0.0010210992768406868\n",
      "Epoch: 48/62, Generator Loss: 7.243896961212158, Discriminator Loss: 0.002045790199190378\n",
      "Epoch: 49/62, Generator Loss: 16.351276397705078, Discriminator Loss: 0.3028636872768402\n",
      "Epoch: 50/62, Generator Loss: 5.718499183654785, Discriminator Loss: 0.005825415253639221\n",
      "Epoch: 51/62, Generator Loss: 5.792873859405518, Discriminator Loss: 0.019876383244991302\n",
      "Epoch: 52/62, Generator Loss: 5.565360069274902, Discriminator Loss: 0.016758333891630173\n",
      "Epoch: 53/62, Generator Loss: 7.523369312286377, Discriminator Loss: 0.02300712838768959\n",
      "Epoch: 54/62, Generator Loss: 7.7451863288879395, Discriminator Loss: 0.0005858353106305003\n",
      "Epoch: 55/62, Generator Loss: 6.54407262802124, Discriminator Loss: 0.003686104202643037\n",
      "Epoch: 56/62, Generator Loss: 8.590410232543945, Discriminator Loss: 0.0004315366386435926\n",
      "Epoch: 57/62, Generator Loss: 9.216753005981445, Discriminator Loss: 0.001381905865855515\n",
      "Epoch: 58/62, Generator Loss: 9.25500774383545, Discriminator Loss: 0.00037539354525506496\n",
      "Epoch: 59/62, Generator Loss: 9.631331443786621, Discriminator Loss: 0.0003624727251008153\n",
      "Epoch: 60/62, Generator Loss: 9.76628589630127, Discriminator Loss: 0.0003683114191517234\n",
      "Epoch: 61/62, Generator Loss: 10.0067720413208, Discriminator Loss: 7.643544086022303e-05\n",
      "Epoch: 62/62, Generator Loss: 9.425954818725586, Discriminator Loss: 0.00013096441398374736\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 17.7753\n",
      "Function value obtained: -9.4260\n",
      "Current minimum: -79.0599\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Epoch: 1/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 17.3779\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -79.0599\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Epoch: 1/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 22.9380\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -79.0599\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Epoch: 1/72, Generator Loss: 0.7099449634552002, Discriminator Loss: 5.988065719604492\n",
      "Epoch: 2/72, Generator Loss: 1.4270678758621216, Discriminator Loss: 1.6619641780853271\n",
      "Epoch: 3/72, Generator Loss: 0.8430091142654419, Discriminator Loss: 1.4910805225372314\n",
      "Epoch: 4/72, Generator Loss: 1.20498788356781, Discriminator Loss: 1.117325782775879\n",
      "Epoch: 5/72, Generator Loss: 0.7316949367523193, Discriminator Loss: 1.283063292503357\n",
      "Epoch: 6/72, Generator Loss: 0.7476360201835632, Discriminator Loss: 1.4157721996307373\n",
      "Epoch: 7/72, Generator Loss: 0.8070738315582275, Discriminator Loss: 1.3857345581054688\n",
      "Epoch: 8/72, Generator Loss: 1.571656346321106, Discriminator Loss: 1.5011296272277832\n",
      "Epoch: 9/72, Generator Loss: 0.9607628583908081, Discriminator Loss: 1.6523425579071045\n",
      "Epoch: 10/72, Generator Loss: 0.7593422532081604, Discriminator Loss: 1.0384553670883179\n",
      "Epoch: 11/72, Generator Loss: 1.625576376914978, Discriminator Loss: 1.0490578413009644\n",
      "Epoch: 12/72, Generator Loss: 3.2754743099212646, Discriminator Loss: 0.7058825492858887\n",
      "Epoch: 13/72, Generator Loss: 43.47361755371094, Discriminator Loss: 0.0006604913505725563\n",
      "Epoch: 14/72, Generator Loss: 45.92094039916992, Discriminator Loss: 0.00024102845054585487\n",
      "Epoch: 15/72, Generator Loss: 44.169715881347656, Discriminator Loss: 0.00018159205501433462\n",
      "Epoch: 16/72, Generator Loss: 44.01295471191406, Discriminator Loss: 0.0001224830630235374\n",
      "Epoch: 17/72, Generator Loss: 41.43857955932617, Discriminator Loss: 0.00011226607603020966\n",
      "Epoch: 18/72, Generator Loss: 40.981101989746094, Discriminator Loss: 0.00011955856462009251\n",
      "Epoch: 19/72, Generator Loss: 40.5156364440918, Discriminator Loss: 8.365757821593434e-05\n",
      "Epoch: 20/72, Generator Loss: 35.770992279052734, Discriminator Loss: 0.0001014053777907975\n",
      "Epoch: 21/72, Generator Loss: 64.50337982177734, Discriminator Loss: 8.06922180345282e-05\n",
      "Epoch: 22/72, Generator Loss: 7.5923686027526855, Discriminator Loss: 0.7668678164482117\n",
      "Epoch: 23/72, Generator Loss: 11.003273010253906, Discriminator Loss: 0.053466204553842545\n",
      "Epoch: 24/72, Generator Loss: 7.848097801208496, Discriminator Loss: 0.0019081290811300278\n",
      "Epoch: 25/72, Generator Loss: 9.050000190734863, Discriminator Loss: 0.00025140694924630225\n",
      "Epoch: 26/72, Generator Loss: 9.201800346374512, Discriminator Loss: 0.00019118750060442835\n",
      "Epoch: 27/72, Generator Loss: 9.558748245239258, Discriminator Loss: 0.00019180390518158674\n",
      "Epoch: 28/72, Generator Loss: 9.57105541229248, Discriminator Loss: 0.0001787221699487418\n",
      "Epoch: 29/72, Generator Loss: 9.828383445739746, Discriminator Loss: 0.00012607246753759682\n",
      "Epoch: 30/72, Generator Loss: 10.079034805297852, Discriminator Loss: 6.624024535994977e-05\n",
      "Epoch: 31/72, Generator Loss: 10.256275177001953, Discriminator Loss: 6.428090273402631e-05\n",
      "Epoch: 32/72, Generator Loss: 10.391783714294434, Discriminator Loss: 6.09834969509393e-05\n",
      "Epoch: 33/72, Generator Loss: 10.578099250793457, Discriminator Loss: 0.00014495394134428352\n",
      "Epoch: 34/72, Generator Loss: 10.703521728515625, Discriminator Loss: 4.4478227209765464e-05\n",
      "Epoch: 35/72, Generator Loss: 10.785649299621582, Discriminator Loss: 6.0542733990587294e-05\n",
      "Epoch: 36/72, Generator Loss: 10.937211990356445, Discriminator Loss: 4.057737533003092e-05\n",
      "Epoch: 37/72, Generator Loss: 11.018532752990723, Discriminator Loss: 4.629075192497112e-05\n",
      "Epoch: 38/72, Generator Loss: 11.156949996948242, Discriminator Loss: 8.14504164736718e-05\n",
      "Epoch: 39/72, Generator Loss: 11.220629692077637, Discriminator Loss: 5.777975820819847e-05\n",
      "Epoch: 40/72, Generator Loss: 11.333096504211426, Discriminator Loss: 2.131554538209457e-05\n",
      "Epoch: 41/72, Generator Loss: 11.408355712890625, Discriminator Loss: 3.1231385946739465e-05\n",
      "Epoch: 42/72, Generator Loss: 11.496613502502441, Discriminator Loss: 4.040964995510876e-05\n",
      "Epoch: 43/72, Generator Loss: 11.579863548278809, Discriminator Loss: 2.0147865143371746e-05\n",
      "Epoch: 44/72, Generator Loss: 11.665818214416504, Discriminator Loss: 1.3904244951845612e-05\n",
      "Epoch: 45/72, Generator Loss: 11.732616424560547, Discriminator Loss: 3.7679230445064604e-05\n",
      "Epoch: 46/72, Generator Loss: 11.80871295928955, Discriminator Loss: 1.6892743587959558e-05\n",
      "Epoch: 47/72, Generator Loss: 11.88858413696289, Discriminator Loss: 2.4702821974642575e-05\n",
      "Epoch: 48/72, Generator Loss: 11.9524507522583, Discriminator Loss: 2.2015683498466387e-05\n",
      "Epoch: 49/72, Generator Loss: 12.019404411315918, Discriminator Loss: 1.4398450730368495e-05\n",
      "Epoch: 50/72, Generator Loss: 10.600929260253906, Discriminator Loss: 5.395638436311856e-05\n",
      "Epoch: 51/72, Generator Loss: 10.709723472595215, Discriminator Loss: 2.932419374701567e-05\n",
      "Epoch: 52/72, Generator Loss: 10.999251365661621, Discriminator Loss: 2.852529360097833e-05\n",
      "Epoch: 53/72, Generator Loss: 12.477404594421387, Discriminator Loss: 3.5746714274864644e-05\n",
      "Epoch: 54/72, Generator Loss: 7.481933116912842, Discriminator Loss: 0.17741568386554718\n",
      "Epoch: 55/72, Generator Loss: 23.447126388549805, Discriminator Loss: 5.620456633437243e-08\n",
      "Epoch: 56/72, Generator Loss: 19.895668029785156, Discriminator Loss: 5.103084177449091e-09\n",
      "Epoch: 57/72, Generator Loss: 19.205045700073242, Discriminator Loss: 8.10132547712783e-08\n",
      "Epoch: 58/72, Generator Loss: 13.623994827270508, Discriminator Loss: 2.1096009277243866e-06\n",
      "Epoch: 59/72, Generator Loss: 14.795051574707031, Discriminator Loss: 6.262632155085157e-07\n",
      "Epoch: 60/72, Generator Loss: 15.421744346618652, Discriminator Loss: 3.4329502796026645e-07\n",
      "Epoch: 61/72, Generator Loss: 15.650114059448242, Discriminator Loss: 2.6228082106172224e-07\n",
      "Epoch: 62/72, Generator Loss: 16.100261688232422, Discriminator Loss: 1.9331857004090125e-07\n",
      "Epoch: 63/72, Generator Loss: 15.394867897033691, Discriminator Loss: 3.6635310607380234e-07\n",
      "Epoch: 64/72, Generator Loss: 15.693521499633789, Discriminator Loss: 2.6773014383252303e-07\n",
      "Epoch: 65/72, Generator Loss: 15.928793907165527, Discriminator Loss: 2.3197839027488953e-07\n",
      "Epoch: 66/72, Generator Loss: 14.78352165222168, Discriminator Loss: 9.019506705953972e-07\n",
      "Epoch: 67/72, Generator Loss: 16.209152221679688, Discriminator Loss: 2.0881979878595303e-07\n",
      "Epoch: 68/72, Generator Loss: 16.28531265258789, Discriminator Loss: 1.5778361728280288e-07\n",
      "Epoch: 69/72, Generator Loss: 16.384662628173828, Discriminator Loss: 1.4491612887468364e-07\n",
      "Epoch: 70/72, Generator Loss: 16.662715911865234, Discriminator Loss: 1.1124367205184171e-07\n",
      "Epoch: 71/72, Generator Loss: 16.8732967376709, Discriminator Loss: 8.733315581821444e-08\n",
      "Epoch: 72/72, Generator Loss: 16.78968620300293, Discriminator Loss: 8.566235010221135e-08\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 19.4001\n",
      "Function value obtained: -16.7897\n",
      "Current minimum: -79.0599\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Epoch: 1/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 95/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 96/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 26.1488\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -79.0599\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Epoch: 1/98, Generator Loss: 3.55800724029541, Discriminator Loss: 0.3402588963508606\n",
      "Epoch: 2/98, Generator Loss: 5.318444728851318, Discriminator Loss: 0.039687879383563995\n",
      "Epoch: 3/98, Generator Loss: 4.043096542358398, Discriminator Loss: 1.278936743736267\n",
      "Epoch: 4/98, Generator Loss: 8.080604553222656, Discriminator Loss: 0.0043923379853367805\n",
      "Epoch: 5/98, Generator Loss: 8.269967079162598, Discriminator Loss: 0.002000347711145878\n",
      "Epoch: 6/98, Generator Loss: 5.841912269592285, Discriminator Loss: 0.021539829671382904\n",
      "Epoch: 7/98, Generator Loss: 8.064055442810059, Discriminator Loss: 0.0023050245363265276\n",
      "Epoch: 8/98, Generator Loss: 11.23717212677002, Discriminator Loss: 0.014630576595664024\n",
      "Epoch: 9/98, Generator Loss: 4.859929084777832, Discriminator Loss: 0.03478902578353882\n",
      "Epoch: 10/98, Generator Loss: 5.859798431396484, Discriminator Loss: 0.009014522656798363\n",
      "Epoch: 11/98, Generator Loss: 5.3694939613342285, Discriminator Loss: 0.01875896565616131\n",
      "Epoch: 12/98, Generator Loss: 7.170636177062988, Discriminator Loss: 0.0034205387346446514\n",
      "Epoch: 13/98, Generator Loss: 8.97814655303955, Discriminator Loss: 0.017086487263441086\n",
      "Epoch: 14/98, Generator Loss: 5.5295257568359375, Discriminator Loss: 0.030453737825155258\n",
      "Epoch: 15/98, Generator Loss: 6.4609479904174805, Discriminator Loss: 0.003918302245438099\n",
      "Epoch: 16/98, Generator Loss: 6.023786544799805, Discriminator Loss: 0.015823669731616974\n",
      "Epoch: 17/98, Generator Loss: 6.73085880279541, Discriminator Loss: 0.002416009083390236\n",
      "Epoch: 18/98, Generator Loss: 7.12129020690918, Discriminator Loss: 0.002061291364952922\n",
      "Epoch: 19/98, Generator Loss: 7.292439937591553, Discriminator Loss: 0.0010388668160885572\n",
      "Epoch: 20/98, Generator Loss: 8.074416160583496, Discriminator Loss: 0.0007926551625132561\n",
      "Epoch: 21/98, Generator Loss: 7.603422164916992, Discriminator Loss: 0.001346064731478691\n",
      "Epoch: 22/98, Generator Loss: 7.731703758239746, Discriminator Loss: 0.0007210597977973521\n",
      "Epoch: 23/98, Generator Loss: 8.320337295532227, Discriminator Loss: 0.0002956381067633629\n",
      "Epoch: 24/98, Generator Loss: 9.267297744750977, Discriminator Loss: 0.00038693618262186646\n",
      "Epoch: 25/98, Generator Loss: 9.204014778137207, Discriminator Loss: 0.00015992597036529332\n",
      "Epoch: 26/98, Generator Loss: 10.112082481384277, Discriminator Loss: 0.00011886493302881718\n",
      "Epoch: 27/98, Generator Loss: 10.285089492797852, Discriminator Loss: 5.444058115244843e-05\n",
      "Epoch: 28/98, Generator Loss: 7.938906669616699, Discriminator Loss: 0.0011907515581697226\n",
      "Epoch: 29/98, Generator Loss: 11.55230712890625, Discriminator Loss: 0.0005342660588212311\n",
      "Epoch: 30/98, Generator Loss: 10.097734451293945, Discriminator Loss: 0.00018879465642385185\n",
      "Epoch: 31/98, Generator Loss: 10.26083755493164, Discriminator Loss: 0.00016702633001841605\n",
      "Epoch: 32/98, Generator Loss: 11.02994155883789, Discriminator Loss: 0.00010123890388058499\n",
      "Epoch: 33/98, Generator Loss: 11.525802612304688, Discriminator Loss: 2.461868461978156e-05\n",
      "Epoch: 34/98, Generator Loss: 10.558222770690918, Discriminator Loss: 7.184824789874256e-05\n",
      "Epoch: 35/98, Generator Loss: 11.540690422058105, Discriminator Loss: 6.170529377413914e-05\n",
      "Epoch: 36/98, Generator Loss: 11.492291450500488, Discriminator Loss: 2.935415250249207e-05\n",
      "Epoch: 37/98, Generator Loss: 10.768830299377441, Discriminator Loss: 3.4350319765508175e-05\n",
      "Epoch: 38/98, Generator Loss: 7.304816246032715, Discriminator Loss: 0.0014801648212596774\n",
      "Epoch: 39/98, Generator Loss: 7.672168731689453, Discriminator Loss: 0.0010157952783629298\n",
      "Epoch: 40/98, Generator Loss: 9.236164093017578, Discriminator Loss: 9.553804557071999e-05\n",
      "Epoch: 41/98, Generator Loss: 7.77373743057251, Discriminator Loss: 0.00048825881094671786\n",
      "Epoch: 42/98, Generator Loss: 9.641111373901367, Discriminator Loss: 7.499667117372155e-05\n",
      "Epoch: 43/98, Generator Loss: 9.757013320922852, Discriminator Loss: 6.852085061836988e-05\n",
      "Epoch: 44/98, Generator Loss: 10.433382034301758, Discriminator Loss: 7.747478230157867e-05\n",
      "Epoch: 45/98, Generator Loss: 10.634868621826172, Discriminator Loss: 3.081397517235018e-05\n",
      "Epoch: 46/98, Generator Loss: 8.841292381286621, Discriminator Loss: 0.0003319271490909159\n",
      "Epoch: 47/98, Generator Loss: 9.745122909545898, Discriminator Loss: 0.00016163589316420257\n",
      "Epoch: 48/98, Generator Loss: 8.772520065307617, Discriminator Loss: 0.00033074384555220604\n",
      "Epoch: 49/98, Generator Loss: 8.8466215133667, Discriminator Loss: 0.0001625168661121279\n",
      "Epoch: 50/98, Generator Loss: 9.809186935424805, Discriminator Loss: 6.733519694535062e-05\n",
      "Epoch: 51/98, Generator Loss: 9.839628219604492, Discriminator Loss: 5.9410765970824286e-05\n",
      "Epoch: 52/98, Generator Loss: 9.789111137390137, Discriminator Loss: 0.002098520053550601\n",
      "Epoch: 53/98, Generator Loss: 10.094310760498047, Discriminator Loss: 5.768949267803691e-05\n",
      "Epoch: 54/98, Generator Loss: 10.390599250793457, Discriminator Loss: 3.288171501480974e-05\n",
      "Epoch: 55/98, Generator Loss: 10.808806419372559, Discriminator Loss: 2.7994310585199855e-05\n",
      "Epoch: 56/98, Generator Loss: 10.909236907958984, Discriminator Loss: 2.1023883164161816e-05\n",
      "Epoch: 57/98, Generator Loss: 11.109511375427246, Discriminator Loss: 1.7063804989447817e-05\n",
      "Epoch: 58/98, Generator Loss: 11.222773551940918, Discriminator Loss: 2.2646388970315456e-05\n",
      "Epoch: 59/98, Generator Loss: 11.337435722351074, Discriminator Loss: 1.2656902072194498e-05\n",
      "Epoch: 60/98, Generator Loss: 11.472297668457031, Discriminator Loss: 1.146641716331942e-05\n",
      "Epoch: 61/98, Generator Loss: 11.535462379455566, Discriminator Loss: 3.0929266358725727e-05\n",
      "Epoch: 62/98, Generator Loss: 11.631153106689453, Discriminator Loss: 1.0213675523118582e-05\n",
      "Epoch: 63/98, Generator Loss: 11.775901794433594, Discriminator Loss: 8.890587196219712e-06\n",
      "Epoch: 64/98, Generator Loss: 11.825511932373047, Discriminator Loss: 8.347535185748711e-06\n",
      "Epoch: 65/98, Generator Loss: 11.872116088867188, Discriminator Loss: 1.2245779544173274e-05\n",
      "Epoch: 66/98, Generator Loss: 10.465871810913086, Discriminator Loss: 6.180258060339838e-05\n",
      "Epoch: 67/98, Generator Loss: 11.410442352294922, Discriminator Loss: 1.38306240842212e-05\n",
      "Epoch: 68/98, Generator Loss: 11.55173397064209, Discriminator Loss: 1.1194861144758761e-05\n",
      "Epoch: 69/98, Generator Loss: 11.803852081298828, Discriminator Loss: 1.0270923667121679e-05\n",
      "Epoch: 70/98, Generator Loss: 11.849353790283203, Discriminator Loss: 8.32975911180256e-06\n",
      "Epoch: 71/98, Generator Loss: 12.035418510437012, Discriminator Loss: 7.041722255962668e-06\n",
      "Epoch: 72/98, Generator Loss: 12.127175331115723, Discriminator Loss: 6.102342467784183e-06\n",
      "Epoch: 73/98, Generator Loss: 11.323172569274902, Discriminator Loss: 1.61715015565278e-05\n",
      "Epoch: 74/98, Generator Loss: 11.624065399169922, Discriminator Loss: 1.0102577107318211e-05\n",
      "Epoch: 75/98, Generator Loss: 11.887718200683594, Discriminator Loss: 1.706334478512872e-05\n",
      "Epoch: 76/98, Generator Loss: 11.444286346435547, Discriminator Loss: 1.3319784557097591e-05\n",
      "Epoch: 77/98, Generator Loss: 11.423758506774902, Discriminator Loss: 1.5812878700671718e-05\n",
      "Epoch: 78/98, Generator Loss: 11.713171005249023, Discriminator Loss: 5.7551689678803086e-05\n",
      "Epoch: 79/98, Generator Loss: 10.609382629394531, Discriminator Loss: 3.544176070136018e-05\n",
      "Epoch: 80/98, Generator Loss: 11.53093433380127, Discriminator Loss: 2.209194644819945e-05\n",
      "Epoch: 81/98, Generator Loss: 11.29342269897461, Discriminator Loss: 2.795094042085111e-05\n",
      "Epoch: 82/98, Generator Loss: 12.021156311035156, Discriminator Loss: 7.027463652775623e-06\n",
      "Epoch: 83/98, Generator Loss: 11.21328067779541, Discriminator Loss: 1.6389531083405018e-05\n",
      "Epoch: 84/98, Generator Loss: 11.479559898376465, Discriminator Loss: 1.5576264559058473e-05\n",
      "Epoch: 85/98, Generator Loss: 12.256767272949219, Discriminator Loss: 7.163480404415168e-06\n",
      "Epoch: 86/98, Generator Loss: 12.571907043457031, Discriminator Loss: 4.337535301601747e-06\n",
      "Epoch: 87/98, Generator Loss: 13.011606216430664, Discriminator Loss: 2.6187569801550126e-06\n",
      "Epoch: 88/98, Generator Loss: 13.164596557617188, Discriminator Loss: 6.9480079218919855e-06\n",
      "Epoch: 89/98, Generator Loss: 13.302191734313965, Discriminator Loss: 1.9497942957968917e-06\n",
      "Epoch: 90/98, Generator Loss: 13.456841468811035, Discriminator Loss: 6.886936262162635e-06\n",
      "Epoch: 91/98, Generator Loss: 13.601224899291992, Discriminator Loss: 1.4490464081973187e-06\n",
      "Epoch: 92/98, Generator Loss: 13.711926460266113, Discriminator Loss: 1.4304022215583245e-06\n",
      "Epoch: 93/98, Generator Loss: 13.832569122314453, Discriminator Loss: 1.466076582801179e-06\n",
      "Epoch: 94/98, Generator Loss: 13.910480499267578, Discriminator Loss: 1.3972467058920301e-06\n",
      "Epoch: 95/98, Generator Loss: 14.026265144348145, Discriminator Loss: 3.9464503061026335e-06\n",
      "Epoch: 96/98, Generator Loss: 14.058955192565918, Discriminator Loss: 3.418365167817683e-06\n",
      "Epoch: 97/98, Generator Loss: 14.196420669555664, Discriminator Loss: 2.358128995183506e-06\n",
      "Epoch: 98/98, Generator Loss: 14.296802520751953, Discriminator Loss: 1.694163302090601e-06\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 28.1134\n",
      "Function value obtained: -14.2968\n",
      "Current minimum: -79.0599\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Epoch: 1/40, Generator Loss: 0.0, Discriminator Loss: 100.21649169921875\n",
      "Epoch: 2/40, Generator Loss: 0.0, Discriminator Loss: 100.0765151977539\n",
      "Epoch: 3/40, Generator Loss: 0.0, Discriminator Loss: 100.03258514404297\n",
      "Epoch: 4/40, Generator Loss: 0.0, Discriminator Loss: 100.01763153076172\n",
      "Epoch: 5/40, Generator Loss: 0.0, Discriminator Loss: 100.01093292236328\n",
      "Epoch: 6/40, Generator Loss: 0.0, Discriminator Loss: 100.00711822509766\n",
      "Epoch: 7/40, Generator Loss: 0.0, Discriminator Loss: 100.00528717041016\n",
      "Epoch: 8/40, Generator Loss: 0.0, Discriminator Loss: 100.00428771972656\n",
      "Epoch: 9/40, Generator Loss: 0.0, Discriminator Loss: 100.00274658203125\n",
      "Epoch: 10/40, Generator Loss: 0.0, Discriminator Loss: 100.0023193359375\n",
      "Epoch: 11/40, Generator Loss: 0.0, Discriminator Loss: 100.00181579589844\n",
      "Epoch: 12/40, Generator Loss: 0.0, Discriminator Loss: 100.0013656616211\n",
      "Epoch: 13/40, Generator Loss: 0.0, Discriminator Loss: 100.00115203857422\n",
      "Epoch: 14/40, Generator Loss: 0.0, Discriminator Loss: 100.00090026855469\n",
      "Epoch: 15/40, Generator Loss: 0.0, Discriminator Loss: 100.00079345703125\n",
      "Epoch: 16/40, Generator Loss: 0.0, Discriminator Loss: 100.00067901611328\n",
      "Epoch: 17/40, Generator Loss: 0.0, Discriminator Loss: 100.0005874633789\n",
      "Epoch: 18/40, Generator Loss: 0.0, Discriminator Loss: 100.00044250488281\n",
      "Epoch: 19/40, Generator Loss: 0.0, Discriminator Loss: 100.00035095214844\n",
      "Epoch: 20/40, Generator Loss: 0.0, Discriminator Loss: 100.00030517578125\n",
      "Epoch: 21/40, Generator Loss: 0.0, Discriminator Loss: 100.000244140625\n",
      "Epoch: 22/40, Generator Loss: 0.0, Discriminator Loss: 100.00023651123047\n",
      "Epoch: 23/40, Generator Loss: 0.0, Discriminator Loss: 100.00018310546875\n",
      "Epoch: 24/40, Generator Loss: 0.0, Discriminator Loss: 100.00016021728516\n",
      "Epoch: 25/40, Generator Loss: 0.0, Discriminator Loss: 100.0001449584961\n",
      "Epoch: 26/40, Generator Loss: 0.0, Discriminator Loss: 100.0001220703125\n",
      "Epoch: 27/40, Generator Loss: 0.0, Discriminator Loss: 100.00011444091797\n",
      "Epoch: 28/40, Generator Loss: 0.0, Discriminator Loss: 100.00009155273438\n",
      "Epoch: 29/40, Generator Loss: 0.0, Discriminator Loss: 100.00009155273438\n",
      "Epoch: 30/40, Generator Loss: 0.0, Discriminator Loss: 100.00007629394531\n",
      "Epoch: 31/40, Generator Loss: 0.0, Discriminator Loss: 100.00006103515625\n",
      "Epoch: 32/40, Generator Loss: 0.0, Discriminator Loss: 100.00006866455078\n",
      "Epoch: 33/40, Generator Loss: 0.0, Discriminator Loss: 100.00006103515625\n",
      "Epoch: 34/40, Generator Loss: 0.0, Discriminator Loss: 100.00004577636719\n",
      "Epoch: 35/40, Generator Loss: 0.0, Discriminator Loss: 100.00004577636719\n",
      "Epoch: 36/40, Generator Loss: 0.0, Discriminator Loss: 100.00004577636719\n",
      "Epoch: 37/40, Generator Loss: 0.0, Discriminator Loss: 100.00003814697266\n",
      "Epoch: 38/40, Generator Loss: 0.0, Discriminator Loss: 100.00003814697266\n",
      "Epoch: 39/40, Generator Loss: 0.0, Discriminator Loss: 100.00003814697266\n",
      "Epoch: 40/40, Generator Loss: 0.0, Discriminator Loss: 100.00003814697266\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.9410\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -79.0599\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "Epoch: 1/89, Generator Loss: 1.5709307193756104, Discriminator Loss: 1.631001591682434\n",
      "Epoch: 2/89, Generator Loss: 2.522623300552368, Discriminator Loss: 0.543529748916626\n",
      "Epoch: 3/89, Generator Loss: 5.157942295074463, Discriminator Loss: 0.33921700716018677\n",
      "Epoch: 4/89, Generator Loss: 3.3231070041656494, Discriminator Loss: 0.09464298188686371\n",
      "Epoch: 5/89, Generator Loss: 4.081423282623291, Discriminator Loss: 0.029195822775363922\n",
      "Epoch: 6/89, Generator Loss: 5.112252712249756, Discriminator Loss: 0.8040151596069336\n",
      "Epoch: 7/89, Generator Loss: 3.598557233810425, Discriminator Loss: 0.06937387585639954\n",
      "Epoch: 8/89, Generator Loss: 3.0354769229888916, Discriminator Loss: 0.2771074175834656\n",
      "Epoch: 9/89, Generator Loss: 3.162679433822632, Discriminator Loss: 0.18048086762428284\n",
      "Epoch: 10/89, Generator Loss: 9.214963912963867, Discriminator Loss: 0.5947293043136597\n",
      "Epoch: 11/89, Generator Loss: 6.415135383605957, Discriminator Loss: 0.022558430209755898\n",
      "Epoch: 12/89, Generator Loss: 6.099390506744385, Discriminator Loss: 0.29970377683639526\n",
      "Epoch: 13/89, Generator Loss: 5.980687618255615, Discriminator Loss: 0.06459400057792664\n",
      "Epoch: 14/89, Generator Loss: 14.787171363830566, Discriminator Loss: 1.0806385278701782\n",
      "Epoch: 15/89, Generator Loss: 19.117324829101562, Discriminator Loss: 2.128774404525757\n",
      "Epoch: 16/89, Generator Loss: 2.9773178100585938, Discriminator Loss: 0.23613962531089783\n",
      "Epoch: 17/89, Generator Loss: 3.1750171184539795, Discriminator Loss: 0.1550731509923935\n",
      "Epoch: 18/89, Generator Loss: 12.590517044067383, Discriminator Loss: 0.030255872756242752\n",
      "Epoch: 19/89, Generator Loss: 20.262126922607422, Discriminator Loss: 0.012967750430107117\n",
      "Epoch: 20/89, Generator Loss: 6.3132548332214355, Discriminator Loss: 0.045761752873659134\n",
      "Epoch: 21/89, Generator Loss: 5.899481773376465, Discriminator Loss: 0.08976232260465622\n",
      "Epoch: 22/89, Generator Loss: 3.5480265617370605, Discriminator Loss: 0.13065123558044434\n",
      "Epoch: 23/89, Generator Loss: 5.09084415435791, Discriminator Loss: 0.009926090948283672\n",
      "Epoch: 24/89, Generator Loss: 8.487051010131836, Discriminator Loss: 0.1232903003692627\n",
      "Epoch: 25/89, Generator Loss: 6.169942855834961, Discriminator Loss: 0.07771588861942291\n",
      "Epoch: 26/89, Generator Loss: 12.754502296447754, Discriminator Loss: 0.024128461256623268\n",
      "Epoch: 27/89, Generator Loss: 8.846028327941895, Discriminator Loss: 0.004748096223920584\n",
      "Epoch: 28/89, Generator Loss: 6.859213829040527, Discriminator Loss: 0.002206653356552124\n",
      "Epoch: 29/89, Generator Loss: 15.398354530334473, Discriminator Loss: 0.01210202556103468\n",
      "Epoch: 30/89, Generator Loss: 25.304229736328125, Discriminator Loss: 0.27550503611564636\n",
      "Epoch: 31/89, Generator Loss: 6.586521625518799, Discriminator Loss: 0.05583271011710167\n",
      "Epoch: 32/89, Generator Loss: 10.55783748626709, Discriminator Loss: 0.003149553434923291\n",
      "Epoch: 33/89, Generator Loss: 14.556017875671387, Discriminator Loss: 1.355534553527832\n",
      "Epoch: 34/89, Generator Loss: 11.190030097961426, Discriminator Loss: 0.08490821719169617\n",
      "Epoch: 35/89, Generator Loss: 6.319607257843018, Discriminator Loss: 0.031733762472867966\n",
      "Epoch: 36/89, Generator Loss: 6.468782424926758, Discriminator Loss: 0.031076254323124886\n",
      "Epoch: 37/89, Generator Loss: 9.705360412597656, Discriminator Loss: 0.011169498786330223\n",
      "Epoch: 38/89, Generator Loss: 7.769111633300781, Discriminator Loss: 0.95309978723526\n",
      "Epoch: 39/89, Generator Loss: 6.218066215515137, Discriminator Loss: 0.004693921655416489\n",
      "Epoch: 40/89, Generator Loss: 35.307613372802734, Discriminator Loss: 0.0031445922795683146\n",
      "Epoch: 41/89, Generator Loss: 5.923823833465576, Discriminator Loss: 0.03249126672744751\n",
      "Epoch: 42/89, Generator Loss: 22.809690475463867, Discriminator Loss: 0.025432083755731583\n",
      "Epoch: 43/89, Generator Loss: 9.21104907989502, Discriminator Loss: 0.0003183330991305411\n",
      "Epoch: 44/89, Generator Loss: 11.248554229736328, Discriminator Loss: 0.00027397979283705354\n",
      "Epoch: 45/89, Generator Loss: 5.757635116577148, Discriminator Loss: 0.015180842950940132\n",
      "Epoch: 46/89, Generator Loss: 5.662982940673828, Discriminator Loss: 0.03125988692045212\n",
      "Epoch: 47/89, Generator Loss: 7.559924602508545, Discriminator Loss: 0.0015152012929320335\n",
      "Epoch: 48/89, Generator Loss: 12.192621231079102, Discriminator Loss: 0.0031376637052744627\n",
      "Epoch: 49/89, Generator Loss: 22.283323287963867, Discriminator Loss: 4.7123605327215046e-05\n",
      "Epoch: 50/89, Generator Loss: 36.91864776611328, Discriminator Loss: 0.0002894971985369921\n",
      "Epoch: 51/89, Generator Loss: 35.06418228149414, Discriminator Loss: 1.618112946744077e-05\n",
      "Epoch: 52/89, Generator Loss: 33.91242599487305, Discriminator Loss: 4.888671583103132e-07\n",
      "Epoch: 53/89, Generator Loss: 32.235836029052734, Discriminator Loss: 1.1636716408247594e-05\n",
      "Epoch: 54/89, Generator Loss: 30.886072158813477, Discriminator Loss: 7.944255457914551e-07\n",
      "Epoch: 55/89, Generator Loss: 29.96721649169922, Discriminator Loss: 1.0017701335129914e-08\n",
      "Epoch: 56/89, Generator Loss: 29.4257869720459, Discriminator Loss: 1.6219320286836592e-06\n",
      "Epoch: 57/89, Generator Loss: 11.88361930847168, Discriminator Loss: 7.608190117025515e-06\n",
      "Epoch: 58/89, Generator Loss: 44.84645080566406, Discriminator Loss: 3.8408109028808207e-20\n",
      "Epoch: 59/89, Generator Loss: 43.745052337646484, Discriminator Loss: 9.988116289605387e-07\n",
      "Epoch: 60/89, Generator Loss: 43.42905807495117, Discriminator Loss: 2.1036953512520995e-08\n",
      "Epoch: 61/89, Generator Loss: 43.15671920776367, Discriminator Loss: 5.329487180461001e-07\n",
      "Epoch: 62/89, Generator Loss: 43.067386627197266, Discriminator Loss: 4.799272574018687e-06\n",
      "Epoch: 63/89, Generator Loss: 42.98249816894531, Discriminator Loss: 1.0618667545259086e-07\n",
      "Epoch: 64/89, Generator Loss: 42.93049240112305, Discriminator Loss: 1.8432491799558193e-07\n",
      "Epoch: 65/89, Generator Loss: 42.82944869995117, Discriminator Loss: 4.697750682680635e-06\n",
      "Epoch: 66/89, Generator Loss: 42.72822570800781, Discriminator Loss: 1.6028145921609394e-08\n",
      "Epoch: 67/89, Generator Loss: 42.70057678222656, Discriminator Loss: 1.352382810182462e-07\n",
      "Epoch: 68/89, Generator Loss: 42.617977142333984, Discriminator Loss: 3.826805823337054e-07\n",
      "Epoch: 69/89, Generator Loss: 42.51723098754883, Discriminator Loss: 1.3433890671876725e-05\n",
      "Epoch: 70/89, Generator Loss: 42.49851608276367, Discriminator Loss: 1.1019354317909347e-08\n",
      "Epoch: 71/89, Generator Loss: 42.463172912597656, Discriminator Loss: 3.62643504558946e-07\n",
      "Epoch: 72/89, Generator Loss: 42.497779846191406, Discriminator Loss: 9.015832524994494e-09\n",
      "Epoch: 73/89, Generator Loss: 42.38869857788086, Discriminator Loss: 7.303123652491195e-07\n",
      "Epoch: 74/89, Generator Loss: 42.385005950927734, Discriminator Loss: 1.4024634786835577e-08\n",
      "Epoch: 75/89, Generator Loss: 42.33807373046875, Discriminator Loss: 4.007035592223929e-09\n",
      "Epoch: 76/89, Generator Loss: 42.326683044433594, Discriminator Loss: 8.615167956804726e-08\n",
      "Epoch: 77/89, Generator Loss: 42.29827880859375, Discriminator Loss: 1.0017589424649032e-08\n",
      "Epoch: 78/89, Generator Loss: 42.27836990356445, Discriminator Loss: 2.5044007756491737e-08\n",
      "Epoch: 79/89, Generator Loss: 42.2519645690918, Discriminator Loss: 2.0035177961119643e-09\n",
      "Epoch: 80/89, Generator Loss: 42.1969108581543, Discriminator Loss: 2.300770574947819e-06\n",
      "Epoch: 81/89, Generator Loss: 42.12099838256836, Discriminator Loss: 1.2021111217563885e-08\n",
      "Epoch: 82/89, Generator Loss: 41.9893913269043, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 83/89, Generator Loss: 42.023502349853516, Discriminator Loss: 8.014072960804697e-09\n",
      "Epoch: 84/89, Generator Loss: 42.00007247924805, Discriminator Loss: 8.014072072626277e-09\n",
      "Epoch: 85/89, Generator Loss: 42.085201263427734, Discriminator Loss: 2.0035177961119643e-09\n",
      "Epoch: 86/89, Generator Loss: 41.91494369506836, Discriminator Loss: 3.0052769162125514e-09\n",
      "Epoch: 87/89, Generator Loss: 42.01078414916992, Discriminator Loss: 1.1019350765195668e-08\n",
      "Epoch: 88/89, Generator Loss: 41.89726638793945, Discriminator Loss: 6.912152628046897e-08\n",
      "Epoch: 89/89, Generator Loss: 41.88167953491211, Discriminator Loss: 3.0052769162125514e-09\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 23.1061\n",
      "Function value obtained: -41.8817\n",
      "Current minimum: -79.0599\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "Epoch: 1/75, Generator Loss: 3.432036876678467, Discriminator Loss: 0.45711013674736023\n",
      "Epoch: 2/75, Generator Loss: 6.90583610534668, Discriminator Loss: 0.27199018001556396\n",
      "Epoch: 3/75, Generator Loss: 4.21967887878418, Discriminator Loss: 0.10307620465755463\n",
      "Epoch: 4/75, Generator Loss: 6.263409614562988, Discriminator Loss: 0.025311440229415894\n",
      "Epoch: 5/75, Generator Loss: 10.192773818969727, Discriminator Loss: 0.16769173741340637\n",
      "Epoch: 6/75, Generator Loss: 6.457500457763672, Discriminator Loss: 0.10058100521564484\n",
      "Epoch: 7/75, Generator Loss: 26.49359130859375, Discriminator Loss: 0.003485108492895961\n",
      "Epoch: 8/75, Generator Loss: 6.120327472686768, Discriminator Loss: 0.09541969746351242\n",
      "Epoch: 9/75, Generator Loss: 8.88879108428955, Discriminator Loss: 0.08041826635599136\n",
      "Epoch: 10/75, Generator Loss: 6.441858768463135, Discriminator Loss: 0.032955966889858246\n",
      "Epoch: 11/75, Generator Loss: 8.028263092041016, Discriminator Loss: 0.03212670236825943\n",
      "Epoch: 12/75, Generator Loss: 12.218841552734375, Discriminator Loss: 0.04116438329219818\n",
      "Epoch: 13/75, Generator Loss: 5.474892616271973, Discriminator Loss: 0.029490748420357704\n",
      "Epoch: 14/75, Generator Loss: 10.859084129333496, Discriminator Loss: 0.0001637887762626633\n",
      "Epoch: 15/75, Generator Loss: 8.678397178649902, Discriminator Loss: 0.06406231969594955\n",
      "Epoch: 16/75, Generator Loss: 10.54053020477295, Discriminator Loss: 0.024727895855903625\n",
      "Epoch: 17/75, Generator Loss: 41.259212493896484, Discriminator Loss: 2.7238666007178836e-05\n",
      "Epoch: 18/75, Generator Loss: 40.28467559814453, Discriminator Loss: 1.351831087958999e-05\n",
      "Epoch: 19/75, Generator Loss: 39.86323547363281, Discriminator Loss: 0.0006088608060963452\n",
      "Epoch: 20/75, Generator Loss: 39.41282272338867, Discriminator Loss: 5.81709764446714e-06\n",
      "Epoch: 21/75, Generator Loss: 39.240272521972656, Discriminator Loss: 8.707209417480044e-06\n",
      "Epoch: 22/75, Generator Loss: 38.27036666870117, Discriminator Loss: 0.0001220853446284309\n",
      "Epoch: 23/75, Generator Loss: 6.318546295166016, Discriminator Loss: 0.003606049343943596\n",
      "Epoch: 24/75, Generator Loss: 8.735490798950195, Discriminator Loss: 0.0012339054374024272\n",
      "Epoch: 25/75, Generator Loss: 17.956830978393555, Discriminator Loss: 8.86461857589893e-05\n",
      "Epoch: 26/75, Generator Loss: 9.613609313964844, Discriminator Loss: 0.00014012600877322257\n",
      "Epoch: 27/75, Generator Loss: 12.075032234191895, Discriminator Loss: 6.283984112087637e-05\n",
      "Epoch: 28/75, Generator Loss: 8.372026443481445, Discriminator Loss: 0.0004541398957371712\n",
      "Epoch: 29/75, Generator Loss: 8.12859058380127, Discriminator Loss: 0.0009075010311789811\n",
      "Epoch: 30/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/75, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 19.4448\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -79.0599\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "Epoch: 1/62, Generator Loss: 1.3476790189743042, Discriminator Loss: 1.4104859828948975\n",
      "Epoch: 2/62, Generator Loss: 0.7676213383674622, Discriminator Loss: 2.568782329559326\n",
      "Epoch: 3/62, Generator Loss: 1.1776684522628784, Discriminator Loss: 0.9935833215713501\n",
      "Epoch: 4/62, Generator Loss: 1.3629049062728882, Discriminator Loss: 0.97898268699646\n",
      "Epoch: 5/62, Generator Loss: 2.572293996810913, Discriminator Loss: 0.627577543258667\n",
      "Epoch: 6/62, Generator Loss: 3.143670082092285, Discriminator Loss: 2.959080696105957\n",
      "Epoch: 7/62, Generator Loss: 2.327007293701172, Discriminator Loss: 2.5893030166625977\n",
      "Epoch: 8/62, Generator Loss: 2.079174280166626, Discriminator Loss: 1.4314666986465454\n",
      "Epoch: 9/62, Generator Loss: 2.958649158477783, Discriminator Loss: 1.6507980823516846\n",
      "Epoch: 10/62, Generator Loss: 0.9419972896575928, Discriminator Loss: 1.8112611770629883\n",
      "Epoch: 11/62, Generator Loss: 1.5490772724151611, Discriminator Loss: 1.0334144830703735\n",
      "Epoch: 12/62, Generator Loss: 1.843500018119812, Discriminator Loss: 0.8998723030090332\n",
      "Epoch: 13/62, Generator Loss: 2.3353028297424316, Discriminator Loss: 1.5726654529571533\n",
      "Epoch: 14/62, Generator Loss: 1.718758463859558, Discriminator Loss: 1.1558213233947754\n",
      "Epoch: 15/62, Generator Loss: 1.4275033473968506, Discriminator Loss: 1.2151578664779663\n",
      "Epoch: 16/62, Generator Loss: 1.6121582984924316, Discriminator Loss: 0.8335602283477783\n",
      "Epoch: 17/62, Generator Loss: 3.907444477081299, Discriminator Loss: 10.424151420593262\n",
      "Epoch: 18/62, Generator Loss: 5.542011737823486, Discriminator Loss: 1.0079779624938965\n",
      "Epoch: 19/62, Generator Loss: 8.81596565246582, Discriminator Loss: 1.3782424926757812\n",
      "Epoch: 20/62, Generator Loss: 2.082226514816284, Discriminator Loss: 0.8049546480178833\n",
      "Epoch: 21/62, Generator Loss: 1.1162679195404053, Discriminator Loss: 1.891218662261963\n",
      "Epoch: 22/62, Generator Loss: 2.2392075061798096, Discriminator Loss: 0.8448336124420166\n",
      "Epoch: 23/62, Generator Loss: 1.7572540044784546, Discriminator Loss: 0.6483497619628906\n",
      "Epoch: 24/62, Generator Loss: 1.3960014581680298, Discriminator Loss: 1.1174925565719604\n",
      "Epoch: 25/62, Generator Loss: 2.404449939727783, Discriminator Loss: 1.3865078687667847\n",
      "Epoch: 26/62, Generator Loss: 3.213876485824585, Discriminator Loss: 0.2944338917732239\n",
      "Epoch: 27/62, Generator Loss: 12.737878799438477, Discriminator Loss: 2.0657174587249756\n",
      "Epoch: 28/62, Generator Loss: 2.760375499725342, Discriminator Loss: 1.217928409576416\n",
      "Epoch: 29/62, Generator Loss: 1.0292963981628418, Discriminator Loss: 0.6298012733459473\n",
      "Epoch: 30/62, Generator Loss: 1.6160115003585815, Discriminator Loss: 1.207815408706665\n",
      "Epoch: 31/62, Generator Loss: 3.869957447052002, Discriminator Loss: 1.3352656364440918\n",
      "Epoch: 32/62, Generator Loss: 1.8936946392059326, Discriminator Loss: 1.7382981777191162\n",
      "Epoch: 33/62, Generator Loss: 4.0010528564453125, Discriminator Loss: 4.134485244750977\n",
      "Epoch: 34/62, Generator Loss: 6.383520126342773, Discriminator Loss: 1.696273922920227\n",
      "Epoch: 35/62, Generator Loss: 2.4114019870758057, Discriminator Loss: 0.5587238073348999\n",
      "Epoch: 36/62, Generator Loss: 3.660703420639038, Discriminator Loss: 1.4803904294967651\n",
      "Epoch: 37/62, Generator Loss: 1.7476850748062134, Discriminator Loss: 0.7296306490898132\n",
      "Epoch: 38/62, Generator Loss: 4.035766124725342, Discriminator Loss: 6.289453983306885\n",
      "Epoch: 39/62, Generator Loss: 5.1354498863220215, Discriminator Loss: 0.21813490986824036\n",
      "Epoch: 40/62, Generator Loss: 5.389238357543945, Discriminator Loss: 0.7041005492210388\n",
      "Epoch: 41/62, Generator Loss: 4.309297561645508, Discriminator Loss: 2.4608235359191895\n",
      "Epoch: 42/62, Generator Loss: 6.460628986358643, Discriminator Loss: 1.5119844675064087\n",
      "Epoch: 43/62, Generator Loss: 3.2756617069244385, Discriminator Loss: 0.11519414186477661\n",
      "Epoch: 44/62, Generator Loss: 2.284014940261841, Discriminator Loss: 0.2732068598270416\n",
      "Epoch: 45/62, Generator Loss: 100.00000762939453, Discriminator Loss: 1.4244023986975662e-05\n",
      "Epoch: 46/62, Generator Loss: 100.00000762939453, Discriminator Loss: 8.647906724945642e-06\n",
      "Epoch: 47/62, Generator Loss: 100.00000762939453, Discriminator Loss: 1.1945436199312098e-05\n",
      "Epoch: 48/62, Generator Loss: 100.00000762939453, Discriminator Loss: 1.1219773199400151e-07\n",
      "Epoch: 49/62, Generator Loss: 100.00000762939453, Discriminator Loss: 1.5026394351025374e-08\n",
      "Epoch: 50/62, Generator Loss: 100.00000762939453, Discriminator Loss: 2.5645292112130846e-07\n",
      "Epoch: 51/62, Generator Loss: 100.00000762939453, Discriminator Loss: 2.3942251914377266e-07\n",
      "Epoch: 52/62, Generator Loss: 100.00000762939453, Discriminator Loss: 2.0035177961119643e-09\n",
      "Epoch: 53/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0002829573058988899\n",
      "Epoch: 54/62, Generator Loss: 100.00000762939453, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 55/62, Generator Loss: 100.00000762939453, Discriminator Loss: 1.3022868117218422e-08\n",
      "Epoch: 56/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 57/62, Generator Loss: 100.00000762939453, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 58/62, Generator Loss: 100.00000762939453, Discriminator Loss: 7.075394933053758e-06\n",
      "Epoch: 59/62, Generator Loss: 100.00000762939453, Discriminator Loss: 6.210927239180819e-08\n",
      "Epoch: 60/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 61/62, Generator Loss: 100.00000762939453, Discriminator Loss: 2.203872284667341e-08\n",
      "Epoch: 62/62, Generator Loss: 100.00000762939453, Discriminator Loss: 2.6045755774362078e-08\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 15.4798\n",
      "Function value obtained: -100.0000\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "Epoch: 1/86, Generator Loss: 1.669331669807434, Discriminator Loss: 0.4881419539451599\n",
      "Epoch: 2/86, Generator Loss: 5.6864190101623535, Discriminator Loss: 0.004554977640509605\n",
      "Epoch: 3/86, Generator Loss: 4.017144680023193, Discriminator Loss: 0.12153280526399612\n",
      "Epoch: 4/86, Generator Loss: 15.763691902160645, Discriminator Loss: 0.39533695578575134\n",
      "Epoch: 5/86, Generator Loss: 9.0575590133667, Discriminator Loss: 0.34150680899620056\n",
      "Epoch: 6/86, Generator Loss: 7.788680553436279, Discriminator Loss: 0.10040735453367233\n",
      "Epoch: 7/86, Generator Loss: 4.260283470153809, Discriminator Loss: 0.041370801627635956\n",
      "Epoch: 8/86, Generator Loss: 8.17283821105957, Discriminator Loss: 0.0012371813645586371\n",
      "Epoch: 9/86, Generator Loss: 24.94866180419922, Discriminator Loss: 0.08370978385210037\n",
      "Epoch: 10/86, Generator Loss: 19.695083618164062, Discriminator Loss: 1.834212064743042\n",
      "Epoch: 11/86, Generator Loss: 8.406922340393066, Discriminator Loss: 0.029852716252207756\n",
      "Epoch: 12/86, Generator Loss: 7.254090309143066, Discriminator Loss: 0.0034047975204885006\n",
      "Epoch: 13/86, Generator Loss: 11.983123779296875, Discriminator Loss: 0.007731343153864145\n",
      "Epoch: 14/86, Generator Loss: 9.1049222946167, Discriminator Loss: 0.0002949396730400622\n",
      "Epoch: 15/86, Generator Loss: 6.756465911865234, Discriminator Loss: 0.004085949156433344\n",
      "Epoch: 16/86, Generator Loss: 8.772405624389648, Discriminator Loss: 0.0008359362254850566\n",
      "Epoch: 17/86, Generator Loss: 20.716272354125977, Discriminator Loss: 0.0018479941645637155\n",
      "Epoch: 18/86, Generator Loss: 52.09555435180664, Discriminator Loss: 5.008794712324516e-09\n",
      "Epoch: 19/86, Generator Loss: 52.03416061401367, Discriminator Loss: 2.0035177961119643e-09\n",
      "Epoch: 20/86, Generator Loss: 52.26939392089844, Discriminator Loss: 1.5739417152019494e-22\n",
      "Epoch: 21/86, Generator Loss: 52.06904983520508, Discriminator Loss: 1.4525586777835997e-07\n",
      "Epoch: 22/86, Generator Loss: 51.70908737182617, Discriminator Loss: 1.9417920991453212e-22\n",
      "Epoch: 23/86, Generator Loss: 51.61128234863281, Discriminator Loss: 4.007035592223929e-09\n",
      "Epoch: 24/86, Generator Loss: 51.9088134765625, Discriminator Loss: 1.8031670379059506e-08\n",
      "Epoch: 25/86, Generator Loss: 52.089515686035156, Discriminator Loss: 1.4868805013468618e-22\n",
      "Epoch: 26/86, Generator Loss: 51.77346420288086, Discriminator Loss: 1.602275369805284e-05\n",
      "Epoch: 27/86, Generator Loss: 51.98455810546875, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 28/86, Generator Loss: 51.350006103515625, Discriminator Loss: 7.05267325429304e-07\n",
      "Epoch: 29/86, Generator Loss: 51.59672164916992, Discriminator Loss: 6.862324539724796e-07\n",
      "Epoch: 30/86, Generator Loss: 51.402130126953125, Discriminator Loss: 3.0052769162125514e-09\n",
      "Epoch: 31/86, Generator Loss: 51.598026275634766, Discriminator Loss: 3.40598660386604e-08\n",
      "Epoch: 32/86, Generator Loss: 51.53057098388672, Discriminator Loss: 4.007035592223929e-09\n",
      "Epoch: 33/86, Generator Loss: 51.723453521728516, Discriminator Loss: 3.3259050269407453e-07\n",
      "Epoch: 34/86, Generator Loss: 51.56462097167969, Discriminator Loss: 6.060859050194267e-07\n",
      "Epoch: 35/86, Generator Loss: 51.4437370300293, Discriminator Loss: 3.906864876057625e-08\n",
      "Epoch: 36/86, Generator Loss: 51.54463577270508, Discriminator Loss: 3.4861869835367543e-07\n",
      "Epoch: 37/86, Generator Loss: 51.135013580322266, Discriminator Loss: 5.5096883500027616e-08\n",
      "Epoch: 38/86, Generator Loss: 51.286556243896484, Discriminator Loss: 5.479798232954636e-07\n",
      "Epoch: 39/86, Generator Loss: 51.281185150146484, Discriminator Loss: 3.285818763743009e-07\n",
      "Epoch: 40/86, Generator Loss: 51.133060455322266, Discriminator Loss: 1.1019350765195668e-08\n",
      "Epoch: 41/86, Generator Loss: 51.43866729736328, Discriminator Loss: 3.396025078927778e-07\n",
      "Epoch: 42/86, Generator Loss: 50.92802047729492, Discriminator Loss: 2.0035177961119643e-09\n",
      "Epoch: 43/86, Generator Loss: 51.50896453857422, Discriminator Loss: 2.684752473669505e-07\n",
      "Epoch: 44/86, Generator Loss: 50.9647331237793, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 45/86, Generator Loss: 51.24791717529297, Discriminator Loss: 3.48691262340284e-22\n",
      "Epoch: 46/86, Generator Loss: 51.09544372558594, Discriminator Loss: 9.015832524994494e-09\n",
      "Epoch: 47/86, Generator Loss: 51.22126770019531, Discriminator Loss: 3.0052769162125514e-09\n",
      "Epoch: 48/86, Generator Loss: 51.44712829589844, Discriminator Loss: 2.9832864034609587e-22\n",
      "Epoch: 49/86, Generator Loss: 51.173622131347656, Discriminator Loss: 4.346418105279183e-22\n",
      "Epoch: 50/86, Generator Loss: 51.23676681518555, Discriminator Loss: 7.413044755821829e-08\n",
      "Epoch: 51/86, Generator Loss: 51.149330139160156, Discriminator Loss: 3.1054543825348446e-08\n",
      "Epoch: 52/86, Generator Loss: 50.826019287109375, Discriminator Loss: 6.010553832425103e-09\n",
      "Epoch: 53/86, Generator Loss: 51.000022888183594, Discriminator Loss: 4.007035592223929e-09\n",
      "Epoch: 54/86, Generator Loss: 51.33910369873047, Discriminator Loss: 3.105456514163052e-08\n",
      "Epoch: 55/86, Generator Loss: 51.03042221069336, Discriminator Loss: 1.1019350765195668e-08\n",
      "Epoch: 56/86, Generator Loss: 51.2082405090332, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 57/86, Generator Loss: 51.40321350097656, Discriminator Loss: 4.0733467716343466e-22\n",
      "Epoch: 58/86, Generator Loss: 50.77238845825195, Discriminator Loss: 6.61163070958537e-08\n",
      "Epoch: 59/86, Generator Loss: 51.014915466308594, Discriminator Loss: 9.015829860459235e-09\n",
      "Epoch: 60/86, Generator Loss: 50.545738220214844, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 61/86, Generator Loss: 51.10066604614258, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 62/86, Generator Loss: 51.06700134277344, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 63/86, Generator Loss: 50.851646423339844, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 64/86, Generator Loss: 50.40953063964844, Discriminator Loss: 6.010554276514313e-09\n",
      "Epoch: 65/86, Generator Loss: 50.95024871826172, Discriminator Loss: 4.0779269611589323e-22\n",
      "Epoch: 66/86, Generator Loss: 50.72093963623047, Discriminator Loss: 7.01231384070411e-09\n",
      "Epoch: 67/86, Generator Loss: 51.2821044921875, Discriminator Loss: 1.662936028878903e-07\n",
      "Epoch: 68/86, Generator Loss: 50.663719177246094, Discriminator Loss: 7.01231384070411e-09\n",
      "Epoch: 69/86, Generator Loss: 50.53825378417969, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 70/86, Generator Loss: 51.145999908447266, Discriminator Loss: 2.0636481679048302e-07\n",
      "Epoch: 71/86, Generator Loss: 50.13530349731445, Discriminator Loss: 5.008795156413726e-09\n",
      "Epoch: 72/86, Generator Loss: 50.75749969482422, Discriminator Loss: 2.7047518003087134e-08\n",
      "Epoch: 73/86, Generator Loss: 50.77336502075195, Discriminator Loss: 5.471237325767292e-22\n",
      "Epoch: 74/86, Generator Loss: 50.16572952270508, Discriminator Loss: 8.575491960982617e-07\n",
      "Epoch: 75/86, Generator Loss: 50.353763580322266, Discriminator Loss: 1.1019352541552507e-08\n",
      "Epoch: 76/86, Generator Loss: 50.49312210083008, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 77/86, Generator Loss: 50.7022705078125, Discriminator Loss: 1.1019354317909347e-08\n",
      "Epoch: 78/86, Generator Loss: 50.4865837097168, Discriminator Loss: 1.4826142091806105e-07\n",
      "Epoch: 79/86, Generator Loss: 50.694435119628906, Discriminator Loss: 8.014072960804697e-09\n",
      "Epoch: 80/86, Generator Loss: 51.11808776855469, Discriminator Loss: 8.014073848983116e-09\n",
      "Epoch: 81/86, Generator Loss: 50.4957275390625, Discriminator Loss: 1.2021107664850206e-08\n",
      "Epoch: 82/86, Generator Loss: 50.78446960449219, Discriminator Loss: 3.1255456178769236e-07\n",
      "Epoch: 83/86, Generator Loss: 50.50877380371094, Discriminator Loss: 3.546298046330776e-07\n",
      "Epoch: 84/86, Generator Loss: 50.37862014770508, Discriminator Loss: 5.499832695932128e-07\n",
      "Epoch: 85/86, Generator Loss: 50.5541877746582, Discriminator Loss: 4.0070360363131385e-09\n",
      "Epoch: 86/86, Generator Loss: 50.57203674316406, Discriminator Loss: 5.910584945922892e-07\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 21.4077\n",
      "Function value obtained: -50.5720\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "Epoch: 1/62, Generator Loss: 2.8149189949035645, Discriminator Loss: 1.0347473621368408\n",
      "Epoch: 2/62, Generator Loss: 2.1827199459075928, Discriminator Loss: 0.9857227802276611\n",
      "Epoch: 3/62, Generator Loss: 1.1513580083847046, Discriminator Loss: 1.4251978397369385\n",
      "Epoch: 4/62, Generator Loss: 2.1575162410736084, Discriminator Loss: 1.3146262168884277\n",
      "Epoch: 5/62, Generator Loss: 2.7603325843811035, Discriminator Loss: 1.5364189147949219\n",
      "Epoch: 6/62, Generator Loss: 3.8573379516601562, Discriminator Loss: 1.2700661420822144\n",
      "Epoch: 7/62, Generator Loss: 4.840088367462158, Discriminator Loss: 1.1038627624511719\n",
      "Epoch: 8/62, Generator Loss: 70.51065063476562, Discriminator Loss: 7.0123142847933195e-09\n",
      "Epoch: 9/62, Generator Loss: 66.67554473876953, Discriminator Loss: 2.4838404142538288e-21\n",
      "Epoch: 10/62, Generator Loss: 68.66409301757812, Discriminator Loss: 2.000259061561192e-22\n",
      "Epoch: 11/62, Generator Loss: 67.43958282470703, Discriminator Loss: 9.592897284007611e-24\n",
      "Epoch: 12/62, Generator Loss: 67.85443115234375, Discriminator Loss: 5.2661921185523047e-23\n",
      "Epoch: 13/62, Generator Loss: 66.84236907958984, Discriminator Loss: 1.0755003132208033e-20\n",
      "Epoch: 14/62, Generator Loss: 68.04423522949219, Discriminator Loss: 5.0547501505906733e-20\n",
      "Epoch: 15/62, Generator Loss: 67.96454620361328, Discriminator Loss: 6.057126970647579e-22\n",
      "Epoch: 16/62, Generator Loss: 67.35517883300781, Discriminator Loss: 1.0682169043711268e-23\n",
      "Epoch: 17/62, Generator Loss: 67.49383544921875, Discriminator Loss: 1.2988708400434311e-23\n",
      "Epoch: 18/62, Generator Loss: 67.52237701416016, Discriminator Loss: 1.3649001133975637e-21\n",
      "Epoch: 19/62, Generator Loss: 68.16614532470703, Discriminator Loss: 2.042333335339208e-06\n",
      "Epoch: 20/62, Generator Loss: 68.71846008300781, Discriminator Loss: 4.2194718316206315e-23\n",
      "Epoch: 21/62, Generator Loss: 66.63288879394531, Discriminator Loss: 6.458955802589354e-22\n",
      "Epoch: 22/62, Generator Loss: 65.94127655029297, Discriminator Loss: 7.877792191477728e-22\n",
      "Epoch: 23/62, Generator Loss: 66.54266357421875, Discriminator Loss: 2.8089039671964227e-22\n",
      "Epoch: 24/62, Generator Loss: 67.46189880371094, Discriminator Loss: 1.1213799131590898e-22\n",
      "Epoch: 25/62, Generator Loss: 68.40977478027344, Discriminator Loss: 1.6359260190675834e-23\n",
      "Epoch: 26/62, Generator Loss: 65.67831420898438, Discriminator Loss: 1.7729661214181234e-21\n",
      "Epoch: 27/62, Generator Loss: 67.51844024658203, Discriminator Loss: 7.84899876843716e-24\n",
      "Epoch: 28/62, Generator Loss: 67.69587707519531, Discriminator Loss: 1.1922429727307312e-22\n",
      "Epoch: 29/62, Generator Loss: 68.28205108642578, Discriminator Loss: 2.9046764773645573e-22\n",
      "Epoch: 30/62, Generator Loss: 67.73117065429688, Discriminator Loss: 1.4230606847622016e-20\n",
      "Epoch: 31/62, Generator Loss: 68.83333587646484, Discriminator Loss: 4.469713104683483e-24\n",
      "Epoch: 32/62, Generator Loss: 67.3204574584961, Discriminator Loss: 6.22721560545056e-23\n",
      "Epoch: 33/62, Generator Loss: 66.40640258789062, Discriminator Loss: 7.432242037595962e-21\n",
      "Epoch: 34/62, Generator Loss: 66.17633819580078, Discriminator Loss: 6.040543347371405e-23\n",
      "Epoch: 35/62, Generator Loss: 65.73967742919922, Discriminator Loss: 1.421958227034695e-23\n",
      "Epoch: 36/62, Generator Loss: 68.19567108154297, Discriminator Loss: 3.041800003333546e-23\n",
      "Epoch: 37/62, Generator Loss: 67.8070297241211, Discriminator Loss: 1.1880276787064647e-22\n",
      "Epoch: 38/62, Generator Loss: 66.5734634399414, Discriminator Loss: 3.990799609205551e-22\n",
      "Epoch: 39/62, Generator Loss: 66.50883483886719, Discriminator Loss: 2.885317728198516e-24\n",
      "Epoch: 40/62, Generator Loss: 67.27796936035156, Discriminator Loss: 3.1772354300742345e-23\n",
      "Epoch: 41/62, Generator Loss: 67.32669830322266, Discriminator Loss: 9.350023577369071e-24\n",
      "Epoch: 42/62, Generator Loss: 66.924560546875, Discriminator Loss: 1.2484999886522797e-22\n",
      "Epoch: 43/62, Generator Loss: 66.16279602050781, Discriminator Loss: 4.361806635838383e-23\n",
      "Epoch: 44/62, Generator Loss: 67.1619873046875, Discriminator Loss: 3.803535995748293e-21\n",
      "Epoch: 45/62, Generator Loss: 66.34058380126953, Discriminator Loss: 1.382904342635408e-22\n",
      "Epoch: 46/62, Generator Loss: 66.59310913085938, Discriminator Loss: 6.908686035744577e-23\n",
      "Epoch: 47/62, Generator Loss: 67.0030746459961, Discriminator Loss: 7.590429885228343e-24\n",
      "Epoch: 48/62, Generator Loss: 67.5235595703125, Discriminator Loss: 3.5902296225636654e-21\n",
      "Epoch: 49/62, Generator Loss: 65.88711547851562, Discriminator Loss: 3.308892591732149e-22\n",
      "Epoch: 50/62, Generator Loss: 66.40375518798828, Discriminator Loss: 5.6427135227263466e-21\n",
      "Epoch: 51/62, Generator Loss: 66.22362518310547, Discriminator Loss: 1.4266255448092124e-06\n",
      "Epoch: 52/62, Generator Loss: 67.0019302368164, Discriminator Loss: 4.314230986847137e-24\n",
      "Epoch: 53/62, Generator Loss: 65.77074432373047, Discriminator Loss: 4.36905954921873e-22\n",
      "Epoch: 54/62, Generator Loss: 68.31813049316406, Discriminator Loss: 1.3564908840635326e-06\n",
      "Epoch: 55/62, Generator Loss: 67.6260757446289, Discriminator Loss: 1.8316719130507717e-23\n",
      "Epoch: 56/62, Generator Loss: 64.86114501953125, Discriminator Loss: 2.0476320521858864e-23\n",
      "Epoch: 57/62, Generator Loss: 66.47575378417969, Discriminator Loss: 1.0453521648326596e-20\n",
      "Epoch: 58/62, Generator Loss: 67.55425262451172, Discriminator Loss: 5.1776588902480747e-23\n",
      "Epoch: 59/62, Generator Loss: 66.04109191894531, Discriminator Loss: 8.959947794727566e-23\n",
      "Epoch: 60/62, Generator Loss: 66.75458526611328, Discriminator Loss: 1.509307059575826e-23\n",
      "Epoch: 61/62, Generator Loss: 68.47069549560547, Discriminator Loss: 1.3682924424819548e-21\n",
      "Epoch: 62/62, Generator Loss: 67.81449890136719, Discriminator Loss: 3.484259463297528e-23\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 15.4540\n",
      "Function value obtained: -67.8145\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "Epoch: 1/50, Generator Loss: 1.0941181182861328, Discriminator Loss: 4.696659088134766\n",
      "Epoch: 2/50, Generator Loss: 3.669025421142578, Discriminator Loss: 0.5629789233207703\n",
      "Epoch: 3/50, Generator Loss: 1.7886418104171753, Discriminator Loss: 1.3306702375411987\n",
      "Epoch: 4/50, Generator Loss: 2.4731967449188232, Discriminator Loss: 0.448563814163208\n",
      "Epoch: 5/50, Generator Loss: 4.43923807144165, Discriminator Loss: 0.2800244390964508\n",
      "Epoch: 6/50, Generator Loss: 1.7401394844055176, Discriminator Loss: 0.8152247667312622\n",
      "Epoch: 7/50, Generator Loss: 1.9278396368026733, Discriminator Loss: 1.675586223602295\n",
      "Epoch: 8/50, Generator Loss: 2.0868492126464844, Discriminator Loss: 1.1117182970046997\n",
      "Epoch: 9/50, Generator Loss: 3.9380807876586914, Discriminator Loss: 0.15551911294460297\n",
      "Epoch: 10/50, Generator Loss: 3.0967905521392822, Discriminator Loss: 0.5395513772964478\n",
      "Epoch: 11/50, Generator Loss: 3.105808973312378, Discriminator Loss: 0.4201475977897644\n",
      "Epoch: 12/50, Generator Loss: 5.8077192306518555, Discriminator Loss: 0.11733924597501755\n",
      "Epoch: 13/50, Generator Loss: 6.982385635375977, Discriminator Loss: 0.4825979173183441\n",
      "Epoch: 14/50, Generator Loss: 4.744455814361572, Discriminator Loss: 0.10706783831119537\n",
      "Epoch: 15/50, Generator Loss: 4.319741249084473, Discriminator Loss: 0.3899065852165222\n",
      "Epoch: 16/50, Generator Loss: 6.674292087554932, Discriminator Loss: 0.02433999441564083\n",
      "Epoch: 17/50, Generator Loss: 7.1190385818481445, Discriminator Loss: 0.07544387876987457\n",
      "Epoch: 18/50, Generator Loss: 5.68410587310791, Discriminator Loss: 0.5547977089881897\n",
      "Epoch: 19/50, Generator Loss: 5.477442264556885, Discriminator Loss: 0.4067627787590027\n",
      "Epoch: 20/50, Generator Loss: 6.294694900512695, Discriminator Loss: 0.09562124311923981\n",
      "Epoch: 21/50, Generator Loss: 5.252058029174805, Discriminator Loss: 0.09560857713222504\n",
      "Epoch: 22/50, Generator Loss: 3.182769775390625, Discriminator Loss: 0.5909595489501953\n",
      "Epoch: 23/50, Generator Loss: 4.994973659515381, Discriminator Loss: 0.29527920484542847\n",
      "Epoch: 24/50, Generator Loss: 5.919977188110352, Discriminator Loss: 0.1005755215883255\n",
      "Epoch: 25/50, Generator Loss: 4.64273738861084, Discriminator Loss: 0.6738483309745789\n",
      "Epoch: 26/50, Generator Loss: 6.859764099121094, Discriminator Loss: 0.7558314204216003\n",
      "Epoch: 27/50, Generator Loss: 7.251601696014404, Discriminator Loss: 0.04056835174560547\n",
      "Epoch: 28/50, Generator Loss: 5.403495788574219, Discriminator Loss: 0.19661816954612732\n",
      "Epoch: 29/50, Generator Loss: 6.4848432540893555, Discriminator Loss: 0.2640419006347656\n",
      "Epoch: 30/50, Generator Loss: 11.430487632751465, Discriminator Loss: 0.4106844365596771\n",
      "Epoch: 31/50, Generator Loss: 11.286232948303223, Discriminator Loss: 0.1291627287864685\n",
      "Epoch: 32/50, Generator Loss: 6.889085292816162, Discriminator Loss: 0.23512691259384155\n",
      "Epoch: 33/50, Generator Loss: 4.598787307739258, Discriminator Loss: 0.06226314976811409\n",
      "Epoch: 34/50, Generator Loss: 3.0362956523895264, Discriminator Loss: 0.296639621257782\n",
      "Epoch: 35/50, Generator Loss: 6.008352756500244, Discriminator Loss: 0.1714918464422226\n",
      "Epoch: 36/50, Generator Loss: 6.638675212860107, Discriminator Loss: 0.11934146285057068\n",
      "Epoch: 37/50, Generator Loss: 8.154985427856445, Discriminator Loss: 0.0033700396306812763\n",
      "Epoch: 38/50, Generator Loss: 23.7164363861084, Discriminator Loss: 0.8154252171516418\n",
      "Epoch: 39/50, Generator Loss: 7.030479431152344, Discriminator Loss: 0.014498482458293438\n",
      "Epoch: 40/50, Generator Loss: 7.241899013519287, Discriminator Loss: 0.07728434354066849\n",
      "Epoch: 41/50, Generator Loss: 7.118607521057129, Discriminator Loss: 0.10336720198392868\n",
      "Epoch: 42/50, Generator Loss: 4.92954683303833, Discriminator Loss: 0.07772676646709442\n",
      "Epoch: 43/50, Generator Loss: 7.385085582733154, Discriminator Loss: 0.12370235472917557\n",
      "Epoch: 44/50, Generator Loss: 8.540777206420898, Discriminator Loss: 0.19771166145801544\n",
      "Epoch: 45/50, Generator Loss: 11.479264259338379, Discriminator Loss: 0.011846690438687801\n",
      "Epoch: 46/50, Generator Loss: 7.342005252838135, Discriminator Loss: 0.012880450114607811\n",
      "Epoch: 47/50, Generator Loss: 18.1726131439209, Discriminator Loss: 0.23933063447475433\n",
      "Epoch: 48/50, Generator Loss: 28.75975799560547, Discriminator Loss: 0.03248406946659088\n",
      "Epoch: 49/50, Generator Loss: 5.184650421142578, Discriminator Loss: 0.08472734689712524\n",
      "Epoch: 50/50, Generator Loss: 6.000332355499268, Discriminator Loss: 0.025586020201444626\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.7470\n",
      "Function value obtained: -6.0003\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "Epoch: 1/76, Generator Loss: 3.7059338092803955, Discriminator Loss: 2.322232961654663\n",
      "Epoch: 2/76, Generator Loss: 1.3887468576431274, Discriminator Loss: 1.4603663682937622\n",
      "Epoch: 3/76, Generator Loss: 1.4334203004837036, Discriminator Loss: 3.242392063140869\n",
      "Epoch: 4/76, Generator Loss: 0.7842936515808105, Discriminator Loss: 3.0723369121551514\n",
      "Epoch: 5/76, Generator Loss: 3.9144246578216553, Discriminator Loss: 7.388425827026367\n",
      "Epoch: 6/76, Generator Loss: 3.689913034439087, Discriminator Loss: 16.773162841796875\n",
      "Epoch: 7/76, Generator Loss: 1.5851696729660034, Discriminator Loss: 1.4524290561676025\n",
      "Epoch: 8/76, Generator Loss: 1.0347529649734497, Discriminator Loss: 1.3386967182159424\n",
      "Epoch: 9/76, Generator Loss: 2.9872751235961914, Discriminator Loss: 1.370112419128418\n",
      "Epoch: 10/76, Generator Loss: 1.1004496812820435, Discriminator Loss: 1.4762039184570312\n",
      "Epoch: 11/76, Generator Loss: 1.1955595016479492, Discriminator Loss: 1.70381498336792\n",
      "Epoch: 12/76, Generator Loss: 1.4850102663040161, Discriminator Loss: 4.7390522956848145\n",
      "Epoch: 13/76, Generator Loss: 2.4061028957366943, Discriminator Loss: 0.9120585918426514\n",
      "Epoch: 14/76, Generator Loss: 4.348729133605957, Discriminator Loss: 16.846256256103516\n",
      "Epoch: 15/76, Generator Loss: 2.0596160888671875, Discriminator Loss: 1.0808537006378174\n",
      "Epoch: 16/76, Generator Loss: 1.35341477394104, Discriminator Loss: 1.3987653255462646\n",
      "Epoch: 17/76, Generator Loss: 2.4525535106658936, Discriminator Loss: 1.7483059167861938\n",
      "Epoch: 18/76, Generator Loss: 2.1850626468658447, Discriminator Loss: 0.4978072941303253\n",
      "Epoch: 19/76, Generator Loss: 3.6383860111236572, Discriminator Loss: 2.919191360473633\n",
      "Epoch: 20/76, Generator Loss: 4.039190292358398, Discriminator Loss: 3.5511977672576904\n",
      "Epoch: 21/76, Generator Loss: 1.8630053997039795, Discriminator Loss: 1.8650996685028076\n",
      "Epoch: 22/76, Generator Loss: 4.120493412017822, Discriminator Loss: 0.7710392475128174\n",
      "Epoch: 23/76, Generator Loss: 0.49437686800956726, Discriminator Loss: 9.511754035949707\n",
      "Epoch: 24/76, Generator Loss: 1.9681507349014282, Discriminator Loss: 6.977480888366699\n",
      "Epoch: 25/76, Generator Loss: 1.0593713521957397, Discriminator Loss: 1.7017760276794434\n",
      "Epoch: 26/76, Generator Loss: 1.219312310218811, Discriminator Loss: 1.2487995624542236\n",
      "Epoch: 27/76, Generator Loss: 2.0908730030059814, Discriminator Loss: 0.8587446212768555\n",
      "Epoch: 28/76, Generator Loss: 0.8769680857658386, Discriminator Loss: 1.6284334659576416\n",
      "Epoch: 29/76, Generator Loss: 1.0434435606002808, Discriminator Loss: 1.6104896068572998\n",
      "Epoch: 30/76, Generator Loss: 1.0539735555648804, Discriminator Loss: 1.7538247108459473\n",
      "Epoch: 31/76, Generator Loss: 1.5830363035202026, Discriminator Loss: 0.9839470386505127\n",
      "Epoch: 32/76, Generator Loss: 1.1131610870361328, Discriminator Loss: 1.6358587741851807\n",
      "Epoch: 33/76, Generator Loss: 1.2547224760055542, Discriminator Loss: 1.608312964439392\n",
      "Epoch: 34/76, Generator Loss: 1.493009090423584, Discriminator Loss: 2.1516315937042236\n",
      "Epoch: 35/76, Generator Loss: 0.8697170615196228, Discriminator Loss: 4.923203468322754\n",
      "Epoch: 36/76, Generator Loss: 1.105341911315918, Discriminator Loss: 8.925241470336914\n",
      "Epoch: 37/76, Generator Loss: 1.834529995918274, Discriminator Loss: 3.521124839782715\n",
      "Epoch: 38/76, Generator Loss: 1.6559407711029053, Discriminator Loss: 2.1639013290405273\n",
      "Epoch: 39/76, Generator Loss: 3.2558116912841797, Discriminator Loss: 2.813650131225586\n",
      "Epoch: 40/76, Generator Loss: 3.501168966293335, Discriminator Loss: 0.6341749429702759\n",
      "Epoch: 41/76, Generator Loss: 0.8824933171272278, Discriminator Loss: 1.7838808298110962\n",
      "Epoch: 42/76, Generator Loss: 1.2133811712265015, Discriminator Loss: 4.683427333831787\n",
      "Epoch: 43/76, Generator Loss: 2.862011432647705, Discriminator Loss: 0.47300010919570923\n",
      "Epoch: 44/76, Generator Loss: 2.066148281097412, Discriminator Loss: 0.5711837410926819\n",
      "Epoch: 45/76, Generator Loss: 1.497218132019043, Discriminator Loss: 3.2833611965179443\n",
      "Epoch: 46/76, Generator Loss: 1.055639624595642, Discriminator Loss: 3.778261184692383\n",
      "Epoch: 47/76, Generator Loss: 4.428513526916504, Discriminator Loss: 0.5588245391845703\n",
      "Epoch: 48/76, Generator Loss: 2.305969715118408, Discriminator Loss: 0.9250279664993286\n",
      "Epoch: 49/76, Generator Loss: 0.9186052680015564, Discriminator Loss: 5.3637495040893555\n",
      "Epoch: 50/76, Generator Loss: 1.1695085763931274, Discriminator Loss: 2.312859296798706\n",
      "Epoch: 51/76, Generator Loss: 1.8535460233688354, Discriminator Loss: 1.4565942287445068\n",
      "Epoch: 52/76, Generator Loss: 2.3362927436828613, Discriminator Loss: 2.1150429248809814\n",
      "Epoch: 53/76, Generator Loss: 1.3311365842819214, Discriminator Loss: 5.219435214996338\n",
      "Epoch: 54/76, Generator Loss: 1.3194406032562256, Discriminator Loss: 1.87460458278656\n",
      "Epoch: 55/76, Generator Loss: 6.60599946975708, Discriminator Loss: 5.555129528045654\n",
      "Epoch: 56/76, Generator Loss: 9.942671775817871, Discriminator Loss: 1.6001434326171875\n",
      "Epoch: 57/76, Generator Loss: 4.719510078430176, Discriminator Loss: 22.692920684814453\n",
      "Epoch: 58/76, Generator Loss: 5.008794712324516e-09, Discriminator Loss: 100.23229217529297\n",
      "Epoch: 59/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/76, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 22.6014\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "Epoch: 1/93, Generator Loss: 2.928576707839966, Discriminator Loss: 0.8870162963867188\n",
      "Epoch: 2/93, Generator Loss: 6.5280680656433105, Discriminator Loss: 0.12955385446548462\n",
      "Epoch: 3/93, Generator Loss: 3.531636953353882, Discriminator Loss: 0.3243025541305542\n",
      "Epoch: 4/93, Generator Loss: 3.8783674240112305, Discriminator Loss: 0.5711103081703186\n",
      "Epoch: 5/93, Generator Loss: 5.844081401824951, Discriminator Loss: 0.4670606255531311\n",
      "Epoch: 6/93, Generator Loss: 5.306251049041748, Discriminator Loss: 0.12238526344299316\n",
      "Epoch: 7/93, Generator Loss: 13.217369079589844, Discriminator Loss: 0.3509311378002167\n",
      "Epoch: 8/93, Generator Loss: 5.093772888183594, Discriminator Loss: 0.5121151208877563\n",
      "Epoch: 9/93, Generator Loss: 39.606544494628906, Discriminator Loss: 6.55391263961792\n",
      "Epoch: 10/93, Generator Loss: 7.48980712890625, Discriminator Loss: 0.40603765845298767\n",
      "Epoch: 11/93, Generator Loss: 6.709574222564697, Discriminator Loss: 0.03171072155237198\n",
      "Epoch: 12/93, Generator Loss: 7.152822971343994, Discriminator Loss: 0.2532636225223541\n",
      "Epoch: 13/93, Generator Loss: 7.3252997398376465, Discriminator Loss: 0.05972463637590408\n",
      "Epoch: 14/93, Generator Loss: 10.630024909973145, Discriminator Loss: 0.0587800033390522\n",
      "Epoch: 15/93, Generator Loss: 6.147594451904297, Discriminator Loss: 0.005322582088410854\n",
      "Epoch: 16/93, Generator Loss: 19.666929244995117, Discriminator Loss: 0.12366961687803268\n",
      "Epoch: 17/93, Generator Loss: 62.827972412109375, Discriminator Loss: 0.027346763759851456\n",
      "Epoch: 18/93, Generator Loss: 54.87040328979492, Discriminator Loss: 0.00010249736806144938\n",
      "Epoch: 19/93, Generator Loss: 53.97130584716797, Discriminator Loss: 7.965872646309435e-05\n",
      "Epoch: 20/93, Generator Loss: 52.54582595825195, Discriminator Loss: 7.845485379220918e-05\n",
      "Epoch: 21/93, Generator Loss: 53.227176666259766, Discriminator Loss: 4.129284934606403e-05\n",
      "Epoch: 22/93, Generator Loss: 52.03054428100586, Discriminator Loss: 0.0002279731270391494\n",
      "Epoch: 23/93, Generator Loss: 51.5032844543457, Discriminator Loss: 4.883570727542974e-05\n",
      "Epoch: 24/93, Generator Loss: 52.41033172607422, Discriminator Loss: 5.529413829208352e-05\n",
      "Epoch: 25/93, Generator Loss: 51.6395263671875, Discriminator Loss: 2.9291755708982237e-05\n",
      "Epoch: 26/93, Generator Loss: 51.256011962890625, Discriminator Loss: 3.54924522980582e-05\n",
      "Epoch: 27/93, Generator Loss: 50.110782623291016, Discriminator Loss: 1.7268097508349456e-05\n",
      "Epoch: 28/93, Generator Loss: 51.0181884765625, Discriminator Loss: 3.093568011536263e-05\n",
      "Epoch: 29/93, Generator Loss: 50.14552688598633, Discriminator Loss: 2.130916982423514e-05\n",
      "Epoch: 30/93, Generator Loss: 50.054100036621094, Discriminator Loss: 2.2657801309833303e-05\n",
      "Epoch: 31/93, Generator Loss: 49.885135650634766, Discriminator Loss: 3.425899558351375e-05\n",
      "Epoch: 32/93, Generator Loss: 49.04325866699219, Discriminator Loss: 2.0207744455547072e-05\n",
      "Epoch: 33/93, Generator Loss: 82.8186264038086, Discriminator Loss: 0.00022225019347388297\n",
      "Epoch: 34/93, Generator Loss: 79.36126708984375, Discriminator Loss: 8.133728260872886e-05\n",
      "Epoch: 35/93, Generator Loss: 78.51809692382812, Discriminator Loss: 7.923640077933669e-05\n",
      "Epoch: 36/93, Generator Loss: 76.91643524169922, Discriminator Loss: 6.102450061007403e-05\n",
      "Epoch: 37/93, Generator Loss: 77.59896850585938, Discriminator Loss: 2.905210385506507e-05\n",
      "Epoch: 38/93, Generator Loss: 76.89361572265625, Discriminator Loss: 5.426374627859332e-05\n",
      "Epoch: 39/93, Generator Loss: 76.7115249633789, Discriminator Loss: 2.644894084369298e-05\n",
      "Epoch: 40/93, Generator Loss: 76.13912200927734, Discriminator Loss: 2.742689503065776e-05\n",
      "Epoch: 41/93, Generator Loss: 76.11698150634766, Discriminator Loss: 2.329650305910036e-05\n",
      "Epoch: 42/93, Generator Loss: 76.29387664794922, Discriminator Loss: 2.232000588264782e-05\n",
      "Epoch: 43/93, Generator Loss: 76.11272430419922, Discriminator Loss: 4.28468338213861e-05\n",
      "Epoch: 44/93, Generator Loss: 75.26448059082031, Discriminator Loss: 2.63170604739571e-05\n",
      "Epoch: 45/93, Generator Loss: 75.30793762207031, Discriminator Loss: 1.3807220966555178e-05\n",
      "Epoch: 46/93, Generator Loss: 75.32333374023438, Discriminator Loss: 1.2614602383109741e-05\n",
      "Epoch: 47/93, Generator Loss: 74.76461029052734, Discriminator Loss: 1.0068883966596331e-05\n",
      "Epoch: 48/93, Generator Loss: 75.2187728881836, Discriminator Loss: 1.2143883395765442e-05\n",
      "Epoch: 49/93, Generator Loss: 75.04231262207031, Discriminator Loss: 4.98881900057313e-06\n",
      "Epoch: 50/93, Generator Loss: 74.9100341796875, Discriminator Loss: 7.577995802421356e-06\n",
      "Epoch: 51/93, Generator Loss: 74.35433959960938, Discriminator Loss: 1.8256969269714318e-05\n",
      "Epoch: 52/93, Generator Loss: 74.04349517822266, Discriminator Loss: 1.3949780623079278e-05\n",
      "Epoch: 53/93, Generator Loss: 74.75102996826172, Discriminator Loss: 7.068628747219918e-06\n",
      "Epoch: 54/93, Generator Loss: 74.26700592041016, Discriminator Loss: 9.426454198546708e-06\n",
      "Epoch: 55/93, Generator Loss: 74.69200134277344, Discriminator Loss: 7.613196430611424e-06\n",
      "Epoch: 56/93, Generator Loss: 73.48374938964844, Discriminator Loss: 6.451452009059722e-06\n",
      "Epoch: 57/93, Generator Loss: 73.9801025390625, Discriminator Loss: 6.5081439970526844e-06\n",
      "Epoch: 58/93, Generator Loss: 73.7132568359375, Discriminator Loss: 1.2231656000949442e-05\n",
      "Epoch: 59/93, Generator Loss: 73.2294692993164, Discriminator Loss: 4.3797294893010985e-06\n",
      "Epoch: 60/93, Generator Loss: 74.25420379638672, Discriminator Loss: 4.222476036375156e-06\n",
      "Epoch: 61/93, Generator Loss: 73.1762466430664, Discriminator Loss: 8.30828048492549e-06\n",
      "Epoch: 62/93, Generator Loss: 73.01715850830078, Discriminator Loss: 5.7041120271605905e-06\n",
      "Epoch: 63/93, Generator Loss: 72.74066162109375, Discriminator Loss: 1.127509221987566e-05\n",
      "Epoch: 64/93, Generator Loss: 72.97101593017578, Discriminator Loss: 7.292617738130502e-06\n",
      "Epoch: 65/93, Generator Loss: 72.24990844726562, Discriminator Loss: 1.8763054185910732e-06\n",
      "Epoch: 66/93, Generator Loss: 73.15258026123047, Discriminator Loss: 8.18378794065211e-06\n",
      "Epoch: 67/93, Generator Loss: 72.32070922851562, Discriminator Loss: 2.8269964786886703e-06\n",
      "Epoch: 68/93, Generator Loss: 72.27664947509766, Discriminator Loss: 4.0933014133770484e-06\n",
      "Epoch: 69/93, Generator Loss: 72.54175567626953, Discriminator Loss: 2.9111422463756753e-06\n",
      "Epoch: 70/93, Generator Loss: 73.11637878417969, Discriminator Loss: 4.277676907804562e-06\n",
      "Epoch: 71/93, Generator Loss: 72.17202758789062, Discriminator Loss: 4.428912689036224e-06\n",
      "Epoch: 72/93, Generator Loss: 71.95966339111328, Discriminator Loss: 3.969051249441691e-06\n",
      "Epoch: 73/93, Generator Loss: 71.78584289550781, Discriminator Loss: 3.064414840991958e-06\n",
      "Epoch: 74/93, Generator Loss: 71.39042663574219, Discriminator Loss: 2.3431339286617003e-06\n",
      "Epoch: 75/93, Generator Loss: 72.37943267822266, Discriminator Loss: 1.7921565813594498e-06\n",
      "Epoch: 76/93, Generator Loss: 70.78043365478516, Discriminator Loss: 2.8029435270582326e-06\n",
      "Epoch: 77/93, Generator Loss: 72.19352722167969, Discriminator Loss: 2.404247197773657e-06\n",
      "Epoch: 78/93, Generator Loss: 70.9398193359375, Discriminator Loss: 3.3048422665160615e-06\n",
      "Epoch: 79/93, Generator Loss: 70.79283905029297, Discriminator Loss: 2.681793375813868e-06\n",
      "Epoch: 80/93, Generator Loss: 70.70521545410156, Discriminator Loss: 2.773905407593702e-06\n",
      "Epoch: 81/93, Generator Loss: 71.1393814086914, Discriminator Loss: 2.6366931251686765e-06\n",
      "Epoch: 82/93, Generator Loss: 71.22422790527344, Discriminator Loss: 2.1918701804679586e-06\n",
      "Epoch: 83/93, Generator Loss: 71.29576110839844, Discriminator Loss: 2.7659282295644516e-06\n",
      "Epoch: 84/93, Generator Loss: 70.14973449707031, Discriminator Loss: 9.296354619436897e-07\n",
      "Epoch: 85/93, Generator Loss: 70.62843322753906, Discriminator Loss: 9.456633165427775e-07\n",
      "Epoch: 86/93, Generator Loss: 70.38912200927734, Discriminator Loss: 1.3894504036215949e-06\n",
      "Epoch: 87/93, Generator Loss: 69.94001007080078, Discriminator Loss: 1.5898060610197717e-06\n",
      "Epoch: 88/93, Generator Loss: 70.11711883544922, Discriminator Loss: 2.3351924482994946e-06\n",
      "Epoch: 89/93, Generator Loss: 69.95348358154297, Discriminator Loss: 1.3894480161980027e-06\n",
      "Epoch: 90/93, Generator Loss: 70.25444793701172, Discriminator Loss: 1.3664080142916646e-06\n",
      "Epoch: 91/93, Generator Loss: 70.27249145507812, Discriminator Loss: 1.4846189060335746e-06\n",
      "Epoch: 92/93, Generator Loss: 69.84622192382812, Discriminator Loss: 8.274578817690781e-07\n",
      "Epoch: 93/93, Generator Loss: 70.07307434082031, Discriminator Loss: 1.2131376934121363e-06\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 28.1977\n",
      "Function value obtained: -70.0731\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "Epoch: 1/57, Generator Loss: 3.4553470611572266, Discriminator Loss: 0.7360185980796814\n",
      "Epoch: 2/57, Generator Loss: 3.0326523780822754, Discriminator Loss: 0.7643476724624634\n",
      "Epoch: 3/57, Generator Loss: 25.13470458984375, Discriminator Loss: 9.99238395690918\n",
      "Epoch: 4/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/57, Generator Loss: 0.0, Discriminator Loss: 100.00009155273438\n",
      "Epoch: 19/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/57, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 16.9092\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "Epoch: 1/41, Generator Loss: 0.9936054348945618, Discriminator Loss: 3.984257221221924\n",
      "Epoch: 2/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/41, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.3749\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "Epoch: 1/62, Generator Loss: 2.56821870803833, Discriminator Loss: 1.0405439138412476\n",
      "Epoch: 2/62, Generator Loss: 2.6684463024139404, Discriminator Loss: 0.3365744352340698\n",
      "Epoch: 3/62, Generator Loss: 2.222890853881836, Discriminator Loss: 0.561611533164978\n",
      "Epoch: 4/62, Generator Loss: 6.132557392120361, Discriminator Loss: 0.28305783867836\n",
      "Epoch: 5/62, Generator Loss: 3.5794081687927246, Discriminator Loss: 0.06703680753707886\n",
      "Epoch: 6/62, Generator Loss: 9.133650779724121, Discriminator Loss: 0.4998096823692322\n",
      "Epoch: 7/62, Generator Loss: 5.389476299285889, Discriminator Loss: 0.010009989142417908\n",
      "Epoch: 8/62, Generator Loss: 13.839555740356445, Discriminator Loss: 0.010026397183537483\n",
      "Epoch: 9/62, Generator Loss: 4.430466175079346, Discriminator Loss: 0.4988860487937927\n",
      "Epoch: 10/62, Generator Loss: 21.293977737426758, Discriminator Loss: 0.5160669088363647\n",
      "Epoch: 11/62, Generator Loss: 7.9668169021606445, Discriminator Loss: 0.1973114162683487\n",
      "Epoch: 12/62, Generator Loss: 6.069358825683594, Discriminator Loss: 0.5019381642341614\n",
      "Epoch: 13/62, Generator Loss: 5.8684306144714355, Discriminator Loss: 0.06479868292808533\n",
      "Epoch: 14/62, Generator Loss: 4.421528339385986, Discriminator Loss: 0.021216798573732376\n",
      "Epoch: 15/62, Generator Loss: 22.00851821899414, Discriminator Loss: 0.790180504322052\n",
      "Epoch: 16/62, Generator Loss: 6.076882839202881, Discriminator Loss: 0.04446813836693764\n",
      "Epoch: 17/62, Generator Loss: 59.009952545166016, Discriminator Loss: 0.01197085902094841\n",
      "Epoch: 18/62, Generator Loss: 21.1697998046875, Discriminator Loss: 0.30585727095603943\n",
      "Epoch: 19/62, Generator Loss: 5.099058628082275, Discriminator Loss: 0.6950247883796692\n",
      "Epoch: 20/62, Generator Loss: 5.835303783416748, Discriminator Loss: 0.003995254635810852\n",
      "Epoch: 21/62, Generator Loss: 81.313720703125, Discriminator Loss: 0.04139520972967148\n",
      "Epoch: 22/62, Generator Loss: 74.05392456054688, Discriminator Loss: 7.1680397013551556e-06\n",
      "Epoch: 23/62, Generator Loss: 75.90563201904297, Discriminator Loss: 0.00013135385233908892\n",
      "Epoch: 24/62, Generator Loss: 75.4720687866211, Discriminator Loss: 2.1103867766214535e-05\n",
      "Epoch: 25/62, Generator Loss: 74.98345947265625, Discriminator Loss: 2.1704247046727687e-05\n",
      "Epoch: 26/62, Generator Loss: 74.06971740722656, Discriminator Loss: 6.707626198476646e-06\n",
      "Epoch: 27/62, Generator Loss: 74.34506225585938, Discriminator Loss: 8.276748303615022e-06\n",
      "Epoch: 28/62, Generator Loss: 74.63794708251953, Discriminator Loss: 3.9810843190934975e-06\n",
      "Epoch: 29/62, Generator Loss: 73.78106689453125, Discriminator Loss: 3.146582002955256e-06\n",
      "Epoch: 30/62, Generator Loss: 73.85075378417969, Discriminator Loss: 0.00010531661246204749\n",
      "Epoch: 31/62, Generator Loss: 73.99756622314453, Discriminator Loss: 1.2852658528572647e-06\n",
      "Epoch: 32/62, Generator Loss: 73.48792266845703, Discriminator Loss: 7.96050881035626e-05\n",
      "Epoch: 33/62, Generator Loss: 73.74601745605469, Discriminator Loss: 7.452162662957562e-06\n",
      "Epoch: 34/62, Generator Loss: 73.68912506103516, Discriminator Loss: 4.767105565406382e-05\n",
      "Epoch: 35/62, Generator Loss: 73.51412200927734, Discriminator Loss: 3.763538188650273e-05\n",
      "Epoch: 36/62, Generator Loss: 73.58305358886719, Discriminator Loss: 3.022864075319376e-05\n",
      "Epoch: 37/62, Generator Loss: 74.3614273071289, Discriminator Loss: 7.586350420751842e-06\n",
      "Epoch: 38/62, Generator Loss: 73.24235534667969, Discriminator Loss: 3.7386498661362566e-06\n",
      "Epoch: 39/62, Generator Loss: 73.71041870117188, Discriminator Loss: 2.6637299015419558e-06\n",
      "Epoch: 40/62, Generator Loss: 74.72802734375, Discriminator Loss: 3.199312232027296e-06\n",
      "Epoch: 41/62, Generator Loss: 73.18490600585938, Discriminator Loss: 3.204176391591318e-05\n",
      "Epoch: 42/62, Generator Loss: 73.35572814941406, Discriminator Loss: 4.617209924617782e-06\n",
      "Epoch: 43/62, Generator Loss: 72.82130432128906, Discriminator Loss: 3.1155379929259652e-06\n",
      "Epoch: 44/62, Generator Loss: 73.28208923339844, Discriminator Loss: 2.3531511033070274e-06\n",
      "Epoch: 45/62, Generator Loss: 72.87703704833984, Discriminator Loss: 5.77743867324898e-06\n",
      "Epoch: 46/62, Generator Loss: 72.87213134765625, Discriminator Loss: 1.98950920093921e-06\n",
      "Epoch: 47/62, Generator Loss: 72.35791778564453, Discriminator Loss: 1.953471155502484e-06\n",
      "Epoch: 48/62, Generator Loss: 73.0251693725586, Discriminator Loss: 4.047906259074807e-06\n",
      "Epoch: 49/62, Generator Loss: 73.30412292480469, Discriminator Loss: 2.9712566629314097e-06\n",
      "Epoch: 50/62, Generator Loss: 72.49435424804688, Discriminator Loss: 8.054177556005016e-07\n",
      "Epoch: 51/62, Generator Loss: 70.53848266601562, Discriminator Loss: 3.1265526558854617e-06\n",
      "Epoch: 52/62, Generator Loss: 72.22295379638672, Discriminator Loss: 4.938883193972288e-06\n",
      "Epoch: 53/62, Generator Loss: 71.66313934326172, Discriminator Loss: 2.442327058815863e-06\n",
      "Epoch: 54/62, Generator Loss: 73.08731842041016, Discriminator Loss: 1.07088874301553e-06\n",
      "Epoch: 55/62, Generator Loss: 72.27391815185547, Discriminator Loss: 1.4405493402591674e-06\n",
      "Epoch: 56/62, Generator Loss: 72.52144622802734, Discriminator Loss: 2.336149918846786e-06\n",
      "Epoch: 57/62, Generator Loss: 72.2813720703125, Discriminator Loss: 3.4444335597072495e-06\n",
      "Epoch: 58/62, Generator Loss: 71.90116882324219, Discriminator Loss: 5.6781896091706585e-06\n",
      "Epoch: 59/62, Generator Loss: 71.85719299316406, Discriminator Loss: 1.9234748833696358e-05\n",
      "Epoch: 60/62, Generator Loss: 71.44959259033203, Discriminator Loss: 1.0418361853226088e-06\n",
      "Epoch: 61/62, Generator Loss: 71.19597625732422, Discriminator Loss: 1.3383607893047156e-06\n",
      "Epoch: 62/62, Generator Loss: 70.2497787475586, Discriminator Loss: 3.7196809898887295e-06\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 18.0602\n",
      "Function value obtained: -70.2498\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "Epoch: 1/44, Generator Loss: 3.3569095134735107, Discriminator Loss: 0.19016557931900024\n",
      "Epoch: 2/44, Generator Loss: 1.5602587461471558, Discriminator Loss: 0.7415941953659058\n",
      "Epoch: 3/44, Generator Loss: 4.351786136627197, Discriminator Loss: 1.3431391716003418\n",
      "Epoch: 4/44, Generator Loss: 7.946488380432129, Discriminator Loss: 3.1532907485961914\n",
      "Epoch: 5/44, Generator Loss: 14.819144248962402, Discriminator Loss: 0.14216239750385284\n",
      "Epoch: 6/44, Generator Loss: 5.715451240539551, Discriminator Loss: 0.215135395526886\n",
      "Epoch: 7/44, Generator Loss: 15.844444274902344, Discriminator Loss: 1.7188804149627686\n",
      "Epoch: 8/44, Generator Loss: 7.629305362701416, Discriminator Loss: 0.052515968680381775\n",
      "Epoch: 9/44, Generator Loss: 4.1690592765808105, Discriminator Loss: 0.3781014084815979\n",
      "Epoch: 10/44, Generator Loss: 4.5637359619140625, Discriminator Loss: 0.23684239387512207\n",
      "Epoch: 11/44, Generator Loss: 11.03956127166748, Discriminator Loss: 0.2040591686964035\n",
      "Epoch: 12/44, Generator Loss: 13.778105735778809, Discriminator Loss: 0.6962525844573975\n",
      "Epoch: 13/44, Generator Loss: 5.209837913513184, Discriminator Loss: 0.021483592689037323\n",
      "Epoch: 14/44, Generator Loss: 5.899235725402832, Discriminator Loss: 0.00914819911122322\n",
      "Epoch: 15/44, Generator Loss: 9.20902156829834, Discriminator Loss: 0.023419806733727455\n",
      "Epoch: 16/44, Generator Loss: 6.620930194854736, Discriminator Loss: 0.052537884563207626\n",
      "Epoch: 17/44, Generator Loss: 8.364531517028809, Discriminator Loss: 0.0003597847535274923\n",
      "Epoch: 18/44, Generator Loss: 28.093366622924805, Discriminator Loss: 0.015421617776155472\n",
      "Epoch: 19/44, Generator Loss: 7.855463981628418, Discriminator Loss: 0.007349795196205378\n",
      "Epoch: 20/44, Generator Loss: 7.111290454864502, Discriminator Loss: 0.7829688787460327\n",
      "Epoch: 21/44, Generator Loss: 37.06936264038086, Discriminator Loss: 0.059919390827417374\n",
      "Epoch: 22/44, Generator Loss: 4.687031269073486, Discriminator Loss: 0.09659918397665024\n",
      "Epoch: 23/44, Generator Loss: 6.882808685302734, Discriminator Loss: 0.0016149129951372743\n",
      "Epoch: 24/44, Generator Loss: 8.728402137756348, Discriminator Loss: 0.00800197571516037\n",
      "Epoch: 25/44, Generator Loss: 8.629446029663086, Discriminator Loss: 0.004137905314564705\n",
      "Epoch: 26/44, Generator Loss: 8.885388374328613, Discriminator Loss: 0.016081444919109344\n",
      "Epoch: 27/44, Generator Loss: 17.646108627319336, Discriminator Loss: 0.17163234949111938\n",
      "Epoch: 28/44, Generator Loss: 13.94365119934082, Discriminator Loss: 0.06140592321753502\n",
      "Epoch: 29/44, Generator Loss: 4.137138843536377, Discriminator Loss: 0.09296271204948425\n",
      "Epoch: 30/44, Generator Loss: 13.77394962310791, Discriminator Loss: 0.00924436841160059\n",
      "Epoch: 31/44, Generator Loss: 10.736623764038086, Discriminator Loss: 0.010811801999807358\n",
      "Epoch: 32/44, Generator Loss: 10.764731407165527, Discriminator Loss: 0.041506893932819366\n",
      "Epoch: 33/44, Generator Loss: 10.606466293334961, Discriminator Loss: 0.08472529798746109\n",
      "Epoch: 34/44, Generator Loss: 9.735554695129395, Discriminator Loss: 0.0038475594483315945\n",
      "Epoch: 35/44, Generator Loss: 8.538125038146973, Discriminator Loss: 0.05618322268128395\n",
      "Epoch: 36/44, Generator Loss: 12.831863403320312, Discriminator Loss: 0.0001092555103241466\n",
      "Epoch: 37/44, Generator Loss: 6.327446460723877, Discriminator Loss: 0.03016137331724167\n",
      "Epoch: 38/44, Generator Loss: 7.435679912567139, Discriminator Loss: 0.006449871696531773\n",
      "Epoch: 39/44, Generator Loss: 25.850736618041992, Discriminator Loss: 0.022970914840698242\n",
      "Epoch: 40/44, Generator Loss: 6.155533790588379, Discriminator Loss: 0.03178515285253525\n",
      "Epoch: 41/44, Generator Loss: 9.73393440246582, Discriminator Loss: 0.004650369752198458\n",
      "Epoch: 42/44, Generator Loss: 11.8589448928833, Discriminator Loss: 0.019476698711514473\n",
      "Epoch: 43/44, Generator Loss: 9.73681926727295, Discriminator Loss: 0.0031855355482548475\n",
      "Epoch: 44/44, Generator Loss: 11.34616756439209, Discriminator Loss: 0.00023605521710123867\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.1085\n",
      "Function value obtained: -11.3462\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "Epoch: 1/89, Generator Loss: 3.478712320327759, Discriminator Loss: 3.9906270503997803\n",
      "Epoch: 2/89, Generator Loss: 0.7719894051551819, Discriminator Loss: 1.1717029809951782\n",
      "Epoch: 3/89, Generator Loss: 0.9952980279922485, Discriminator Loss: 1.058422327041626\n",
      "Epoch: 4/89, Generator Loss: 0.9899138808250427, Discriminator Loss: 1.511512279510498\n",
      "Epoch: 5/89, Generator Loss: 1.220555067062378, Discriminator Loss: 1.353620171546936\n",
      "Epoch: 6/89, Generator Loss: 1.1733440160751343, Discriminator Loss: 1.3600249290466309\n",
      "Epoch: 7/89, Generator Loss: 0.9050041437149048, Discriminator Loss: 1.053816795349121\n",
      "Epoch: 8/89, Generator Loss: 1.0914088487625122, Discriminator Loss: 2.7996764183044434\n",
      "Epoch: 9/89, Generator Loss: 2.3387396335601807, Discriminator Loss: 0.6674913167953491\n",
      "Epoch: 10/89, Generator Loss: 1.1264654397964478, Discriminator Loss: 1.1405093669891357\n",
      "Epoch: 11/89, Generator Loss: 1.3950815200805664, Discriminator Loss: 1.1383951902389526\n",
      "Epoch: 12/89, Generator Loss: 1.4112987518310547, Discriminator Loss: 0.948380708694458\n",
      "Epoch: 13/89, Generator Loss: 1.209734559059143, Discriminator Loss: 1.6366902589797974\n",
      "Epoch: 14/89, Generator Loss: 2.2144927978515625, Discriminator Loss: 0.3937505781650543\n",
      "Epoch: 15/89, Generator Loss: 0.8277310132980347, Discriminator Loss: 1.1380081176757812\n",
      "Epoch: 16/89, Generator Loss: 1.078900933265686, Discriminator Loss: 2.8289761543273926\n",
      "Epoch: 17/89, Generator Loss: 1.888755440711975, Discriminator Loss: 1.1131457090377808\n",
      "Epoch: 18/89, Generator Loss: 1.6196552515029907, Discriminator Loss: 0.8200401067733765\n",
      "Epoch: 19/89, Generator Loss: 1.1035727262496948, Discriminator Loss: 1.315605878829956\n",
      "Epoch: 20/89, Generator Loss: 0.6115732789039612, Discriminator Loss: 1.7616024017333984\n",
      "Epoch: 21/89, Generator Loss: 0.9206851124763489, Discriminator Loss: 2.7222096920013428\n",
      "Epoch: 22/89, Generator Loss: 0.7566072344779968, Discriminator Loss: 1.6000362634658813\n",
      "Epoch: 23/89, Generator Loss: 0.934191882610321, Discriminator Loss: 1.2993443012237549\n",
      "Epoch: 24/89, Generator Loss: 1.0297508239746094, Discriminator Loss: 1.4959461688995361\n",
      "Epoch: 25/89, Generator Loss: 1.0980454683303833, Discriminator Loss: 1.330628752708435\n",
      "Epoch: 26/89, Generator Loss: 0.7382761836051941, Discriminator Loss: 2.0780744552612305\n",
      "Epoch: 27/89, Generator Loss: 2.59987211227417, Discriminator Loss: 1.630272388458252\n",
      "Epoch: 28/89, Generator Loss: 0.786735475063324, Discriminator Loss: 1.2525112628936768\n",
      "Epoch: 29/89, Generator Loss: 0.8925679326057434, Discriminator Loss: 1.8959813117980957\n",
      "Epoch: 30/89, Generator Loss: 1.2743555307388306, Discriminator Loss: 0.856088399887085\n",
      "Epoch: 31/89, Generator Loss: 0.8980241417884827, Discriminator Loss: 0.786145806312561\n",
      "Epoch: 32/89, Generator Loss: 0.9431861639022827, Discriminator Loss: 1.4171326160430908\n",
      "Epoch: 33/89, Generator Loss: 0.918907642364502, Discriminator Loss: 2.8422465324401855\n",
      "Epoch: 34/89, Generator Loss: 1.0031020641326904, Discriminator Loss: 1.6050821542739868\n",
      "Epoch: 35/89, Generator Loss: 1.0219841003417969, Discriminator Loss: 2.5301012992858887\n",
      "Epoch: 36/89, Generator Loss: 0.8869606256484985, Discriminator Loss: 1.747194528579712\n",
      "Epoch: 37/89, Generator Loss: 2.7825820446014404, Discriminator Loss: 0.8130051493644714\n",
      "Epoch: 38/89, Generator Loss: 2.703256368637085, Discriminator Loss: 1.0839848518371582\n",
      "Epoch: 39/89, Generator Loss: 0.7460654973983765, Discriminator Loss: 1.2442166805267334\n",
      "Epoch: 40/89, Generator Loss: 1.0087393522262573, Discriminator Loss: 1.3378558158874512\n",
      "Epoch: 41/89, Generator Loss: 1.1417351961135864, Discriminator Loss: 0.5830792188644409\n",
      "Epoch: 42/89, Generator Loss: 0.9101986289024353, Discriminator Loss: 1.1120246648788452\n",
      "Epoch: 43/89, Generator Loss: 0.5809917449951172, Discriminator Loss: 1.4449799060821533\n",
      "Epoch: 44/89, Generator Loss: 0.8405587673187256, Discriminator Loss: 1.3052579164505005\n",
      "Epoch: 45/89, Generator Loss: 1.2709962129592896, Discriminator Loss: 2.3331918716430664\n",
      "Epoch: 46/89, Generator Loss: 0.9517219662666321, Discriminator Loss: 1.177268624305725\n",
      "Epoch: 47/89, Generator Loss: 1.0239131450653076, Discriminator Loss: 1.5014312267303467\n",
      "Epoch: 48/89, Generator Loss: 0.8407042026519775, Discriminator Loss: 1.2900785207748413\n",
      "Epoch: 49/89, Generator Loss: 0.9561018943786621, Discriminator Loss: 1.476161241531372\n",
      "Epoch: 50/89, Generator Loss: 0.5684586763381958, Discriminator Loss: 1.5916497707366943\n",
      "Epoch: 51/89, Generator Loss: 1.1268680095672607, Discriminator Loss: 1.1895334720611572\n",
      "Epoch: 52/89, Generator Loss: 1.2503910064697266, Discriminator Loss: 1.516385793685913\n",
      "Epoch: 53/89, Generator Loss: 1.3406316041946411, Discriminator Loss: 1.0097085237503052\n",
      "Epoch: 54/89, Generator Loss: 2.7364487648010254, Discriminator Loss: 2.47373104095459\n",
      "Epoch: 55/89, Generator Loss: 1.0495719909667969, Discriminator Loss: 1.3855540752410889\n",
      "Epoch: 56/89, Generator Loss: 0.9972344636917114, Discriminator Loss: 1.2229118347167969\n",
      "Epoch: 57/89, Generator Loss: 0.7507026195526123, Discriminator Loss: 1.1167232990264893\n",
      "Epoch: 58/89, Generator Loss: 0.7865864038467407, Discriminator Loss: 1.3871963024139404\n",
      "Epoch: 59/89, Generator Loss: 0.716200590133667, Discriminator Loss: 1.425045371055603\n",
      "Epoch: 60/89, Generator Loss: 0.6982994079589844, Discriminator Loss: 1.4700055122375488\n",
      "Epoch: 61/89, Generator Loss: 1.022901177406311, Discriminator Loss: 1.4096379280090332\n",
      "Epoch: 62/89, Generator Loss: 0.7192075252532959, Discriminator Loss: 1.3689851760864258\n",
      "Epoch: 63/89, Generator Loss: 0.692597508430481, Discriminator Loss: 1.4204330444335938\n",
      "Epoch: 64/89, Generator Loss: 0.704876720905304, Discriminator Loss: 1.3788764476776123\n",
      "Epoch: 65/89, Generator Loss: 0.698397159576416, Discriminator Loss: 1.3800196647644043\n",
      "Epoch: 66/89, Generator Loss: 0.6946531534194946, Discriminator Loss: 1.3719388246536255\n",
      "Epoch: 67/89, Generator Loss: 0.715115487575531, Discriminator Loss: 1.2772092819213867\n",
      "Epoch: 68/89, Generator Loss: 0.9222543239593506, Discriminator Loss: 0.8716186881065369\n",
      "Epoch: 69/89, Generator Loss: 1.1705108880996704, Discriminator Loss: 0.8281235694885254\n",
      "Epoch: 70/89, Generator Loss: 1.0097898244857788, Discriminator Loss: 1.4667956829071045\n",
      "Epoch: 71/89, Generator Loss: 0.8129311203956604, Discriminator Loss: 1.2721610069274902\n",
      "Epoch: 72/89, Generator Loss: 0.9717485904693604, Discriminator Loss: 1.3088254928588867\n",
      "Epoch: 73/89, Generator Loss: 0.40470126271247864, Discriminator Loss: 1.6670485734939575\n",
      "Epoch: 74/89, Generator Loss: 0.8809188604354858, Discriminator Loss: 1.573434591293335\n",
      "Epoch: 75/89, Generator Loss: 1.162225365638733, Discriminator Loss: 1.5364258289337158\n",
      "Epoch: 76/89, Generator Loss: 0.9247921705245972, Discriminator Loss: 1.4299461841583252\n",
      "Epoch: 77/89, Generator Loss: 0.7976102232933044, Discriminator Loss: 1.3923351764678955\n",
      "Epoch: 78/89, Generator Loss: 0.7361888885498047, Discriminator Loss: 1.3845763206481934\n",
      "Epoch: 79/89, Generator Loss: 0.7140334248542786, Discriminator Loss: 1.3841218948364258\n",
      "Epoch: 80/89, Generator Loss: 0.7025195360183716, Discriminator Loss: 1.3814529180526733\n",
      "Epoch: 81/89, Generator Loss: 0.7207850813865662, Discriminator Loss: 0.8422147035598755\n",
      "Epoch: 82/89, Generator Loss: 0.7777372598648071, Discriminator Loss: 1.4054954051971436\n",
      "Epoch: 83/89, Generator Loss: 0.7198352217674255, Discriminator Loss: 1.3872783184051514\n",
      "Epoch: 84/89, Generator Loss: 0.7026681303977966, Discriminator Loss: 1.3869636058807373\n",
      "Epoch: 85/89, Generator Loss: 0.6987900137901306, Discriminator Loss: 1.3866288661956787\n",
      "Epoch: 86/89, Generator Loss: 0.6950300931930542, Discriminator Loss: 1.3867621421813965\n",
      "Epoch: 87/89, Generator Loss: 0.6969741582870483, Discriminator Loss: 1.3781931400299072\n",
      "Epoch: 88/89, Generator Loss: 0.6936978101730347, Discriminator Loss: 1.3806066513061523\n",
      "Epoch: 89/89, Generator Loss: 0.7069535255432129, Discriminator Loss: 1.3838112354278564\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 23.6809\n",
      "Function value obtained: -0.7070\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "Epoch: 1/77, Generator Loss: 4.664962291717529, Discriminator Loss: 0.10579018294811249\n",
      "Epoch: 2/77, Generator Loss: 7.749139308929443, Discriminator Loss: 2.9653525352478027\n",
      "Epoch: 3/77, Generator Loss: 2.66499400138855, Discriminator Loss: 0.5240858793258667\n",
      "Epoch: 4/77, Generator Loss: 8.078372955322266, Discriminator Loss: 0.004726708866655827\n",
      "Epoch: 5/77, Generator Loss: 5.683300495147705, Discriminator Loss: 0.02330959215760231\n",
      "Epoch: 6/77, Generator Loss: 12.358948707580566, Discriminator Loss: 0.18008142709732056\n",
      "Epoch: 7/77, Generator Loss: 3.9605822563171387, Discriminator Loss: 0.21673662960529327\n",
      "Epoch: 8/77, Generator Loss: 7.769867897033691, Discriminator Loss: 0.003722645342350006\n",
      "Epoch: 9/77, Generator Loss: 69.921630859375, Discriminator Loss: 5.994055391056463e-05\n",
      "Epoch: 10/77, Generator Loss: 55.11357879638672, Discriminator Loss: 8.014073848983116e-09\n",
      "Epoch: 11/77, Generator Loss: 55.232383728027344, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 12/77, Generator Loss: 54.85138702392578, Discriminator Loss: 8.615010349092882e-22\n",
      "Epoch: 13/77, Generator Loss: 55.01374053955078, Discriminator Loss: 4.153583802233857e-24\n",
      "Epoch: 14/77, Generator Loss: 55.16270065307617, Discriminator Loss: 1.602815657975043e-08\n",
      "Epoch: 15/77, Generator Loss: 55.05044937133789, Discriminator Loss: 1.5818979769653912e-22\n",
      "Epoch: 16/77, Generator Loss: 55.27754211425781, Discriminator Loss: 4.5386240490590645e-24\n",
      "Epoch: 17/77, Generator Loss: 54.84474182128906, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 18/77, Generator Loss: 54.934688568115234, Discriminator Loss: 3.452825643921096e-24\n",
      "Epoch: 19/77, Generator Loss: 55.02861404418945, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 20/77, Generator Loss: 54.877079010009766, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 21/77, Generator Loss: 55.25760269165039, Discriminator Loss: 2.8771181107344224e-24\n",
      "Epoch: 22/77, Generator Loss: 55.08538055419922, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 23/77, Generator Loss: 55.031925201416016, Discriminator Loss: 3.8534853366696796e-24\n",
      "Epoch: 24/77, Generator Loss: 54.94783401489258, Discriminator Loss: 1.1670324612583695e-23\n",
      "Epoch: 25/77, Generator Loss: 54.94784927368164, Discriminator Loss: 5.880819208903324e-23\n",
      "Epoch: 26/77, Generator Loss: 54.64347457885742, Discriminator Loss: 4.744010059962325e-23\n",
      "Epoch: 27/77, Generator Loss: 55.20040512084961, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 28/77, Generator Loss: 55.112545013427734, Discriminator Loss: 1.3679169951781675e-23\n",
      "Epoch: 29/77, Generator Loss: 55.13335037231445, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 30/77, Generator Loss: 55.149776458740234, Discriminator Loss: 7.299629092065282e-22\n",
      "Epoch: 31/77, Generator Loss: 55.17320251464844, Discriminator Loss: 2.302039891334889e-24\n",
      "Epoch: 32/77, Generator Loss: 55.232147216796875, Discriminator Loss: 2.5525284722915273e-24\n",
      "Epoch: 33/77, Generator Loss: 55.01478958129883, Discriminator Loss: 7.114970007016251e-24\n",
      "Epoch: 34/77, Generator Loss: 54.8126106262207, Discriminator Loss: 3.8066922058987984e-08\n",
      "Epoch: 35/77, Generator Loss: 54.95506286621094, Discriminator Loss: 4.933650091653012e-24\n",
      "Epoch: 36/77, Generator Loss: 54.94831085205078, Discriminator Loss: 1.142012777677337e-07\n",
      "Epoch: 37/77, Generator Loss: 54.99228286743164, Discriminator Loss: 4.007035592223929e-09\n",
      "Epoch: 38/77, Generator Loss: 55.00132751464844, Discriminator Loss: 1.6028293714498432e-07\n",
      "Epoch: 39/77, Generator Loss: 54.94845962524414, Discriminator Loss: 1.3731483420483587e-22\n",
      "Epoch: 40/77, Generator Loss: 55.0546989440918, Discriminator Loss: 7.739952158925744e-24\n",
      "Epoch: 41/77, Generator Loss: 54.98564147949219, Discriminator Loss: 7.01231384070411e-09\n",
      "Epoch: 42/77, Generator Loss: 54.98830032348633, Discriminator Loss: 4.426868885629572e-24\n",
      "Epoch: 43/77, Generator Loss: 54.98291015625, Discriminator Loss: 4.651355427858768e-24\n",
      "Epoch: 44/77, Generator Loss: 55.05841827392578, Discriminator Loss: 1.2389536030237625e-18\n",
      "Epoch: 45/77, Generator Loss: 55.08599853515625, Discriminator Loss: 2.8156534611014937e-23\n",
      "Epoch: 46/77, Generator Loss: 55.107666015625, Discriminator Loss: 1.1714500823276072e-23\n",
      "Epoch: 47/77, Generator Loss: 55.01260757446289, Discriminator Loss: 3.0052769162125514e-09\n",
      "Epoch: 48/77, Generator Loss: 54.82317352294922, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 49/77, Generator Loss: 55.04261016845703, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 50/77, Generator Loss: 55.10850524902344, Discriminator Loss: 2.0035177961119643e-09\n",
      "Epoch: 51/77, Generator Loss: 55.0643310546875, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 52/77, Generator Loss: 54.888092041015625, Discriminator Loss: 3.606339404882419e-08\n",
      "Epoch: 53/77, Generator Loss: 54.9524040222168, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 54/77, Generator Loss: 54.76436233520508, Discriminator Loss: 4.1621342655855475e-23\n",
      "Epoch: 55/77, Generator Loss: 54.857215881347656, Discriminator Loss: 7.615539327841528e-24\n",
      "Epoch: 56/77, Generator Loss: 55.06027603149414, Discriminator Loss: 3.0052769162125514e-09\n",
      "Epoch: 57/77, Generator Loss: 54.81021499633789, Discriminator Loss: 9.015834301351333e-09\n",
      "Epoch: 58/77, Generator Loss: 54.996883392333984, Discriminator Loss: 5.200726050863733e-24\n",
      "Epoch: 59/77, Generator Loss: 54.92912292480469, Discriminator Loss: 6.728386353829978e-24\n",
      "Epoch: 60/77, Generator Loss: 54.62575912475586, Discriminator Loss: 3.743212206222826e-23\n",
      "Epoch: 61/77, Generator Loss: 54.99630355834961, Discriminator Loss: 9.255552750803424e-24\n",
      "Epoch: 62/77, Generator Loss: 54.81867218017578, Discriminator Loss: 2.0035177961119643e-09\n",
      "Epoch: 63/77, Generator Loss: 54.91136169433594, Discriminator Loss: 1.5026392574668535e-08\n",
      "Epoch: 64/77, Generator Loss: 54.78873062133789, Discriminator Loss: 1.2584326466242265e-19\n",
      "Epoch: 65/77, Generator Loss: 54.808685302734375, Discriminator Loss: 3.0052769162125514e-09\n",
      "Epoch: 66/77, Generator Loss: 54.87091064453125, Discriminator Loss: 1.3724206837650854e-07\n",
      "Epoch: 67/77, Generator Loss: 54.868988037109375, Discriminator Loss: 1.374679584174265e-23\n",
      "Epoch: 68/77, Generator Loss: 54.607234954833984, Discriminator Loss: 2.0035177961119643e-09\n",
      "Epoch: 69/77, Generator Loss: 54.89436721801758, Discriminator Loss: 5.172731743920155e-24\n",
      "Epoch: 70/77, Generator Loss: 54.89336013793945, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 71/77, Generator Loss: 54.70848846435547, Discriminator Loss: 4.839234879781183e-24\n",
      "Epoch: 72/77, Generator Loss: 54.90408706665039, Discriminator Loss: 1.0807556118013432e-23\n",
      "Epoch: 73/77, Generator Loss: 54.93986511230469, Discriminator Loss: 3.832479154055002e-24\n",
      "Epoch: 74/77, Generator Loss: 54.72322463989258, Discriminator Loss: 3.964820431667142e-24\n",
      "Epoch: 75/77, Generator Loss: 54.984615325927734, Discriminator Loss: 3.710404901124313e-24\n",
      "Epoch: 76/77, Generator Loss: 54.61810302734375, Discriminator Loss: 3.3594919603503246e-23\n",
      "Epoch: 77/77, Generator Loss: 54.73075866699219, Discriminator Loss: 2.0035177961119643e-09\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 22.8442\n",
      "Function value obtained: -54.7308\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "Epoch: 1/67, Generator Loss: 1.1468521356582642, Discriminator Loss: 0.6299692392349243\n",
      "Epoch: 2/67, Generator Loss: 4.399072170257568, Discriminator Loss: 2.0076963901519775\n",
      "Epoch: 3/67, Generator Loss: 1.1727672815322876, Discriminator Loss: 0.998408317565918\n",
      "Epoch: 4/67, Generator Loss: 0.8787606358528137, Discriminator Loss: 0.8503367900848389\n",
      "Epoch: 5/67, Generator Loss: 0.8638257384300232, Discriminator Loss: 0.9774433374404907\n",
      "Epoch: 6/67, Generator Loss: 1.2638992071151733, Discriminator Loss: 1.415748119354248\n",
      "Epoch: 7/67, Generator Loss: 0.8802777528762817, Discriminator Loss: 1.480055570602417\n",
      "Epoch: 8/67, Generator Loss: 0.6855639815330505, Discriminator Loss: 1.8203718662261963\n",
      "Epoch: 9/67, Generator Loss: 0.8979727029800415, Discriminator Loss: 2.3334784507751465\n",
      "Epoch: 10/67, Generator Loss: 1.47325599193573, Discriminator Loss: 0.9852173328399658\n",
      "Epoch: 11/67, Generator Loss: 1.0294418334960938, Discriminator Loss: 2.2351927757263184\n",
      "Epoch: 12/67, Generator Loss: 2.7313554286956787, Discriminator Loss: 1.1023054122924805\n",
      "Epoch: 13/67, Generator Loss: 2.5020318031311035, Discriminator Loss: 2.39143967628479\n",
      "Epoch: 14/67, Generator Loss: 1.938226580619812, Discriminator Loss: 2.6235220432281494\n",
      "Epoch: 15/67, Generator Loss: 1.0880099534988403, Discriminator Loss: 1.4701248407363892\n",
      "Epoch: 16/67, Generator Loss: 1.7927048206329346, Discriminator Loss: 0.641310453414917\n",
      "Epoch: 17/67, Generator Loss: 1.3632179498672485, Discriminator Loss: 2.560366153717041\n",
      "Epoch: 18/67, Generator Loss: 0.8296669721603394, Discriminator Loss: 1.4684021472930908\n",
      "Epoch: 19/67, Generator Loss: 1.3997331857681274, Discriminator Loss: 1.0795445442199707\n",
      "Epoch: 20/67, Generator Loss: 1.0195099115371704, Discriminator Loss: 1.1974561214447021\n",
      "Epoch: 21/67, Generator Loss: 0.7022659182548523, Discriminator Loss: 1.3863508701324463\n",
      "Epoch: 22/67, Generator Loss: 1.507836937904358, Discriminator Loss: 1.6423821449279785\n",
      "Epoch: 23/67, Generator Loss: 4.128840923309326, Discriminator Loss: 4.04909610748291\n",
      "Epoch: 24/67, Generator Loss: 0.9356951713562012, Discriminator Loss: 0.6969236135482788\n",
      "Epoch: 25/67, Generator Loss: 0.8882191777229309, Discriminator Loss: 0.8900164365768433\n",
      "Epoch: 26/67, Generator Loss: 0.8089456558227539, Discriminator Loss: 0.9609569311141968\n",
      "Epoch: 27/67, Generator Loss: 0.6677993535995483, Discriminator Loss: 1.210313320159912\n",
      "Epoch: 28/67, Generator Loss: 1.5630481243133545, Discriminator Loss: 0.9352128505706787\n",
      "Epoch: 29/67, Generator Loss: 1.025101661682129, Discriminator Loss: 1.8343175649642944\n",
      "Epoch: 30/67, Generator Loss: 1.0215193033218384, Discriminator Loss: 1.3451526165008545\n",
      "Epoch: 31/67, Generator Loss: 1.8965847492218018, Discriminator Loss: 1.2428102493286133\n",
      "Epoch: 32/67, Generator Loss: 0.5244801640510559, Discriminator Loss: 1.3297474384307861\n",
      "Epoch: 33/67, Generator Loss: 1.0235071182250977, Discriminator Loss: 3.885009288787842\n",
      "Epoch: 34/67, Generator Loss: 2.108988046646118, Discriminator Loss: 1.4047788381576538\n",
      "Epoch: 35/67, Generator Loss: 0.7981017827987671, Discriminator Loss: 2.4055635929107666\n",
      "Epoch: 36/67, Generator Loss: 1.6953186988830566, Discriminator Loss: 3.820751667022705\n",
      "Epoch: 37/67, Generator Loss: 2.968411684036255, Discriminator Loss: 0.47510629892349243\n",
      "Epoch: 38/67, Generator Loss: 0.9043766856193542, Discriminator Loss: 1.492882251739502\n",
      "Epoch: 39/67, Generator Loss: 0.9146093726158142, Discriminator Loss: 1.651700735092163\n",
      "Epoch: 40/67, Generator Loss: 0.8822000026702881, Discriminator Loss: 1.0830250978469849\n",
      "Epoch: 41/67, Generator Loss: 0.5029093027114868, Discriminator Loss: 2.4732038974761963\n",
      "Epoch: 42/67, Generator Loss: 0.7958451509475708, Discriminator Loss: 3.254979372024536\n",
      "Epoch: 43/67, Generator Loss: 1.2573362588882446, Discriminator Loss: 1.4129747152328491\n",
      "Epoch: 44/67, Generator Loss: 1.4068894386291504, Discriminator Loss: 1.37421452999115\n",
      "Epoch: 45/67, Generator Loss: 1.284778356552124, Discriminator Loss: 0.8209767937660217\n",
      "Epoch: 46/67, Generator Loss: 0.8804077506065369, Discriminator Loss: 1.6519687175750732\n",
      "Epoch: 47/67, Generator Loss: 0.9436622858047485, Discriminator Loss: 1.5022016763687134\n",
      "Epoch: 48/67, Generator Loss: 1.10538649559021, Discriminator Loss: 1.048829436302185\n",
      "Epoch: 49/67, Generator Loss: 1.2591763734817505, Discriminator Loss: 1.399914026260376\n",
      "Epoch: 50/67, Generator Loss: 0.8680857419967651, Discriminator Loss: 1.2410621643066406\n",
      "Epoch: 51/67, Generator Loss: 1.2697052955627441, Discriminator Loss: 0.7943152785301208\n",
      "Epoch: 52/67, Generator Loss: 0.7930920124053955, Discriminator Loss: 1.2105077505111694\n",
      "Epoch: 53/67, Generator Loss: 0.8340264558792114, Discriminator Loss: 1.4168295860290527\n",
      "Epoch: 54/67, Generator Loss: 0.8707019090652466, Discriminator Loss: 1.2429369688034058\n",
      "Epoch: 55/67, Generator Loss: 0.9844189882278442, Discriminator Loss: 1.4303230047225952\n",
      "Epoch: 56/67, Generator Loss: 0.910336434841156, Discriminator Loss: 1.4934577941894531\n",
      "Epoch: 57/67, Generator Loss: 0.9152559638023376, Discriminator Loss: 1.2626283168792725\n",
      "Epoch: 58/67, Generator Loss: 0.9849161505699158, Discriminator Loss: 0.6550809144973755\n",
      "Epoch: 59/67, Generator Loss: 1.0652313232421875, Discriminator Loss: 1.484259843826294\n",
      "Epoch: 60/67, Generator Loss: 0.7522178292274475, Discriminator Loss: 1.3319904804229736\n",
      "Epoch: 61/67, Generator Loss: 0.7851330041885376, Discriminator Loss: 1.364058256149292\n",
      "Epoch: 62/67, Generator Loss: 1.1677303314208984, Discriminator Loss: 2.810581922531128\n",
      "Epoch: 63/67, Generator Loss: 0.696794867515564, Discriminator Loss: 1.930476427078247\n",
      "Epoch: 64/67, Generator Loss: 2.079643487930298, Discriminator Loss: 1.2166615724563599\n",
      "Epoch: 65/67, Generator Loss: 1.2185341119766235, Discriminator Loss: 1.4290485382080078\n",
      "Epoch: 66/67, Generator Loss: 1.9865128993988037, Discriminator Loss: 1.2942891120910645\n",
      "Epoch: 67/67, Generator Loss: 0.5505018830299377, Discriminator Loss: 1.3624627590179443\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 20.3561\n",
      "Function value obtained: -0.5505\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "Epoch: 1/83, Generator Loss: 2.8558599948883057, Discriminator Loss: 0.14793428778648376\n",
      "Epoch: 2/83, Generator Loss: 3.822598695755005, Discriminator Loss: 1.4983142614364624\n",
      "Epoch: 3/83, Generator Loss: 16.74009132385254, Discriminator Loss: 4.523250102996826\n",
      "Epoch: 4/83, Generator Loss: 9.83598518371582, Discriminator Loss: 0.3744519054889679\n",
      "Epoch: 5/83, Generator Loss: 8.562700271606445, Discriminator Loss: 0.38969185948371887\n",
      "Epoch: 6/83, Generator Loss: 7.3507513999938965, Discriminator Loss: 0.24471041560173035\n",
      "Epoch: 7/83, Generator Loss: 8.718473434448242, Discriminator Loss: 0.029745209962129593\n",
      "Epoch: 8/83, Generator Loss: 3.3670434951782227, Discriminator Loss: 0.006675831973552704\n",
      "Epoch: 9/83, Generator Loss: 35.008384704589844, Discriminator Loss: 0.6821008324623108\n",
      "Epoch: 10/83, Generator Loss: 2.5258102416992188, Discriminator Loss: 0.017330311238765717\n",
      "Epoch: 11/83, Generator Loss: 6.345187664031982, Discriminator Loss: 0.04653842747211456\n",
      "Epoch: 12/83, Generator Loss: 6.341961860656738, Discriminator Loss: 0.03255988657474518\n",
      "Epoch: 13/83, Generator Loss: 5.403432369232178, Discriminator Loss: 0.004678179044276476\n",
      "Epoch: 14/83, Generator Loss: 10.242399215698242, Discriminator Loss: 0.00026160446577705443\n",
      "Epoch: 15/83, Generator Loss: 22.896486282348633, Discriminator Loss: 0.04705603048205376\n",
      "Epoch: 16/83, Generator Loss: 13.44715404510498, Discriminator Loss: 0.0009573413408361375\n",
      "Epoch: 17/83, Generator Loss: 7.39589786529541, Discriminator Loss: 0.0012827933533117175\n",
      "Epoch: 18/83, Generator Loss: 11.543532371520996, Discriminator Loss: 1.841323683038354e-05\n",
      "Epoch: 19/83, Generator Loss: 8.335973739624023, Discriminator Loss: 0.0004054427263326943\n",
      "Epoch: 20/83, Generator Loss: 8.130712509155273, Discriminator Loss: 0.003451722441241145\n",
      "Epoch: 21/83, Generator Loss: 7.773868560791016, Discriminator Loss: 0.0006556244334205985\n",
      "Epoch: 22/83, Generator Loss: 7.615301609039307, Discriminator Loss: 0.0023975474759936333\n",
      "Epoch: 23/83, Generator Loss: 15.524052619934082, Discriminator Loss: 0.032438069581985474\n",
      "Epoch: 24/83, Generator Loss: 7.331396579742432, Discriminator Loss: 0.0027971421368420124\n",
      "Epoch: 25/83, Generator Loss: 41.060123443603516, Discriminator Loss: 0.00692019471898675\n",
      "Epoch: 26/83, Generator Loss: 0.0017841163789853454, Discriminator Loss: 4.202239036560059\n",
      "Epoch: 27/83, Generator Loss: 26.78683853149414, Discriminator Loss: 0.0068253991194069386\n",
      "Epoch: 28/83, Generator Loss: 4.911986351013184, Discriminator Loss: 0.06712132692337036\n",
      "Epoch: 29/83, Generator Loss: 5.130056381225586, Discriminator Loss: 0.10572417080402374\n",
      "Epoch: 30/83, Generator Loss: 6.852250099182129, Discriminator Loss: 0.005794926080852747\n",
      "Epoch: 31/83, Generator Loss: 7.682788372039795, Discriminator Loss: 0.0029265524353832006\n",
      "Epoch: 32/83, Generator Loss: 25.730613708496094, Discriminator Loss: 0.0012866910547018051\n",
      "Epoch: 33/83, Generator Loss: 8.611833572387695, Discriminator Loss: 0.04126310721039772\n",
      "Epoch: 34/83, Generator Loss: 12.337038040161133, Discriminator Loss: 0.22331158816814423\n",
      "Epoch: 35/83, Generator Loss: 4.728025436401367, Discriminator Loss: 0.04850965738296509\n",
      "Epoch: 36/83, Generator Loss: 8.952507972717285, Discriminator Loss: 0.00612778402864933\n",
      "Epoch: 37/83, Generator Loss: 13.439265251159668, Discriminator Loss: 0.00203256169334054\n",
      "Epoch: 38/83, Generator Loss: 8.0176420211792, Discriminator Loss: 0.02690373733639717\n",
      "Epoch: 39/83, Generator Loss: 5.4686808586120605, Discriminator Loss: 0.02757754921913147\n",
      "Epoch: 40/83, Generator Loss: 17.43292999267578, Discriminator Loss: 0.12883950769901276\n",
      "Epoch: 41/83, Generator Loss: 4.927042007446289, Discriminator Loss: 0.07991756498813629\n",
      "Epoch: 42/83, Generator Loss: 20.258625030517578, Discriminator Loss: 0.010781572200357914\n",
      "Epoch: 43/83, Generator Loss: 7.122046947479248, Discriminator Loss: 0.0033799726516008377\n",
      "Epoch: 44/83, Generator Loss: 13.331718444824219, Discriminator Loss: 0.09166161715984344\n",
      "Epoch: 45/83, Generator Loss: 19.66046905517578, Discriminator Loss: 0.07264655828475952\n",
      "Epoch: 46/83, Generator Loss: 6.586561679840088, Discriminator Loss: 0.029594209045171738\n",
      "Epoch: 47/83, Generator Loss: 11.469406127929688, Discriminator Loss: 0.030611928552389145\n",
      "Epoch: 48/83, Generator Loss: 12.348428726196289, Discriminator Loss: 0.024408655241131783\n",
      "Epoch: 49/83, Generator Loss: 9.381772994995117, Discriminator Loss: 0.003638495923951268\n",
      "Epoch: 50/83, Generator Loss: 53.44084930419922, Discriminator Loss: 0.0012223398080095649\n",
      "Epoch: 51/83, Generator Loss: 48.70237731933594, Discriminator Loss: 1.6028619711505598e-06\n",
      "Epoch: 52/83, Generator Loss: 48.5063591003418, Discriminator Loss: 2.331892119400436e-06\n",
      "Epoch: 53/83, Generator Loss: 48.57059860229492, Discriminator Loss: 1.8432427850711974e-07\n",
      "Epoch: 54/83, Generator Loss: 48.480873107910156, Discriminator Loss: 8.815482743784742e-08\n",
      "Epoch: 55/83, Generator Loss: 48.44916534423828, Discriminator Loss: 1.0268557844028692e-06\n",
      "Epoch: 56/83, Generator Loss: 48.35533142089844, Discriminator Loss: 1.3724124414693506e-07\n",
      "Epoch: 57/83, Generator Loss: 47.89049530029297, Discriminator Loss: 4.5580182472804154e-07\n",
      "Epoch: 58/83, Generator Loss: 48.46124267578125, Discriminator Loss: 6.471479423453275e-07\n",
      "Epoch: 59/83, Generator Loss: 48.182762145996094, Discriminator Loss: 2.2055203316995176e-06\n",
      "Epoch: 60/83, Generator Loss: 48.01295852661133, Discriminator Loss: 3.31583436263827e-07\n",
      "Epoch: 61/83, Generator Loss: 48.05490493774414, Discriminator Loss: 2.0593361114151776e-06\n",
      "Epoch: 62/83, Generator Loss: 47.8592643737793, Discriminator Loss: 2.098799086525105e-06\n",
      "Epoch: 63/83, Generator Loss: 47.51436996459961, Discriminator Loss: 8.986128250398906e-07\n",
      "Epoch: 64/83, Generator Loss: 47.87014389038086, Discriminator Loss: 3.5963375921710394e-07\n",
      "Epoch: 65/83, Generator Loss: 47.92461013793945, Discriminator Loss: 4.568085500977759e-07\n",
      "Epoch: 66/83, Generator Loss: 47.724151611328125, Discriminator Loss: 4.908650339530141e-07\n",
      "Epoch: 67/83, Generator Loss: 47.64867401123047, Discriminator Loss: 3.2156648899217544e-07\n",
      "Epoch: 68/83, Generator Loss: 47.77473068237305, Discriminator Loss: 7.222868134704186e-07\n",
      "Epoch: 69/83, Generator Loss: 47.53190231323242, Discriminator Loss: 3.426041530474322e-07\n",
      "Epoch: 70/83, Generator Loss: 47.563636779785156, Discriminator Loss: 1.3333828064787667e-05\n",
      "Epoch: 71/83, Generator Loss: 47.63286590576172, Discriminator Loss: 1.3824298150666436e-07\n",
      "Epoch: 72/83, Generator Loss: 47.418060302734375, Discriminator Loss: 1.1821413181678508e-06\n",
      "Epoch: 73/83, Generator Loss: 47.48790740966797, Discriminator Loss: 1.2031864571326878e-06\n",
      "Epoch: 74/83, Generator Loss: 47.486602783203125, Discriminator Loss: 8.715315402696433e-08\n",
      "Epoch: 75/83, Generator Loss: 47.2755012512207, Discriminator Loss: 2.5745387688402843e-07\n",
      "Epoch: 76/83, Generator Loss: 47.37624740600586, Discriminator Loss: 3.666459349460638e-07\n",
      "Epoch: 77/83, Generator Loss: 47.30466079711914, Discriminator Loss: 8.815494112468514e-08\n",
      "Epoch: 78/83, Generator Loss: 46.85175704956055, Discriminator Loss: 1.382432941454681e-07\n",
      "Epoch: 79/83, Generator Loss: 47.047943115234375, Discriminator Loss: 4.4478858285401657e-07\n",
      "Epoch: 80/83, Generator Loss: 47.32111740112305, Discriminator Loss: 4.678276184222341e-07\n",
      "Epoch: 81/83, Generator Loss: 46.9796257019043, Discriminator Loss: 2.564529779647273e-07\n",
      "Epoch: 82/83, Generator Loss: 46.78759765625, Discriminator Loss: 1.7430636489734752e-07\n",
      "Epoch: 83/83, Generator Loss: 47.06329345703125, Discriminator Loss: 2.6446761580700695e-07\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 25.0769\n",
      "Function value obtained: -47.0633\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "Epoch: 1/62, Generator Loss: 3.725764036178589, Discriminator Loss: 0.530494213104248\n",
      "Epoch: 2/62, Generator Loss: 3.8302106857299805, Discriminator Loss: 0.038781799376010895\n",
      "Epoch: 3/62, Generator Loss: 6.129525184631348, Discriminator Loss: 0.004458727315068245\n",
      "Epoch: 4/62, Generator Loss: 10.662129402160645, Discriminator Loss: 0.14630331099033356\n",
      "Epoch: 5/62, Generator Loss: 7.877941608428955, Discriminator Loss: 0.0087560024112463\n",
      "Epoch: 6/62, Generator Loss: 3.3103203773498535, Discriminator Loss: 0.15011784434318542\n",
      "Epoch: 7/62, Generator Loss: 3.070930242538452, Discriminator Loss: 0.09066130220890045\n",
      "Epoch: 8/62, Generator Loss: 5.3778204917907715, Discriminator Loss: 0.028277000412344933\n",
      "Epoch: 9/62, Generator Loss: 10.391242980957031, Discriminator Loss: 0.006521856412291527\n",
      "Epoch: 10/62, Generator Loss: 39.95998001098633, Discriminator Loss: 0.004550400655716658\n",
      "Epoch: 11/62, Generator Loss: 8.955904960632324, Discriminator Loss: 0.09978436678647995\n",
      "Epoch: 12/62, Generator Loss: 5.815178871154785, Discriminator Loss: 0.007789133116602898\n",
      "Epoch: 13/62, Generator Loss: 16.14824867248535, Discriminator Loss: 0.002185391029343009\n",
      "Epoch: 14/62, Generator Loss: 11.187127113342285, Discriminator Loss: 0.0003687693679239601\n",
      "Epoch: 15/62, Generator Loss: 5.923627853393555, Discriminator Loss: 0.027291346341371536\n",
      "Epoch: 16/62, Generator Loss: 10.757733345031738, Discriminator Loss: 0.004259135108441114\n",
      "Epoch: 17/62, Generator Loss: 5.965240478515625, Discriminator Loss: 0.023623423650860786\n",
      "Epoch: 18/62, Generator Loss: 8.824895858764648, Discriminator Loss: 0.0016941442154347897\n",
      "Epoch: 19/62, Generator Loss: 16.196949005126953, Discriminator Loss: 3.372741412022151e-05\n",
      "Epoch: 20/62, Generator Loss: 11.472807884216309, Discriminator Loss: 2.10160269489279e-05\n",
      "Epoch: 21/62, Generator Loss: 13.479047775268555, Discriminator Loss: 2.2602860553888604e-05\n",
      "Epoch: 22/62, Generator Loss: 10.286293029785156, Discriminator Loss: 8.93852484296076e-05\n",
      "Epoch: 23/62, Generator Loss: 21.05765151977539, Discriminator Loss: 1.4997372090874705e-06\n",
      "Epoch: 24/62, Generator Loss: 10.754937171936035, Discriminator Loss: 7.311870285775512e-05\n",
      "Epoch: 25/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 17.5202\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "Epoch: 1/62, Generator Loss: 4.1862592697143555, Discriminator Loss: 0.34513428807258606\n",
      "Epoch: 2/62, Generator Loss: 5.280791759490967, Discriminator Loss: 0.13217392563819885\n",
      "Epoch: 3/62, Generator Loss: 7.199878692626953, Discriminator Loss: 5.570967674255371\n",
      "Epoch: 4/62, Generator Loss: 100.00000762939453, Discriminator Loss: 3.0052769162125514e-09\n",
      "Epoch: 5/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 6/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 7/62, Generator Loss: 100.00000762939453, Discriminator Loss: 5.600194526778068e-06\n",
      "Epoch: 8/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 9/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 10/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 11/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 12/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 13/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 14/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 15/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 16/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 17/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 18/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 19/62, Generator Loss: 100.00000762939453, Discriminator Loss: 2.459176812408259e-06\n",
      "Epoch: 20/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 21/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 22/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 23/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 24/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 25/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 26/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 27/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 28/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 29/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 30/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 31/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 32/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 33/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 34/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 35/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 36/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 37/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 38/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 39/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 40/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 41/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 42/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 43/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 44/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 45/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 46/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 47/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 48/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 49/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 50/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 51/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 52/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 53/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 54/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 55/62, Generator Loss: 100.00000762939453, Discriminator Loss: 8.405176004089299e-07\n",
      "Epoch: 56/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 57/62, Generator Loss: 100.00000762939453, Discriminator Loss: 8.365342182514723e-06\n",
      "Epoch: 58/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 59/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 60/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 61/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 62/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 15.4014\n",
      "Function value obtained: -100.0000\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "Epoch: 1/62, Generator Loss: 0.6637285351753235, Discriminator Loss: 1.0662689208984375\n",
      "Epoch: 2/62, Generator Loss: 41.89509963989258, Discriminator Loss: 14.579289436340332\n",
      "Epoch: 3/62, Generator Loss: 20.58942413330078, Discriminator Loss: 0.00017459638183936477\n",
      "Epoch: 4/62, Generator Loss: 0.041290514171123505, Discriminator Loss: 3.969306707382202\n",
      "Epoch: 5/62, Generator Loss: 0.009575197473168373, Discriminator Loss: 22.57181167602539\n",
      "Epoch: 6/62, Generator Loss: 0.012164677493274212, Discriminator Loss: 19.56876564025879\n",
      "Epoch: 7/62, Generator Loss: 0.019026795402169228, Discriminator Loss: 112.41033935546875\n",
      "Epoch: 8/62, Generator Loss: 7.0753350257873535, Discriminator Loss: 18.18367576599121\n",
      "Epoch: 9/62, Generator Loss: 0.020903632044792175, Discriminator Loss: 21.25604248046875\n",
      "Epoch: 10/62, Generator Loss: 7.183154582977295, Discriminator Loss: 11.334254264831543\n",
      "Epoch: 11/62, Generator Loss: 100.00000762939453, Discriminator Loss: 4.989253520965576\n",
      "Epoch: 12/62, Generator Loss: 100.00000762939453, Discriminator Loss: 2.6236095428466797\n",
      "Epoch: 13/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.4037173390388489\n",
      "Epoch: 14/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 15/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.6854602098464966\n",
      "Epoch: 16/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 17/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 18/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 19/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 20/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 21/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 22/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 23/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 24/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 25/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 26/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 27/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 28/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 29/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 30/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 31/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 32/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 33/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 34/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 35/62, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 36/62, Generator Loss: 99.5553970336914, Discriminator Loss: 3.2460095859688507e-24\n",
      "Epoch: 37/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/62, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 16.3531\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "Epoch: 1/64, Generator Loss: 0.8734593391418457, Discriminator Loss: 1.9260942935943604\n",
      "Epoch: 2/64, Generator Loss: 2.1286463737487793, Discriminator Loss: 0.8243041634559631\n",
      "Epoch: 3/64, Generator Loss: 5.379793643951416, Discriminator Loss: 0.43390417098999023\n",
      "Epoch: 4/64, Generator Loss: 4.635920524597168, Discriminator Loss: 0.7664961218833923\n",
      "Epoch: 5/64, Generator Loss: 8.942605972290039, Discriminator Loss: 1.5892345905303955\n",
      "Epoch: 6/64, Generator Loss: 3.193049430847168, Discriminator Loss: 1.5607234239578247\n",
      "Epoch: 7/64, Generator Loss: 4.607195854187012, Discriminator Loss: 0.12875063717365265\n",
      "Epoch: 8/64, Generator Loss: 5.114941596984863, Discriminator Loss: 0.22938066720962524\n",
      "Epoch: 9/64, Generator Loss: 5.544750690460205, Discriminator Loss: 0.14621251821517944\n",
      "Epoch: 10/64, Generator Loss: 8.018848419189453, Discriminator Loss: 0.4261476993560791\n",
      "Epoch: 11/64, Generator Loss: 6.037614345550537, Discriminator Loss: 0.06396611034870148\n",
      "Epoch: 12/64, Generator Loss: 7.0644211769104, Discriminator Loss: 0.7611543536186218\n",
      "Epoch: 13/64, Generator Loss: 6.640966892242432, Discriminator Loss: 0.9792693853378296\n",
      "Epoch: 14/64, Generator Loss: 10.342031478881836, Discriminator Loss: 0.16742022335529327\n",
      "Epoch: 15/64, Generator Loss: 4.754664897918701, Discriminator Loss: 0.1643233597278595\n",
      "Epoch: 16/64, Generator Loss: 5.624423980712891, Discriminator Loss: 0.07404889166355133\n",
      "Epoch: 17/64, Generator Loss: 8.476093292236328, Discriminator Loss: 0.3706875443458557\n",
      "Epoch: 18/64, Generator Loss: 4.881597995758057, Discriminator Loss: 0.031342655420303345\n",
      "Epoch: 19/64, Generator Loss: 10.739537239074707, Discriminator Loss: 0.15691478550434113\n",
      "Epoch: 20/64, Generator Loss: 13.787078857421875, Discriminator Loss: 0.03239539638161659\n",
      "Epoch: 21/64, Generator Loss: 6.686946392059326, Discriminator Loss: 0.10048732906579971\n",
      "Epoch: 22/64, Generator Loss: 17.34307861328125, Discriminator Loss: 0.06484004110097885\n",
      "Epoch: 23/64, Generator Loss: 5.886134147644043, Discriminator Loss: 0.018158450722694397\n",
      "Epoch: 24/64, Generator Loss: 9.365060806274414, Discriminator Loss: 0.0061465417966246605\n",
      "Epoch: 25/64, Generator Loss: 24.521432876586914, Discriminator Loss: 0.36024388670921326\n",
      "Epoch: 26/64, Generator Loss: 4.981204509735107, Discriminator Loss: 0.010250505059957504\n",
      "Epoch: 27/64, Generator Loss: 37.066932678222656, Discriminator Loss: 0.0001410383847542107\n",
      "Epoch: 28/64, Generator Loss: 4.405837059020996, Discriminator Loss: 0.08133823424577713\n",
      "Epoch: 29/64, Generator Loss: 4.784326553344727, Discriminator Loss: 0.02454296126961708\n",
      "Epoch: 30/64, Generator Loss: 34.13819122314453, Discriminator Loss: 7.341417949646711e-05\n",
      "Epoch: 31/64, Generator Loss: 6.906593322753906, Discriminator Loss: 0.007441374473273754\n",
      "Epoch: 32/64, Generator Loss: 19.750099182128906, Discriminator Loss: 1.0268264304613695e-05\n",
      "Epoch: 33/64, Generator Loss: 13.818181991577148, Discriminator Loss: 0.0003985624643974006\n",
      "Epoch: 34/64, Generator Loss: 15.349753379821777, Discriminator Loss: 5.8646368415793404e-05\n",
      "Epoch: 35/64, Generator Loss: 41.3283576965332, Discriminator Loss: 7.947793346829712e-05\n",
      "Epoch: 36/64, Generator Loss: 99.22359466552734, Discriminator Loss: 0.00025785082834772766\n",
      "Epoch: 37/64, Generator Loss: 95.86957550048828, Discriminator Loss: 1.8760094462777488e-05\n",
      "Epoch: 38/64, Generator Loss: 90.09131622314453, Discriminator Loss: 9.249290997104254e-06\n",
      "Epoch: 39/64, Generator Loss: 88.5124282836914, Discriminator Loss: 0.0005061659612692893\n",
      "Epoch: 40/64, Generator Loss: 86.96894073486328, Discriminator Loss: 1.1940211152250413e-05\n",
      "Epoch: 41/64, Generator Loss: 87.00611114501953, Discriminator Loss: 1.809308560041245e-05\n",
      "Epoch: 42/64, Generator Loss: 86.3095703125, Discriminator Loss: 2.5950967028620653e-05\n",
      "Epoch: 43/64, Generator Loss: 85.97850036621094, Discriminator Loss: 4.436421295395121e-05\n",
      "Epoch: 44/64, Generator Loss: 85.82227325439453, Discriminator Loss: 5.2251136366976425e-05\n",
      "Epoch: 45/64, Generator Loss: 86.0521011352539, Discriminator Loss: 4.578030711854808e-05\n",
      "Epoch: 46/64, Generator Loss: 85.2882308959961, Discriminator Loss: 8.863959374139085e-05\n",
      "Epoch: 47/64, Generator Loss: 85.21165466308594, Discriminator Loss: 1.0127914720214903e-06\n",
      "Epoch: 48/64, Generator Loss: 85.33190155029297, Discriminator Loss: 5.63632011107984e-06\n",
      "Epoch: 49/64, Generator Loss: 84.85710144042969, Discriminator Loss: 4.8000997594499495e-06\n",
      "Epoch: 50/64, Generator Loss: 84.92678833007812, Discriminator Loss: 4.372511284600478e-06\n",
      "Epoch: 51/64, Generator Loss: 84.80465698242188, Discriminator Loss: 4.204148808639729e-06\n",
      "Epoch: 52/64, Generator Loss: 84.72434997558594, Discriminator Loss: 1.846775194280781e-05\n",
      "Epoch: 53/64, Generator Loss: 84.26136016845703, Discriminator Loss: 1.3963664059701841e-05\n",
      "Epoch: 54/64, Generator Loss: 84.3979263305664, Discriminator Loss: 1.167074401564605e-06\n",
      "Epoch: 55/64, Generator Loss: 84.27757263183594, Discriminator Loss: 1.3042234058957547e-05\n",
      "Epoch: 56/64, Generator Loss: 83.9712142944336, Discriminator Loss: 1.5827822608116549e-07\n",
      "Epoch: 57/64, Generator Loss: 83.87307739257812, Discriminator Loss: 8.181342855095863e-05\n",
      "Epoch: 58/64, Generator Loss: 83.94551086425781, Discriminator Loss: 5.717989552067593e-05\n",
      "Epoch: 59/64, Generator Loss: 83.835693359375, Discriminator Loss: 5.217544821789488e-05\n",
      "Epoch: 60/64, Generator Loss: 83.48629760742188, Discriminator Loss: 1.8797940356307663e-05\n",
      "Epoch: 61/64, Generator Loss: 83.4601058959961, Discriminator Loss: 2.023556220365208e-07\n",
      "Epoch: 62/64, Generator Loss: 83.70917510986328, Discriminator Loss: 6.9945454015396535e-06\n",
      "Epoch: 63/64, Generator Loss: 83.4657974243164, Discriminator Loss: 4.726763563667191e-06\n",
      "Epoch: 64/64, Generator Loss: 83.435791015625, Discriminator Loss: 7.485175501642516e-06\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 19.4597\n",
      "Function value obtained: -83.4358\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n",
      "Epoch: 1/61, Generator Loss: 3.169647455215454, Discriminator Loss: 2.0612051486968994\n",
      "Epoch: 2/61, Generator Loss: 3.2107279300689697, Discriminator Loss: 0.11049992591142654\n",
      "Epoch: 3/61, Generator Loss: 5.139585018157959, Discriminator Loss: 0.07513267546892166\n",
      "Epoch: 4/61, Generator Loss: 8.457657814025879, Discriminator Loss: 0.001953544095158577\n",
      "Epoch: 5/61, Generator Loss: 4.873938083648682, Discriminator Loss: 0.19034342467784882\n",
      "Epoch: 6/61, Generator Loss: 4.862297534942627, Discriminator Loss: 0.0673184022307396\n",
      "Epoch: 7/61, Generator Loss: 4.261538982391357, Discriminator Loss: 0.08705896139144897\n",
      "Epoch: 8/61, Generator Loss: 3.7955002784729004, Discriminator Loss: 0.16050070524215698\n",
      "Epoch: 9/61, Generator Loss: 15.504980087280273, Discriminator Loss: 0.2512454092502594\n",
      "Epoch: 10/61, Generator Loss: 5.251636505126953, Discriminator Loss: 0.0076293861493468285\n",
      "Epoch: 11/61, Generator Loss: 9.657596588134766, Discriminator Loss: 0.2227054238319397\n",
      "Epoch: 12/61, Generator Loss: 5.786868572235107, Discriminator Loss: 0.06336911022663116\n",
      "Epoch: 13/61, Generator Loss: 6.0911359786987305, Discriminator Loss: 0.007299399934709072\n",
      "Epoch: 14/61, Generator Loss: 4.899788856506348, Discriminator Loss: 0.03212781995534897\n",
      "Epoch: 15/61, Generator Loss: 9.375775337219238, Discriminator Loss: 0.1118522360920906\n",
      "Epoch: 16/61, Generator Loss: 6.330510139465332, Discriminator Loss: 0.008984515443444252\n",
      "Epoch: 17/61, Generator Loss: 48.47527313232422, Discriminator Loss: 0.677622377872467\n",
      "Epoch: 18/61, Generator Loss: 15.756553649902344, Discriminator Loss: 0.24658365547657013\n",
      "Epoch: 19/61, Generator Loss: 4.342273235321045, Discriminator Loss: 0.12763236463069916\n",
      "Epoch: 20/61, Generator Loss: 11.026193618774414, Discriminator Loss: 0.00137592782266438\n",
      "Epoch: 21/61, Generator Loss: 9.065074920654297, Discriminator Loss: 0.013229476287961006\n",
      "Epoch: 22/61, Generator Loss: 8.24074935913086, Discriminator Loss: 0.022524205967783928\n",
      "Epoch: 23/61, Generator Loss: 8.598827362060547, Discriminator Loss: 0.0007725560571998358\n",
      "Epoch: 24/61, Generator Loss: 7.420841217041016, Discriminator Loss: 0.034030135720968246\n",
      "Epoch: 25/61, Generator Loss: 7.649019718170166, Discriminator Loss: 0.0009727856377139688\n",
      "Epoch: 26/61, Generator Loss: 8.56270980834961, Discriminator Loss: 0.009734281338751316\n",
      "Epoch: 27/61, Generator Loss: 20.677051544189453, Discriminator Loss: 0.0003647829871624708\n",
      "Epoch: 28/61, Generator Loss: 9.919598579406738, Discriminator Loss: 0.00015322814579121768\n",
      "Epoch: 29/61, Generator Loss: 17.048439025878906, Discriminator Loss: 0.0002697884920053184\n",
      "Epoch: 30/61, Generator Loss: 11.7473783493042, Discriminator Loss: 2.1217638277448714e-05\n",
      "Epoch: 31/61, Generator Loss: 11.249460220336914, Discriminator Loss: 0.0001831158879213035\n",
      "Epoch: 32/61, Generator Loss: 13.277472496032715, Discriminator Loss: 7.515640845667804e-06\n",
      "Epoch: 33/61, Generator Loss: 12.628613471984863, Discriminator Loss: 0.0004012943245470524\n",
      "Epoch: 34/61, Generator Loss: 12.973873138427734, Discriminator Loss: 1.348231944575673e-05\n",
      "Epoch: 35/61, Generator Loss: 13.846578598022461, Discriminator Loss: 5.4392285164794885e-06\n",
      "Epoch: 36/61, Generator Loss: 14.057048797607422, Discriminator Loss: 3.651898850876023e-06\n",
      "Epoch: 37/61, Generator Loss: 14.306130409240723, Discriminator Loss: 4.711901965492871e-06\n",
      "Epoch: 38/61, Generator Loss: 14.490744590759277, Discriminator Loss: 7.3265823630208615e-06\n",
      "Epoch: 39/61, Generator Loss: 13.081948280334473, Discriminator Loss: 4.800014266947983e-06\n",
      "Epoch: 40/61, Generator Loss: 12.594747543334961, Discriminator Loss: 7.846258085919544e-06\n",
      "Epoch: 41/61, Generator Loss: 14.098270416259766, Discriminator Loss: 3.0521068765665404e-06\n",
      "Epoch: 42/61, Generator Loss: 13.964686393737793, Discriminator Loss: 4.192015694570728e-06\n",
      "Epoch: 43/61, Generator Loss: 13.753226280212402, Discriminator Loss: 3.198901322321035e-05\n",
      "Epoch: 44/61, Generator Loss: 14.7036771774292, Discriminator Loss: 7.29554585632286e-06\n",
      "Epoch: 45/61, Generator Loss: 15.034661293029785, Discriminator Loss: 4.7775815801287536e-06\n",
      "Epoch: 46/61, Generator Loss: 15.309253692626953, Discriminator Loss: 1.4858098893455463e-06\n",
      "Epoch: 47/61, Generator Loss: 15.433455467224121, Discriminator Loss: 1.0068697520182468e-06\n",
      "Epoch: 48/61, Generator Loss: 15.545987129211426, Discriminator Loss: 3.091983307967894e-05\n",
      "Epoch: 49/61, Generator Loss: 14.475409507751465, Discriminator Loss: 4.194522261968814e-06\n",
      "Epoch: 50/61, Generator Loss: 15.092950820922852, Discriminator Loss: 2.2824056031822693e-06\n",
      "Epoch: 51/61, Generator Loss: 14.803415298461914, Discriminator Loss: 1.7464662960264832e-06\n",
      "Epoch: 52/61, Generator Loss: 15.259984016418457, Discriminator Loss: 2.9774333597742952e-05\n",
      "Epoch: 53/61, Generator Loss: 15.58191967010498, Discriminator Loss: 1.6025761624405277e-06\n",
      "Epoch: 54/61, Generator Loss: 14.659184455871582, Discriminator Loss: 3.517922777973581e-06\n",
      "Epoch: 55/61, Generator Loss: 15.38172721862793, Discriminator Loss: 8.157597221725155e-06\n",
      "Epoch: 56/61, Generator Loss: 15.677664756774902, Discriminator Loss: 1.491430612077238e-05\n",
      "Epoch: 57/61, Generator Loss: 15.921420097351074, Discriminator Loss: 4.868127803092648e-07\n",
      "Epoch: 58/61, Generator Loss: 16.05719757080078, Discriminator Loss: 1.2247230188222602e-05\n",
      "Epoch: 59/61, Generator Loss: 16.155263900756836, Discriminator Loss: 1.3219100765127223e-06\n",
      "Epoch: 60/61, Generator Loss: 16.338361740112305, Discriminator Loss: 7.382416242762702e-07\n",
      "Epoch: 61/61, Generator Loss: 16.455102920532227, Discriminator Loss: 9.252357813238632e-07\n",
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 18.3286\n",
      "Function value obtained: -16.4551\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "Epoch: 1/63, Generator Loss: 1.3459646701812744, Discriminator Loss: 0.8474328517913818\n",
      "Epoch: 2/63, Generator Loss: 2.0232455730438232, Discriminator Loss: 0.920744776725769\n",
      "Epoch: 3/63, Generator Loss: 0.9246782064437866, Discriminator Loss: 0.9886983633041382\n",
      "Epoch: 4/63, Generator Loss: 2.9188170433044434, Discriminator Loss: 0.4755169153213501\n",
      "Epoch: 5/63, Generator Loss: 3.304806709289551, Discriminator Loss: 3.3882079124450684\n",
      "Epoch: 6/63, Generator Loss: 2.525451898574829, Discriminator Loss: 1.2434873580932617\n",
      "Epoch: 7/63, Generator Loss: 0.737878680229187, Discriminator Loss: 2.8790760040283203\n",
      "Epoch: 8/63, Generator Loss: 2.477971076965332, Discriminator Loss: 0.8958056569099426\n",
      "Epoch: 9/63, Generator Loss: 2.5063905715942383, Discriminator Loss: 0.5683482885360718\n",
      "Epoch: 10/63, Generator Loss: 4.528510093688965, Discriminator Loss: 1.4101704359054565\n",
      "Epoch: 11/63, Generator Loss: 1.7189260721206665, Discriminator Loss: 0.5696682929992676\n",
      "Epoch: 12/63, Generator Loss: 1.5317449569702148, Discriminator Loss: 1.0338915586471558\n",
      "Epoch: 13/63, Generator Loss: 1.0007293224334717, Discriminator Loss: 1.1889665126800537\n",
      "Epoch: 14/63, Generator Loss: 5.476046085357666, Discriminator Loss: 0.6154545545578003\n",
      "Epoch: 15/63, Generator Loss: 1.4763017892837524, Discriminator Loss: 1.1476000547409058\n",
      "Epoch: 16/63, Generator Loss: 4.438091278076172, Discriminator Loss: 5.581331253051758\n",
      "Epoch: 17/63, Generator Loss: 3.983433961868286, Discriminator Loss: 0.6578711867332458\n",
      "Epoch: 18/63, Generator Loss: 2.6973981857299805, Discriminator Loss: 0.8877924680709839\n",
      "Epoch: 19/63, Generator Loss: 2.8196606636047363, Discriminator Loss: 0.5939688682556152\n",
      "Epoch: 20/63, Generator Loss: 2.1023569107055664, Discriminator Loss: 1.1506164073944092\n",
      "Epoch: 21/63, Generator Loss: 3.3016252517700195, Discriminator Loss: 0.7243263721466064\n",
      "Epoch: 22/63, Generator Loss: 3.0865039825439453, Discriminator Loss: 0.3391159772872925\n",
      "Epoch: 23/63, Generator Loss: 4.198266983032227, Discriminator Loss: 0.6349302530288696\n",
      "Epoch: 24/63, Generator Loss: 3.1022238731384277, Discriminator Loss: 2.236656904220581\n",
      "Epoch: 25/63, Generator Loss: 3.729188919067383, Discriminator Loss: 0.12033842504024506\n",
      "Epoch: 26/63, Generator Loss: 1.9726207256317139, Discriminator Loss: 0.7143276333808899\n",
      "Epoch: 27/63, Generator Loss: 8.668219566345215, Discriminator Loss: 0.928682267665863\n",
      "Epoch: 28/63, Generator Loss: 1.5185929536819458, Discriminator Loss: 0.910127580165863\n",
      "Epoch: 29/63, Generator Loss: 4.527498245239258, Discriminator Loss: 1.0386370420455933\n",
      "Epoch: 30/63, Generator Loss: 4.446814060211182, Discriminator Loss: 1.344387412071228\n",
      "Epoch: 31/63, Generator Loss: 1.9048012495040894, Discriminator Loss: 0.5027278661727905\n",
      "Epoch: 32/63, Generator Loss: 11.915773391723633, Discriminator Loss: 0.13280850648880005\n",
      "Epoch: 33/63, Generator Loss: 4.916093349456787, Discriminator Loss: 0.8837447166442871\n",
      "Epoch: 34/63, Generator Loss: 2.4812324047088623, Discriminator Loss: 0.4183730483055115\n",
      "Epoch: 35/63, Generator Loss: 3.465991735458374, Discriminator Loss: 1.1237449645996094\n",
      "Epoch: 36/63, Generator Loss: 5.472302436828613, Discriminator Loss: 0.15841969847679138\n",
      "Epoch: 37/63, Generator Loss: 4.814825534820557, Discriminator Loss: 2.0937089920043945\n",
      "Epoch: 38/63, Generator Loss: 3.8508148193359375, Discriminator Loss: 0.16298416256904602\n",
      "Epoch: 39/63, Generator Loss: 5.427600860595703, Discriminator Loss: 0.5230939984321594\n",
      "Epoch: 40/63, Generator Loss: 6.721765995025635, Discriminator Loss: 0.03011227957904339\n",
      "Epoch: 41/63, Generator Loss: 7.3994832038879395, Discriminator Loss: 0.09840258210897446\n",
      "Epoch: 42/63, Generator Loss: 8.790687561035156, Discriminator Loss: 0.2360386997461319\n",
      "Epoch: 43/63, Generator Loss: 6.485982894897461, Discriminator Loss: 0.06457298249006271\n",
      "Epoch: 44/63, Generator Loss: 6.999571800231934, Discriminator Loss: 1.4365495443344116\n",
      "Epoch: 45/63, Generator Loss: 4.145997047424316, Discriminator Loss: 0.23713773488998413\n",
      "Epoch: 46/63, Generator Loss: 4.509866237640381, Discriminator Loss: 0.09092302620410919\n",
      "Epoch: 47/63, Generator Loss: 5.4173455238342285, Discriminator Loss: 0.5650423169136047\n",
      "Epoch: 48/63, Generator Loss: 9.542396545410156, Discriminator Loss: 0.027867205440998077\n",
      "Epoch: 49/63, Generator Loss: 6.32288122177124, Discriminator Loss: 0.32999610900878906\n",
      "Epoch: 50/63, Generator Loss: 5.069402694702148, Discriminator Loss: 0.11453622579574585\n",
      "Epoch: 51/63, Generator Loss: 4.418989658355713, Discriminator Loss: 0.09636491537094116\n",
      "Epoch: 52/63, Generator Loss: 6.8979339599609375, Discriminator Loss: 0.29474225640296936\n",
      "Epoch: 53/63, Generator Loss: 6.5484619140625, Discriminator Loss: 0.06108216568827629\n",
      "Epoch: 54/63, Generator Loss: 4.124358177185059, Discriminator Loss: 0.611480176448822\n",
      "Epoch: 55/63, Generator Loss: 11.209918022155762, Discriminator Loss: 0.4292571544647217\n",
      "Epoch: 56/63, Generator Loss: 5.965346813201904, Discriminator Loss: 0.36979344487190247\n",
      "Epoch: 57/63, Generator Loss: 3.384528160095215, Discriminator Loss: 0.13657835125923157\n",
      "Epoch: 58/63, Generator Loss: 5.689249515533447, Discriminator Loss: 0.11573334783315659\n",
      "Epoch: 59/63, Generator Loss: 4.951649188995361, Discriminator Loss: 0.17233625054359436\n",
      "Epoch: 60/63, Generator Loss: 4.5084710121154785, Discriminator Loss: 0.10651986300945282\n",
      "Epoch: 61/63, Generator Loss: 10.019609451293945, Discriminator Loss: 0.2787834405899048\n",
      "Epoch: 62/63, Generator Loss: 4.95802116394043, Discriminator Loss: 0.07266029715538025\n",
      "Epoch: 63/63, Generator Loss: 7.589863300323486, Discriminator Loss: 0.24519549310207367\n",
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 17.6186\n",
      "Function value obtained: -7.5899\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "Epoch: 1/62, Generator Loss: 1.3963934183120728, Discriminator Loss: 3.2119243144989014\n",
      "Epoch: 2/62, Generator Loss: 2.2033112049102783, Discriminator Loss: 0.6166729927062988\n",
      "Epoch: 3/62, Generator Loss: 4.500370502471924, Discriminator Loss: 1.4180927276611328\n",
      "Epoch: 4/62, Generator Loss: 6.391183853149414, Discriminator Loss: 0.31198349595069885\n",
      "Epoch: 5/62, Generator Loss: 1.9879854917526245, Discriminator Loss: 0.5782212018966675\n",
      "Epoch: 6/62, Generator Loss: 15.54861068725586, Discriminator Loss: 0.7595449686050415\n",
      "Epoch: 7/62, Generator Loss: 3.1127045154571533, Discriminator Loss: 0.4817715287208557\n",
      "Epoch: 8/62, Generator Loss: 42.49182891845703, Discriminator Loss: 2.79907488822937\n",
      "Epoch: 9/62, Generator Loss: 4.55830192565918, Discriminator Loss: 0.353816956281662\n",
      "Epoch: 10/62, Generator Loss: 6.803434371948242, Discriminator Loss: 0.15413296222686768\n",
      "Epoch: 11/62, Generator Loss: 4.714564800262451, Discriminator Loss: 0.38418716192245483\n",
      "Epoch: 12/62, Generator Loss: 5.298778057098389, Discriminator Loss: 0.1981516182422638\n",
      "Epoch: 13/62, Generator Loss: 3.9552481174468994, Discriminator Loss: 0.024136392399668694\n",
      "Epoch: 14/62, Generator Loss: 13.878759384155273, Discriminator Loss: 0.5832089781761169\n",
      "Epoch: 15/62, Generator Loss: 7.639423847198486, Discriminator Loss: 0.2654149532318115\n",
      "Epoch: 16/62, Generator Loss: 6.938268184661865, Discriminator Loss: 0.06560669839382172\n",
      "Epoch: 17/62, Generator Loss: 6.325932025909424, Discriminator Loss: 0.2357262223958969\n",
      "Epoch: 18/62, Generator Loss: 9.494830131530762, Discriminator Loss: 0.10323753952980042\n",
      "Epoch: 19/62, Generator Loss: 10.737560272216797, Discriminator Loss: 0.31209927797317505\n",
      "Epoch: 20/62, Generator Loss: 10.124290466308594, Discriminator Loss: 0.11382875591516495\n",
      "Epoch: 21/62, Generator Loss: 6.986542701721191, Discriminator Loss: 0.4875795841217041\n",
      "Epoch: 22/62, Generator Loss: 7.862603664398193, Discriminator Loss: 0.029676085337996483\n",
      "Epoch: 23/62, Generator Loss: 5.713636875152588, Discriminator Loss: 0.4132380783557892\n",
      "Epoch: 24/62, Generator Loss: 10.611871719360352, Discriminator Loss: 0.14600592851638794\n",
      "Epoch: 25/62, Generator Loss: 10.624258041381836, Discriminator Loss: 0.14434264600276947\n",
      "Epoch: 26/62, Generator Loss: 7.64227294921875, Discriminator Loss: 0.05546668916940689\n",
      "Epoch: 27/62, Generator Loss: 4.656412124633789, Discriminator Loss: 0.07404019683599472\n",
      "Epoch: 28/62, Generator Loss: 11.121018409729004, Discriminator Loss: 1.3249326944351196\n",
      "Epoch: 29/62, Generator Loss: 7.02565860748291, Discriminator Loss: 0.06519163399934769\n",
      "Epoch: 30/62, Generator Loss: 41.833412170410156, Discriminator Loss: 0.04168473929166794\n",
      "Epoch: 31/62, Generator Loss: 22.572452545166016, Discriminator Loss: 0.37241411209106445\n",
      "Epoch: 32/62, Generator Loss: 35.220802307128906, Discriminator Loss: 0.75929856300354\n",
      "Epoch: 33/62, Generator Loss: 14.55866813659668, Discriminator Loss: 0.024347877129912376\n",
      "Epoch: 34/62, Generator Loss: 9.003132820129395, Discriminator Loss: 0.028955692425370216\n",
      "Epoch: 35/62, Generator Loss: 11.03966999053955, Discriminator Loss: 0.013571306131780148\n",
      "Epoch: 36/62, Generator Loss: 9.621384620666504, Discriminator Loss: 0.08977443724870682\n",
      "Epoch: 37/62, Generator Loss: 19.022581100463867, Discriminator Loss: 0.38796427845954895\n",
      "Epoch: 38/62, Generator Loss: 8.063970565795898, Discriminator Loss: 0.1930844783782959\n",
      "Epoch: 39/62, Generator Loss: 6.5976715087890625, Discriminator Loss: 0.0751810073852539\n",
      "Epoch: 40/62, Generator Loss: 10.50693416595459, Discriminator Loss: 0.11603512614965439\n",
      "Epoch: 41/62, Generator Loss: 7.518538475036621, Discriminator Loss: 0.003279478754848242\n",
      "Epoch: 42/62, Generator Loss: 14.985766410827637, Discriminator Loss: 0.15323446691036224\n",
      "Epoch: 43/62, Generator Loss: 6.840787887573242, Discriminator Loss: 0.025670697912573814\n",
      "Epoch: 44/62, Generator Loss: 8.550735473632812, Discriminator Loss: 0.037738289684057236\n",
      "Epoch: 45/62, Generator Loss: 9.005329132080078, Discriminator Loss: 0.04716518148779869\n",
      "Epoch: 46/62, Generator Loss: 11.528241157531738, Discriminator Loss: 0.009771645069122314\n",
      "Epoch: 47/62, Generator Loss: 9.260143280029297, Discriminator Loss: 0.009715301916003227\n",
      "Epoch: 48/62, Generator Loss: 8.004597663879395, Discriminator Loss: 0.0006375469965860248\n",
      "Epoch: 49/62, Generator Loss: 6.750275135040283, Discriminator Loss: 0.0058985184878110886\n",
      "Epoch: 50/62, Generator Loss: 6.744141578674316, Discriminator Loss: 0.002163138473406434\n",
      "Epoch: 51/62, Generator Loss: 10.318864822387695, Discriminator Loss: 0.0012292612809687853\n",
      "Epoch: 52/62, Generator Loss: 7.482527256011963, Discriminator Loss: 0.0014037912478670478\n",
      "Epoch: 53/62, Generator Loss: 11.614375114440918, Discriminator Loss: 0.022782985121011734\n",
      "Epoch: 54/62, Generator Loss: 83.50627136230469, Discriminator Loss: 3.538414239301346e-05\n",
      "Epoch: 55/62, Generator Loss: 81.20196533203125, Discriminator Loss: 1.6128355184719112e-07\n",
      "Epoch: 56/62, Generator Loss: 81.06168365478516, Discriminator Loss: 1.0198025393037824e-06\n",
      "Epoch: 57/62, Generator Loss: 81.29559326171875, Discriminator Loss: 1.0241731615678873e-05\n",
      "Epoch: 58/62, Generator Loss: 81.37974548339844, Discriminator Loss: 8.358393824892119e-05\n",
      "Epoch: 59/62, Generator Loss: 81.16912078857422, Discriminator Loss: 7.779525731166359e-06\n",
      "Epoch: 60/62, Generator Loss: 80.81791687011719, Discriminator Loss: 3.981861300417222e-05\n",
      "Epoch: 61/62, Generator Loss: 80.57271575927734, Discriminator Loss: 8.163415259332396e-06\n",
      "Epoch: 62/62, Generator Loss: 79.92329406738281, Discriminator Loss: 2.2280164557741955e-06\n",
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 18.8289\n",
      "Function value obtained: -79.9233\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n",
      "Epoch: 1/88, Generator Loss: 3.421912431716919, Discriminator Loss: 0.4990418255329132\n",
      "Epoch: 2/88, Generator Loss: 3.4905307292938232, Discriminator Loss: 0.11355549842119217\n",
      "Epoch: 3/88, Generator Loss: 1.7087844610214233, Discriminator Loss: 0.47250914573669434\n",
      "Epoch: 4/88, Generator Loss: 4.7280354499816895, Discriminator Loss: 0.0707082524895668\n",
      "Epoch: 5/88, Generator Loss: 3.77156925201416, Discriminator Loss: 0.14168933033943176\n",
      "Epoch: 6/88, Generator Loss: 5.47634220123291, Discriminator Loss: 0.03291991353034973\n",
      "Epoch: 7/88, Generator Loss: 5.0598015785217285, Discriminator Loss: 0.07291102409362793\n",
      "Epoch: 8/88, Generator Loss: 6.205659866333008, Discriminator Loss: 0.6260035037994385\n",
      "Epoch: 9/88, Generator Loss: 17.699108123779297, Discriminator Loss: 0.23259025812149048\n",
      "Epoch: 10/88, Generator Loss: 1.3037569522857666, Discriminator Loss: 1.4398796558380127\n",
      "Epoch: 11/88, Generator Loss: 5.961862087249756, Discriminator Loss: 0.0373937152326107\n",
      "Epoch: 12/88, Generator Loss: 4.004034519195557, Discriminator Loss: 0.06450384110212326\n",
      "Epoch: 13/88, Generator Loss: 5.495504856109619, Discriminator Loss: 0.027429429814219475\n",
      "Epoch: 14/88, Generator Loss: 22.829877853393555, Discriminator Loss: 0.05654115602374077\n",
      "Epoch: 15/88, Generator Loss: 13.146720886230469, Discriminator Loss: 0.04157235845923424\n",
      "Epoch: 16/88, Generator Loss: 16.92192840576172, Discriminator Loss: 3.6947126388549805\n",
      "Epoch: 17/88, Generator Loss: 14.822254180908203, Discriminator Loss: 2.6752275516628288e-05\n",
      "Epoch: 18/88, Generator Loss: 11.568056106567383, Discriminator Loss: 0.00255423947237432\n",
      "Epoch: 19/88, Generator Loss: 43.92817306518555, Discriminator Loss: 0.00017116426897700876\n",
      "Epoch: 20/88, Generator Loss: 42.56068801879883, Discriminator Loss: 4.4486132537713274e-05\n",
      "Epoch: 21/88, Generator Loss: 42.3391227722168, Discriminator Loss: 1.1107532372989226e-05\n",
      "Epoch: 22/88, Generator Loss: 41.98074722290039, Discriminator Loss: 1.9309083654661663e-05\n",
      "Epoch: 23/88, Generator Loss: 41.6866340637207, Discriminator Loss: 8.11305744718993e-06\n",
      "Epoch: 24/88, Generator Loss: 41.646446228027344, Discriminator Loss: 7.375477252935525e-06\n",
      "Epoch: 25/88, Generator Loss: 41.304141998291016, Discriminator Loss: 9.598044016456697e-06\n",
      "Epoch: 26/88, Generator Loss: 41.18320083618164, Discriminator Loss: 1.0239608855044935e-05\n",
      "Epoch: 27/88, Generator Loss: 41.03658676147461, Discriminator Loss: 8.977344805316534e-06\n",
      "Epoch: 28/88, Generator Loss: 40.796302795410156, Discriminator Loss: 7.996620297490153e-06\n",
      "Epoch: 29/88, Generator Loss: 40.7291145324707, Discriminator Loss: 7.607413863297552e-06\n",
      "Epoch: 30/88, Generator Loss: 40.630096435546875, Discriminator Loss: 6.126930202299263e-06\n",
      "Epoch: 31/88, Generator Loss: 40.48271942138672, Discriminator Loss: 1.854388574429322e-05\n",
      "Epoch: 32/88, Generator Loss: 40.28239440917969, Discriminator Loss: 3.799802016146714e-06\n",
      "Epoch: 33/88, Generator Loss: 40.24124526977539, Discriminator Loss: 6.475565442087827e-06\n",
      "Epoch: 34/88, Generator Loss: 40.07982635498047, Discriminator Loss: 5.646611043630401e-06\n",
      "Epoch: 35/88, Generator Loss: 40.03807067871094, Discriminator Loss: 6.330608812277205e-06\n",
      "Epoch: 36/88, Generator Loss: 39.8801383972168, Discriminator Loss: 7.24228721082909e-06\n",
      "Epoch: 37/88, Generator Loss: 39.8479118347168, Discriminator Loss: 4.043185981572606e-06\n",
      "Epoch: 38/88, Generator Loss: 39.59747314453125, Discriminator Loss: 5.518857051356463e-06\n",
      "Epoch: 39/88, Generator Loss: 39.60778045654297, Discriminator Loss: 4.841250756726367e-06\n",
      "Epoch: 40/88, Generator Loss: 39.36332702636719, Discriminator Loss: 9.81989342108136e-06\n",
      "Epoch: 41/88, Generator Loss: 39.38064956665039, Discriminator Loss: 3.355941998961498e-06\n",
      "Epoch: 42/88, Generator Loss: 39.24279022216797, Discriminator Loss: 5.38501126357005e-06\n",
      "Epoch: 43/88, Generator Loss: 39.14336395263672, Discriminator Loss: 4.5461142690328415e-06\n",
      "Epoch: 44/88, Generator Loss: 39.08855056762695, Discriminator Loss: 3.740645524885622e-06\n",
      "Epoch: 45/88, Generator Loss: 38.897335052490234, Discriminator Loss: 2.708832653297577e-06\n",
      "Epoch: 46/88, Generator Loss: 38.73157501220703, Discriminator Loss: 7.076749625412049e-06\n",
      "Epoch: 47/88, Generator Loss: 38.37027359008789, Discriminator Loss: 3.2784694212750765e-06\n",
      "Epoch: 48/88, Generator Loss: 38.300376892089844, Discriminator Loss: 4.473654826142592e-06\n",
      "Epoch: 49/88, Generator Loss: 38.11233139038086, Discriminator Loss: 3.955603460781276e-06\n",
      "Epoch: 50/88, Generator Loss: 37.8616943359375, Discriminator Loss: 7.041506250970997e-06\n",
      "Epoch: 51/88, Generator Loss: 37.45237350463867, Discriminator Loss: 3.519328856782522e-06\n",
      "Epoch: 52/88, Generator Loss: 37.26556396484375, Discriminator Loss: 1.4204998706190963e-06\n",
      "Epoch: 53/88, Generator Loss: 37.04917526245117, Discriminator Loss: 3.028433638974093e-06\n",
      "Epoch: 54/88, Generator Loss: 36.89307403564453, Discriminator Loss: 3.0393923680094304e-06\n",
      "Epoch: 55/88, Generator Loss: 36.77291488647461, Discriminator Loss: 4.466596237762133e-06\n",
      "Epoch: 56/88, Generator Loss: 36.62322998046875, Discriminator Loss: 1.8412440567772137e-06\n",
      "Epoch: 57/88, Generator Loss: 36.407264709472656, Discriminator Loss: 2.6737434382084757e-06\n",
      "Epoch: 58/88, Generator Loss: 36.36415481567383, Discriminator Loss: 1.593811361999542e-06\n",
      "Epoch: 59/88, Generator Loss: 36.16257095336914, Discriminator Loss: 1.1560341590666212e-06\n",
      "Epoch: 60/88, Generator Loss: 36.14085006713867, Discriminator Loss: 1.5717705537099391e-06\n",
      "Epoch: 61/88, Generator Loss: 36.0106315612793, Discriminator Loss: 2.357185621804092e-06\n",
      "Epoch: 62/88, Generator Loss: 35.86237335205078, Discriminator Loss: 7.142555205064127e-07\n",
      "Epoch: 63/88, Generator Loss: 35.78866958618164, Discriminator Loss: 1.0117828423972242e-06\n",
      "Epoch: 64/88, Generator Loss: 35.64276123046875, Discriminator Loss: 2.1758469301857986e-06\n",
      "Epoch: 65/88, Generator Loss: 35.35160446166992, Discriminator Loss: 2.2549986624653684e-06\n",
      "Epoch: 66/88, Generator Loss: 41.391693115234375, Discriminator Loss: 2.0035177961119643e-09\n",
      "Epoch: 67/88, Generator Loss: 40.92180633544922, Discriminator Loss: 1.602815657975043e-08\n",
      "Epoch: 68/88, Generator Loss: 41.14695739746094, Discriminator Loss: 7.02585622888554e-18\n",
      "Epoch: 69/88, Generator Loss: 40.97758865356445, Discriminator Loss: 6.442551621970297e-18\n",
      "Epoch: 70/88, Generator Loss: 40.88032150268555, Discriminator Loss: 1.3895403446139386e-17\n",
      "Epoch: 71/88, Generator Loss: 41.04235076904297, Discriminator Loss: 3.706515627754925e-08\n",
      "Epoch: 72/88, Generator Loss: 39.71277618408203, Discriminator Loss: 3.706515627754925e-08\n",
      "Epoch: 73/88, Generator Loss: 100.00000762939453, Discriminator Loss: 3.0052769162125514e-09\n",
      "Epoch: 74/88, Generator Loss: 100.00000762939453, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 75/88, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 76/88, Generator Loss: 100.00000762939453, Discriminator Loss: 2.0035177961119643e-09\n",
      "Epoch: 77/88, Generator Loss: 100.00000762939453, Discriminator Loss: 1.0017588980559822e-09\n",
      "Epoch: 78/88, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 79/88, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 80/88, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 81/88, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 82/88, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 83/88, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 84/88, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 85/88, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 86/88, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 87/88, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 88/88, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 27.0587\n",
      "Function value obtained: -100.0000\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "Epoch: 1/63, Generator Loss: 2.9655423164367676, Discriminator Loss: 4.411109447479248\n",
      "Epoch: 2/63, Generator Loss: 6.32180643081665, Discriminator Loss: 11.457399368286133\n",
      "Epoch: 3/63, Generator Loss: 1.7191448211669922, Discriminator Loss: 1.7610630989074707\n",
      "Epoch: 4/63, Generator Loss: 10.961941719055176, Discriminator Loss: 0.21690264344215393\n",
      "Epoch: 5/63, Generator Loss: 0.21222636103630066, Discriminator Loss: 55.6613883972168\n",
      "Epoch: 6/63, Generator Loss: 100.00000762939453, Discriminator Loss: 0.1365749090909958\n",
      "Epoch: 7/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/63, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 19.1668\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "Epoch: 1/89, Generator Loss: 1.4585258960723877, Discriminator Loss: 0.9947646856307983\n",
      "Epoch: 2/89, Generator Loss: 5.1350531578063965, Discriminator Loss: 0.0884849950671196\n",
      "Epoch: 3/89, Generator Loss: 4.101231098175049, Discriminator Loss: 1.4004360437393188\n",
      "Epoch: 4/89, Generator Loss: 5.007798194885254, Discriminator Loss: 0.08281359821557999\n",
      "Epoch: 5/89, Generator Loss: 3.0696463584899902, Discriminator Loss: 0.13280239701271057\n",
      "Epoch: 6/89, Generator Loss: 3.923365831375122, Discriminator Loss: 0.4499438405036926\n",
      "Epoch: 7/89, Generator Loss: 4.778405666351318, Discriminator Loss: 0.12470068037509918\n",
      "Epoch: 8/89, Generator Loss: 5.763702869415283, Discriminator Loss: 0.04952879995107651\n",
      "Epoch: 9/89, Generator Loss: 4.545687675476074, Discriminator Loss: 0.0689103975892067\n",
      "Epoch: 10/89, Generator Loss: 4.439241409301758, Discriminator Loss: 0.027324620634317398\n",
      "Epoch: 11/89, Generator Loss: 4.37709903717041, Discriminator Loss: 0.2705947458744049\n",
      "Epoch: 12/89, Generator Loss: 4.666100025177002, Discriminator Loss: 0.056691303849220276\n",
      "Epoch: 13/89, Generator Loss: 17.40739631652832, Discriminator Loss: 1.0540833473205566\n",
      "Epoch: 14/89, Generator Loss: 32.85822677612305, Discriminator Loss: 0.002319813473150134\n",
      "Epoch: 15/89, Generator Loss: 7.2918901443481445, Discriminator Loss: 0.009272033348679543\n",
      "Epoch: 16/89, Generator Loss: 4.5035176277160645, Discriminator Loss: 0.05125998705625534\n",
      "Epoch: 17/89, Generator Loss: 5.964428424835205, Discriminator Loss: 0.13824376463890076\n",
      "Epoch: 18/89, Generator Loss: 7.512319564819336, Discriminator Loss: 0.03697850927710533\n",
      "Epoch: 19/89, Generator Loss: 8.517107009887695, Discriminator Loss: 0.004285841714590788\n",
      "Epoch: 20/89, Generator Loss: 6.5740766525268555, Discriminator Loss: 0.042360931634902954\n",
      "Epoch: 21/89, Generator Loss: 14.841119766235352, Discriminator Loss: 4.0377726554870605\n",
      "Epoch: 22/89, Generator Loss: 11.72085189819336, Discriminator Loss: 0.05660243704915047\n",
      "Epoch: 23/89, Generator Loss: 7.936427593231201, Discriminator Loss: 0.23133811354637146\n",
      "Epoch: 24/89, Generator Loss: 7.543370246887207, Discriminator Loss: 0.007365033030509949\n",
      "Epoch: 25/89, Generator Loss: 5.413780689239502, Discriminator Loss: 0.05740171670913696\n",
      "Epoch: 26/89, Generator Loss: 9.333325386047363, Discriminator Loss: 0.00040954991709440947\n",
      "Epoch: 27/89, Generator Loss: 7.477463245391846, Discriminator Loss: 0.0484263114631176\n",
      "Epoch: 28/89, Generator Loss: 6.344379425048828, Discriminator Loss: 0.010157914832234383\n",
      "Epoch: 29/89, Generator Loss: 15.2631196975708, Discriminator Loss: 0.011561865918338299\n",
      "Epoch: 30/89, Generator Loss: 8.112725257873535, Discriminator Loss: 0.012202270328998566\n",
      "Epoch: 31/89, Generator Loss: 12.334327697753906, Discriminator Loss: 0.007930491119623184\n",
      "Epoch: 32/89, Generator Loss: 20.38545036315918, Discriminator Loss: 0.0006414186209440231\n",
      "Epoch: 33/89, Generator Loss: 35.15904235839844, Discriminator Loss: 5.727882125938777e-06\n",
      "Epoch: 34/89, Generator Loss: 61.238929748535156, Discriminator Loss: 0.0014314516447484493\n",
      "Epoch: 35/89, Generator Loss: 58.907501220703125, Discriminator Loss: 0.00012923836766276509\n",
      "Epoch: 36/89, Generator Loss: 57.49415969848633, Discriminator Loss: 2.8874237614218146e-05\n",
      "Epoch: 37/89, Generator Loss: 57.02778244018555, Discriminator Loss: 3.149085387121886e-05\n",
      "Epoch: 38/89, Generator Loss: 56.57662582397461, Discriminator Loss: 4.3552849092520773e-05\n",
      "Epoch: 39/89, Generator Loss: 56.34402847290039, Discriminator Loss: 2.1568605461652623e-06\n",
      "Epoch: 40/89, Generator Loss: 56.046234130859375, Discriminator Loss: 4.148465450271033e-06\n",
      "Epoch: 41/89, Generator Loss: 55.7203254699707, Discriminator Loss: 9.24182022572495e-05\n",
      "Epoch: 42/89, Generator Loss: 55.597007751464844, Discriminator Loss: 2.2225797238206724e-06\n",
      "Epoch: 43/89, Generator Loss: 55.40736770629883, Discriminator Loss: 1.2131424682593206e-06\n",
      "Epoch: 44/89, Generator Loss: 55.0113639831543, Discriminator Loss: 3.806607855949551e-05\n",
      "Epoch: 45/89, Generator Loss: 55.20350646972656, Discriminator Loss: 3.865950475301361e-06\n",
      "Epoch: 46/89, Generator Loss: 55.04140090942383, Discriminator Loss: 4.334443929110421e-06\n",
      "Epoch: 47/89, Generator Loss: 55.28385543823242, Discriminator Loss: 4.187042577541433e-06\n",
      "Epoch: 48/89, Generator Loss: 54.91958999633789, Discriminator Loss: 5.141888777870918e-06\n",
      "Epoch: 49/89, Generator Loss: 54.520633697509766, Discriminator Loss: 4.872469162364723e-06\n",
      "Epoch: 50/89, Generator Loss: 54.49248504638672, Discriminator Loss: 4.089773210580461e-05\n",
      "Epoch: 51/89, Generator Loss: 54.47888946533203, Discriminator Loss: 2.9578968678833917e-06\n",
      "Epoch: 52/89, Generator Loss: 54.30016326904297, Discriminator Loss: 2.449991598041379e-06\n",
      "Epoch: 53/89, Generator Loss: 54.335350036621094, Discriminator Loss: 7.071382242429536e-06\n",
      "Epoch: 54/89, Generator Loss: 53.94886016845703, Discriminator Loss: 8.749204425839707e-06\n",
      "Epoch: 55/89, Generator Loss: 54.21088790893555, Discriminator Loss: 4.126424300920917e-06\n",
      "Epoch: 56/89, Generator Loss: 54.11732864379883, Discriminator Loss: 1.3474141269398388e-06\n",
      "Epoch: 57/89, Generator Loss: 53.713348388671875, Discriminator Loss: 5.589883471657231e-07\n",
      "Epoch: 58/89, Generator Loss: 53.745670318603516, Discriminator Loss: 6.020634941705794e-07\n",
      "Epoch: 59/89, Generator Loss: 53.61082458496094, Discriminator Loss: 1.7767724784789607e-05\n",
      "Epoch: 60/89, Generator Loss: 53.63221740722656, Discriminator Loss: 1.188131363960565e-06\n",
      "Epoch: 61/89, Generator Loss: 53.68310546875, Discriminator Loss: 5.028873033552372e-07\n",
      "Epoch: 62/89, Generator Loss: 53.19157028198242, Discriminator Loss: 6.0638827562797815e-05\n",
      "Epoch: 63/89, Generator Loss: 53.244964599609375, Discriminator Loss: 5.469634629662323e-07\n",
      "Epoch: 64/89, Generator Loss: 53.113136291503906, Discriminator Loss: 5.602694727713242e-06\n",
      "Epoch: 65/89, Generator Loss: 53.24065399169922, Discriminator Loss: 3.95357892557513e-06\n",
      "Epoch: 66/89, Generator Loss: 53.06241226196289, Discriminator Loss: 1.2672622915488319e-06\n",
      "Epoch: 67/89, Generator Loss: 53.299503326416016, Discriminator Loss: 1.0613577615004033e-05\n",
      "Epoch: 68/89, Generator Loss: 53.292354583740234, Discriminator Loss: 2.0707157091237605e-06\n",
      "Epoch: 69/89, Generator Loss: 52.823795318603516, Discriminator Loss: 9.747246849656221e-07\n",
      "Epoch: 70/89, Generator Loss: 52.800193786621094, Discriminator Loss: 4.36550508311484e-05\n",
      "Epoch: 71/89, Generator Loss: 52.75132369995117, Discriminator Loss: 6.58328963254462e-06\n",
      "Epoch: 72/89, Generator Loss: 52.55080032348633, Discriminator Loss: 7.3747983151406515e-06\n",
      "Epoch: 73/89, Generator Loss: 52.53971862792969, Discriminator Loss: 1.2141532579335035e-06\n",
      "Epoch: 74/89, Generator Loss: 52.48776626586914, Discriminator Loss: 6.371232075252919e-07\n",
      "Epoch: 75/89, Generator Loss: 52.497589111328125, Discriminator Loss: 2.300123014720157e-06\n",
      "Epoch: 76/89, Generator Loss: 52.35378646850586, Discriminator Loss: 2.7465027869766345e-06\n",
      "Epoch: 77/89, Generator Loss: 52.17261505126953, Discriminator Loss: 7.433170026160951e-07\n",
      "Epoch: 78/89, Generator Loss: 51.97257614135742, Discriminator Loss: 2.9720358725171536e-06\n",
      "Epoch: 79/89, Generator Loss: 52.20424270629883, Discriminator Loss: 2.050267767117475e-06\n",
      "Epoch: 80/89, Generator Loss: 52.0411262512207, Discriminator Loss: 1.4586030374630354e-06\n",
      "Epoch: 81/89, Generator Loss: 51.94225311279297, Discriminator Loss: 4.0871867668101913e-07\n",
      "Epoch: 82/89, Generator Loss: 51.673282623291016, Discriminator Loss: 7.961393748701084e-06\n",
      "Epoch: 83/89, Generator Loss: 51.74243927001953, Discriminator Loss: 1.108978494812618e-06\n",
      "Epoch: 84/89, Generator Loss: 51.89949035644531, Discriminator Loss: 5.339434778761643e-07\n",
      "Epoch: 85/89, Generator Loss: 51.719017028808594, Discriminator Loss: 1.1180110277564381e-06\n",
      "Epoch: 86/89, Generator Loss: 51.51799392700195, Discriminator Loss: 4.097213377463049e-07\n",
      "Epoch: 87/89, Generator Loss: 51.579803466796875, Discriminator Loss: 5.96059635427082e-07\n",
      "Epoch: 88/89, Generator Loss: 51.67873001098633, Discriminator Loss: 2.2339273186844366e-07\n",
      "Epoch: 89/89, Generator Loss: 51.193084716796875, Discriminator Loss: 2.390309873590013e-06\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 27.3880\n",
      "Function value obtained: -51.1931\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n",
      "Epoch: 1/65, Generator Loss: 2.2796664237976074, Discriminator Loss: 1.397152304649353\n",
      "Epoch: 2/65, Generator Loss: 5.25114631652832, Discriminator Loss: 0.5999292135238647\n",
      "Epoch: 3/65, Generator Loss: 11.107803344726562, Discriminator Loss: 1.806881308555603\n",
      "Epoch: 4/65, Generator Loss: 6.371949672698975, Discriminator Loss: 0.43578922748565674\n",
      "Epoch: 5/65, Generator Loss: 9.049420356750488, Discriminator Loss: 0.10612468421459198\n",
      "Epoch: 6/65, Generator Loss: 8.053606986999512, Discriminator Loss: 0.06400647014379501\n",
      "Epoch: 7/65, Generator Loss: 12.29008674621582, Discriminator Loss: 0.05945829302072525\n",
      "Epoch: 8/65, Generator Loss: 31.34775161743164, Discriminator Loss: 0.058042556047439575\n",
      "Epoch: 9/65, Generator Loss: 10.4595308303833, Discriminator Loss: 0.012680965475738049\n",
      "Epoch: 10/65, Generator Loss: 4.776836395263672, Discriminator Loss: 0.07896900177001953\n",
      "Epoch: 11/65, Generator Loss: 37.13159942626953, Discriminator Loss: 0.9387359023094177\n",
      "Epoch: 12/65, Generator Loss: 7.862307071685791, Discriminator Loss: 0.0024680907372385263\n",
      "Epoch: 13/65, Generator Loss: 51.16924285888672, Discriminator Loss: 0.0007110448786988854\n",
      "Epoch: 14/65, Generator Loss: 45.85712432861328, Discriminator Loss: 2.7563630283111706e-05\n",
      "Epoch: 15/65, Generator Loss: 43.4739875793457, Discriminator Loss: 0.00010926235700026155\n",
      "Epoch: 16/65, Generator Loss: 8.134927749633789, Discriminator Loss: 0.21989460289478302\n",
      "Epoch: 17/65, Generator Loss: 12.36978530883789, Discriminator Loss: 0.1057504341006279\n",
      "Epoch: 18/65, Generator Loss: 40.849613189697266, Discriminator Loss: 2.3884615075076e-05\n",
      "Epoch: 19/65, Generator Loss: 8.185216903686523, Discriminator Loss: 0.006178863346576691\n",
      "Epoch: 20/65, Generator Loss: 22.909799575805664, Discriminator Loss: 0.0005481804837472737\n",
      "Epoch: 21/65, Generator Loss: 5.374202251434326, Discriminator Loss: 0.14759352803230286\n",
      "Epoch: 22/65, Generator Loss: 17.180784225463867, Discriminator Loss: 0.13999870419502258\n",
      "Epoch: 23/65, Generator Loss: 14.262776374816895, Discriminator Loss: 0.014378450810909271\n",
      "Epoch: 24/65, Generator Loss: 22.154651641845703, Discriminator Loss: 0.20955902338027954\n",
      "Epoch: 25/65, Generator Loss: 10.651577949523926, Discriminator Loss: 0.03371717780828476\n",
      "Epoch: 26/65, Generator Loss: 6.6083807945251465, Discriminator Loss: 0.001610289327800274\n",
      "Epoch: 27/65, Generator Loss: 14.796984672546387, Discriminator Loss: 0.014067149721086025\n",
      "Epoch: 28/65, Generator Loss: 35.71405792236328, Discriminator Loss: 0.024911724030971527\n",
      "Epoch: 29/65, Generator Loss: 7.4421067237854, Discriminator Loss: 0.0008628423674963415\n",
      "Epoch: 30/65, Generator Loss: 6.414306163787842, Discriminator Loss: 0.025347411632537842\n",
      "Epoch: 31/65, Generator Loss: 42.22342300415039, Discriminator Loss: 0.532021701335907\n",
      "Epoch: 32/65, Generator Loss: 6.551630020141602, Discriminator Loss: 0.0013318652054294944\n",
      "Epoch: 33/65, Generator Loss: 7.359002590179443, Discriminator Loss: 0.06481524556875229\n",
      "Epoch: 34/65, Generator Loss: 12.115817070007324, Discriminator Loss: 3.3183743653353304e-05\n",
      "Epoch: 35/65, Generator Loss: 51.7511100769043, Discriminator Loss: 0.00021272320009302348\n",
      "Epoch: 36/65, Generator Loss: 46.34873962402344, Discriminator Loss: 0.000173147302120924\n",
      "Epoch: 37/65, Generator Loss: 55.361019134521484, Discriminator Loss: 0.0009217881597578526\n",
      "Epoch: 38/65, Generator Loss: 53.6711540222168, Discriminator Loss: 4.0577702748123556e-05\n",
      "Epoch: 39/65, Generator Loss: 53.143898010253906, Discriminator Loss: 3.816062962869182e-05\n",
      "Epoch: 40/65, Generator Loss: 52.81145095825195, Discriminator Loss: 3.359261609148234e-05\n",
      "Epoch: 41/65, Generator Loss: 10.99898624420166, Discriminator Loss: 0.00015863386215642095\n",
      "Epoch: 42/65, Generator Loss: 10.656644821166992, Discriminator Loss: 0.002599249128252268\n",
      "Epoch: 43/65, Generator Loss: 37.634437561035156, Discriminator Loss: 0.0020884231198579073\n",
      "Epoch: 44/65, Generator Loss: 11.499139785766602, Discriminator Loss: 0.00042358686914667487\n",
      "Epoch: 45/65, Generator Loss: 47.0721549987793, Discriminator Loss: 9.607070978745469e-07\n",
      "Epoch: 46/65, Generator Loss: 46.65283966064453, Discriminator Loss: 7.799061677360442e-06\n",
      "Epoch: 47/65, Generator Loss: 10.461122512817383, Discriminator Loss: 0.0004251637146808207\n",
      "Epoch: 48/65, Generator Loss: 9.771398544311523, Discriminator Loss: 0.03184223920106888\n",
      "Epoch: 49/65, Generator Loss: 46.80756378173828, Discriminator Loss: 3.029320214409381e-05\n",
      "Epoch: 50/65, Generator Loss: 68.98856353759766, Discriminator Loss: 0.0003216030017938465\n",
      "Epoch: 51/65, Generator Loss: 62.623714447021484, Discriminator Loss: 9.129143290920183e-05\n",
      "Epoch: 52/65, Generator Loss: 60.019649505615234, Discriminator Loss: 7.766264752717689e-05\n",
      "Epoch: 53/65, Generator Loss: 57.59532165527344, Discriminator Loss: 1.7092012058128603e-05\n",
      "Epoch: 54/65, Generator Loss: 58.77998352050781, Discriminator Loss: 6.52968228678219e-05\n",
      "Epoch: 55/65, Generator Loss: 57.002662658691406, Discriminator Loss: 4.579120650305413e-05\n",
      "Epoch: 56/65, Generator Loss: 56.47148513793945, Discriminator Loss: 1.6833973859320395e-05\n",
      "Epoch: 57/65, Generator Loss: 56.00714111328125, Discriminator Loss: 4.16413604398258e-05\n",
      "Epoch: 58/65, Generator Loss: 55.3298454284668, Discriminator Loss: 1.605494435352739e-05\n",
      "Epoch: 59/65, Generator Loss: 55.54840850830078, Discriminator Loss: 9.371572559757624e-06\n",
      "Epoch: 60/65, Generator Loss: 56.613037109375, Discriminator Loss: 3.193824159097858e-05\n",
      "Epoch: 61/65, Generator Loss: 56.33921432495117, Discriminator Loss: 6.393064268195303e-06\n",
      "Epoch: 62/65, Generator Loss: 54.908470153808594, Discriminator Loss: 1.7922842744155787e-05\n",
      "Epoch: 63/65, Generator Loss: 54.750389099121094, Discriminator Loss: 2.849851989594754e-05\n",
      "Epoch: 64/65, Generator Loss: 53.723121643066406, Discriminator Loss: 0.000163866498041898\n",
      "Epoch: 65/65, Generator Loss: 46.72096633911133, Discriminator Loss: 7.337879651458934e-06\n",
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 19.9872\n",
      "Function value obtained: -46.7210\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n",
      "Epoch: 1/87, Generator Loss: 3.3643364906311035, Discriminator Loss: 0.2986651062965393\n",
      "Epoch: 2/87, Generator Loss: 12.01891803741455, Discriminator Loss: 8.194046677090228e-05\n",
      "Epoch: 3/87, Generator Loss: 10.411032676696777, Discriminator Loss: 0.017888270318508148\n",
      "Epoch: 4/87, Generator Loss: 17.91081428527832, Discriminator Loss: 0.6194217205047607\n",
      "Epoch: 5/87, Generator Loss: 10.201855659484863, Discriminator Loss: 0.00025856768479570746\n",
      "Epoch: 6/87, Generator Loss: 17.90070152282715, Discriminator Loss: 0.08028555661439896\n",
      "Epoch: 7/87, Generator Loss: 6.0399065017700195, Discriminator Loss: 0.020556967705488205\n",
      "Epoch: 8/87, Generator Loss: 8.908377647399902, Discriminator Loss: 0.01821974664926529\n",
      "Epoch: 9/87, Generator Loss: 9.653923988342285, Discriminator Loss: 0.0028786512557417154\n",
      "Epoch: 10/87, Generator Loss: 8.975186347961426, Discriminator Loss: 0.0007121368544176221\n",
      "Epoch: 11/87, Generator Loss: 12.680779457092285, Discriminator Loss: 0.03877492621541023\n",
      "Epoch: 12/87, Generator Loss: 14.662827491760254, Discriminator Loss: 0.04710514470934868\n",
      "Epoch: 13/87, Generator Loss: 9.774798393249512, Discriminator Loss: 0.010199583135545254\n",
      "Epoch: 14/87, Generator Loss: 12.517550468444824, Discriminator Loss: 0.09220835566520691\n",
      "Epoch: 15/87, Generator Loss: 17.382020950317383, Discriminator Loss: 0.7536839246749878\n",
      "Epoch: 16/87, Generator Loss: 9.758553504943848, Discriminator Loss: 0.009227296337485313\n",
      "Epoch: 17/87, Generator Loss: 8.837485313415527, Discriminator Loss: 0.0022453488782048225\n",
      "Epoch: 18/87, Generator Loss: 43.44950866699219, Discriminator Loss: 0.01587662100791931\n",
      "Epoch: 19/87, Generator Loss: 21.236038208007812, Discriminator Loss: 0.017388097941875458\n",
      "Epoch: 20/87, Generator Loss: 10.489748001098633, Discriminator Loss: 0.0007197834202088416\n",
      "Epoch: 21/87, Generator Loss: 89.13420867919922, Discriminator Loss: 5.373699036320777e-29\n",
      "Epoch: 22/87, Generator Loss: 93.09142303466797, Discriminator Loss: 3.516544200710886e-30\n",
      "Epoch: 23/87, Generator Loss: 94.0469970703125, Discriminator Loss: 7.39944271576981e-24\n",
      "Epoch: 24/87, Generator Loss: 92.39228820800781, Discriminator Loss: 2.507674810544211e-31\n",
      "Epoch: 25/87, Generator Loss: 92.84028625488281, Discriminator Loss: 1.2921032963843104e-30\n",
      "Epoch: 26/87, Generator Loss: 93.24015808105469, Discriminator Loss: 1.0445843033723415e-29\n",
      "Epoch: 27/87, Generator Loss: 94.21473693847656, Discriminator Loss: 1.6108131166471913e-32\n",
      "Epoch: 28/87, Generator Loss: 92.6137924194336, Discriminator Loss: 2.7191801643221277e-29\n",
      "Epoch: 29/87, Generator Loss: 94.16183471679688, Discriminator Loss: 3.9205863979133764e-29\n",
      "Epoch: 30/87, Generator Loss: 91.41827392578125, Discriminator Loss: 3.229488405008445e-29\n",
      "Epoch: 31/87, Generator Loss: 91.33888244628906, Discriminator Loss: 5.950919564935184e-20\n",
      "Epoch: 32/87, Generator Loss: 91.8630142211914, Discriminator Loss: 2.341342633369863e-27\n",
      "Epoch: 33/87, Generator Loss: 94.4069595336914, Discriminator Loss: 9.877459917812689e-31\n",
      "Epoch: 34/87, Generator Loss: 92.06822967529297, Discriminator Loss: 7.007835397342379e-30\n",
      "Epoch: 35/87, Generator Loss: 92.58402252197266, Discriminator Loss: 6.830289482910565e-30\n",
      "Epoch: 36/87, Generator Loss: 93.8847885131836, Discriminator Loss: 7.912409212980369e-28\n",
      "Epoch: 37/87, Generator Loss: 92.01432800292969, Discriminator Loss: 3.8503326865138834e-29\n",
      "Epoch: 38/87, Generator Loss: 93.25144958496094, Discriminator Loss: 8.869715080773649e-29\n",
      "Epoch: 39/87, Generator Loss: 92.72686004638672, Discriminator Loss: 1.9429724984651185e-27\n",
      "Epoch: 40/87, Generator Loss: 91.1035385131836, Discriminator Loss: 5.397028186849004e-28\n",
      "Epoch: 41/87, Generator Loss: 94.23221588134766, Discriminator Loss: 4.520752379618359e-31\n",
      "Epoch: 42/87, Generator Loss: 90.649658203125, Discriminator Loss: 2.5517666576057013e-27\n",
      "Epoch: 43/87, Generator Loss: 92.2036361694336, Discriminator Loss: 6.6589552643098525e-28\n",
      "Epoch: 44/87, Generator Loss: 91.28807067871094, Discriminator Loss: 1.5219936733316868e-29\n",
      "Epoch: 45/87, Generator Loss: 91.7295150756836, Discriminator Loss: 7.974450759096995e-29\n",
      "Epoch: 46/87, Generator Loss: 91.79149627685547, Discriminator Loss: 1.2709971499322614e-23\n",
      "Epoch: 47/87, Generator Loss: 91.55307006835938, Discriminator Loss: 3.1501071097493932e-28\n",
      "Epoch: 48/87, Generator Loss: 90.491455078125, Discriminator Loss: 1.8716888546203706e-24\n",
      "Epoch: 49/87, Generator Loss: 90.8450927734375, Discriminator Loss: 1.6332280142189252e-29\n",
      "Epoch: 50/87, Generator Loss: 89.5815658569336, Discriminator Loss: 3.7765562128382054e-25\n",
      "Epoch: 51/87, Generator Loss: 91.86860656738281, Discriminator Loss: 4.769079787743015e-27\n",
      "Epoch: 52/87, Generator Loss: 91.03430938720703, Discriminator Loss: 8.03295900617471e-30\n",
      "Epoch: 53/87, Generator Loss: 90.96430969238281, Discriminator Loss: 5.4205230576304146e-30\n",
      "Epoch: 54/87, Generator Loss: 89.5600357055664, Discriminator Loss: 2.1623543019816806e-31\n",
      "Epoch: 55/87, Generator Loss: 88.4303970336914, Discriminator Loss: 1.550185218905653e-13\n",
      "Epoch: 56/87, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 57/87, Generator Loss: 99.78585052490234, Discriminator Loss: 0.0\n",
      "Epoch: 58/87, Generator Loss: 99.88591766357422, Discriminator Loss: 2.4599234021836434e-40\n",
      "Epoch: 59/87, Generator Loss: 99.77272033691406, Discriminator Loss: 7.471877554611e-40\n",
      "Epoch: 60/87, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 61/87, Generator Loss: 99.89347076416016, Discriminator Loss: 1.0015640643915198e-40\n",
      "Epoch: 62/87, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 63/87, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 64/87, Generator Loss: 99.89482116699219, Discriminator Loss: 8.527321544955809e-41\n",
      "Epoch: 65/87, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 66/87, Generator Loss: 99.79533386230469, Discriminator Loss: 1.2165512747882332e-40\n",
      "Epoch: 67/87, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 68/87, Generator Loss: 99.75778198242188, Discriminator Loss: 1.1523409765559414e-39\n",
      "Epoch: 69/87, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 70/87, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 71/87, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 72/87, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 73/87, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 74/87, Generator Loss: 99.87850189208984, Discriminator Loss: 5.949156578352438e-40\n",
      "Epoch: 75/87, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 76/87, Generator Loss: 99.89220428466797, Discriminator Loss: 1.1641286992378418e-40\n",
      "Epoch: 77/87, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 78/87, Generator Loss: 99.7637939453125, Discriminator Loss: 3.059293787836976e-39\n",
      "Epoch: 79/87, Generator Loss: 99.88565826416016, Discriminator Loss: 2.5394470900340767e-40\n",
      "Epoch: 80/87, Generator Loss: 99.89703369140625, Discriminator Loss: 6.561299799508091e-41\n",
      "Epoch: 81/87, Generator Loss: 99.90030670166016, Discriminator Loss: 4.442396391602535e-41\n",
      "Epoch: 82/87, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 83/87, Generator Loss: 99.88688659667969, Discriminator Loss: 2.19170086312723e-40\n",
      "Epoch: 84/87, Generator Loss: 99.78260040283203, Discriminator Loss: 6.36569254687299e-40\n",
      "Epoch: 85/87, Generator Loss: 99.87902069091797, Discriminator Loss: 5.593282820352507e-40\n",
      "Epoch: 86/87, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 87/87, Generator Loss: 99.86882019042969, Discriminator Loss: 1.882089572628519e-39\n",
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 25.7977\n",
      "Function value obtained: -99.8688\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n",
      "Epoch: 1/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/87, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 26.0103\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -100.0000\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n",
      "Epoch: 1/86, Generator Loss: 3.971158266067505, Discriminator Loss: 0.3822513520717621\n",
      "Epoch: 2/86, Generator Loss: 2.940774440765381, Discriminator Loss: 0.11642928421497345\n",
      "Epoch: 3/86, Generator Loss: 2.923468828201294, Discriminator Loss: 0.19983349740505219\n",
      "Epoch: 4/86, Generator Loss: 2.2150721549987793, Discriminator Loss: 0.4478369355201721\n",
      "Epoch: 5/86, Generator Loss: 4.9923014640808105, Discriminator Loss: 0.031495049595832825\n",
      "Epoch: 6/86, Generator Loss: 10.715150833129883, Discriminator Loss: 0.05387696996331215\n",
      "Epoch: 7/86, Generator Loss: 5.448698043823242, Discriminator Loss: 0.13610945641994476\n",
      "Epoch: 8/86, Generator Loss: 11.363360404968262, Discriminator Loss: 0.16741400957107544\n",
      "Epoch: 9/86, Generator Loss: 5.96278715133667, Discriminator Loss: 0.021644804626703262\n",
      "Epoch: 10/86, Generator Loss: 14.397494316101074, Discriminator Loss: 0.09614992141723633\n",
      "Epoch: 11/86, Generator Loss: 7.323975086212158, Discriminator Loss: 0.020991550758481026\n",
      "Epoch: 12/86, Generator Loss: 7.944265365600586, Discriminator Loss: 0.009801607578992844\n",
      "Epoch: 13/86, Generator Loss: 8.2372407913208, Discriminator Loss: 0.004657982382923365\n",
      "Epoch: 14/86, Generator Loss: 7.501226425170898, Discriminator Loss: 0.0014311689883470535\n",
      "Epoch: 15/86, Generator Loss: 10.02694034576416, Discriminator Loss: 0.06869833171367645\n",
      "Epoch: 16/86, Generator Loss: 7.752094268798828, Discriminator Loss: 0.0010548183927312493\n",
      "Epoch: 17/86, Generator Loss: 10.669272422790527, Discriminator Loss: 3.56380405719392e-05\n",
      "Epoch: 18/86, Generator Loss: 12.02908706665039, Discriminator Loss: 9.487225906923413e-05\n",
      "Epoch: 19/86, Generator Loss: 8.521723747253418, Discriminator Loss: 0.0004094684845767915\n",
      "Epoch: 20/86, Generator Loss: 8.444562911987305, Discriminator Loss: 0.0002646596112754196\n",
      "Epoch: 21/86, Generator Loss: 9.735678672790527, Discriminator Loss: 6.333774217637256e-05\n",
      "Epoch: 22/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/86, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 26.1683\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -100.0000\n",
      "Best Parameters: {'num_epochs': 62, 'gen_hidden_dim': 447, 'disc_hidden_dim': 365, 'gen_lr': 0.00038592444637358675, 'disc_lr': 0.00474175516976875, 'gen_beta1': 0.0008878067093097246, 'disc_beta1': 0.8453021569800112}\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(torch.tensor(X, dtype = torch.float32), torch.tensor(y, dtype = torch.float32))\n",
    "dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "noise_dim = 100\n",
    "label_dim = y_cgan.shape[1]\n",
    "input_dim = X_cgan.shape[1]\n",
    "num_numerical = 2\n",
    "num_categorical = 156\n",
    "best_params = bayesian_optimization_cgan(dataloader, device, noise_dim, label_dim, num_numerical, num_categorical)\n",
    "print(f\"Best Parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/62, Generator Loss: 1.1947742700576782, Discriminator Loss: 2.5292813777923584\n",
      "Epoch: 2/62, Generator Loss: 1.3821673393249512, Discriminator Loss: 2.4107437133789062\n",
      "Epoch: 3/62, Generator Loss: 2.4826173782348633, Discriminator Loss: 4.31268835067749\n",
      "Epoch: 4/62, Generator Loss: 2.7348506450653076, Discriminator Loss: 2.8705875873565674\n",
      "Epoch: 5/62, Generator Loss: 1.583798885345459, Discriminator Loss: 2.580413341522217\n",
      "Epoch: 6/62, Generator Loss: 1.15731942653656, Discriminator Loss: 1.6408135890960693\n",
      "Epoch: 7/62, Generator Loss: 1.689857006072998, Discriminator Loss: 0.7259542942047119\n",
      "Epoch: 8/62, Generator Loss: 2.0117719173431396, Discriminator Loss: 1.9466776847839355\n",
      "Epoch: 9/62, Generator Loss: 2.565052032470703, Discriminator Loss: 1.0410444736480713\n",
      "Epoch: 10/62, Generator Loss: 1.2156667709350586, Discriminator Loss: 2.2745323181152344\n",
      "Epoch: 11/62, Generator Loss: 1.2743812799453735, Discriminator Loss: 1.1924340724945068\n",
      "Epoch: 12/62, Generator Loss: 5.190311431884766, Discriminator Loss: 4.814348220825195\n",
      "Epoch: 13/62, Generator Loss: 3.7353923320770264, Discriminator Loss: 4.045554161071777\n",
      "Epoch: 14/62, Generator Loss: 3.331022024154663, Discriminator Loss: 3.825702428817749\n",
      "Epoch: 15/62, Generator Loss: 1.867116093635559, Discriminator Loss: 0.9069279432296753\n",
      "Epoch: 16/62, Generator Loss: 3.3403215408325195, Discriminator Loss: 1.4259892702102661\n",
      "Epoch: 17/62, Generator Loss: 3.3044373989105225, Discriminator Loss: 2.969693660736084\n",
      "Epoch: 18/62, Generator Loss: 1.2077088356018066, Discriminator Loss: 2.5405848026275635\n",
      "Epoch: 19/62, Generator Loss: 3.2030158042907715, Discriminator Loss: 0.24178546667099\n",
      "Epoch: 20/62, Generator Loss: 1.7246620655059814, Discriminator Loss: 1.102083444595337\n",
      "Epoch: 21/62, Generator Loss: 1.9125512838363647, Discriminator Loss: 1.1938588619232178\n",
      "Epoch: 22/62, Generator Loss: 1.888081669807434, Discriminator Loss: 1.9284906387329102\n",
      "Epoch: 23/62, Generator Loss: 1.9676642417907715, Discriminator Loss: 0.43429845571517944\n",
      "Epoch: 24/62, Generator Loss: 2.8221211433410645, Discriminator Loss: 3.099179267883301\n",
      "Epoch: 25/62, Generator Loss: 1.221145510673523, Discriminator Loss: 1.3386720418930054\n",
      "Epoch: 26/62, Generator Loss: 4.137285232543945, Discriminator Loss: 1.088018536567688\n",
      "Epoch: 27/62, Generator Loss: 3.8104045391082764, Discriminator Loss: 1.836446762084961\n",
      "Epoch: 28/62, Generator Loss: 1.4246751070022583, Discriminator Loss: 0.650312066078186\n",
      "Epoch: 29/62, Generator Loss: 3.708590507507324, Discriminator Loss: 0.45989230275154114\n",
      "Epoch: 30/62, Generator Loss: 1.428328514099121, Discriminator Loss: 1.4126458168029785\n",
      "Epoch: 31/62, Generator Loss: 2.831328868865967, Discriminator Loss: 0.5130599141120911\n",
      "Epoch: 32/62, Generator Loss: 2.8301548957824707, Discriminator Loss: 0.8882617950439453\n",
      "Epoch: 33/62, Generator Loss: 0.8585459589958191, Discriminator Loss: 1.7349565029144287\n",
      "Epoch: 34/62, Generator Loss: 1.9090770483016968, Discriminator Loss: 0.9149034023284912\n",
      "Epoch: 35/62, Generator Loss: 1.938488483428955, Discriminator Loss: 1.111831784248352\n",
      "Epoch: 36/62, Generator Loss: 5.128477096557617, Discriminator Loss: 2.071560859680176\n",
      "Epoch: 37/62, Generator Loss: 2.0445668697357178, Discriminator Loss: 0.44390183687210083\n",
      "Epoch: 38/62, Generator Loss: 2.3910348415374756, Discriminator Loss: 0.45979154109954834\n",
      "Epoch: 39/62, Generator Loss: 2.614372730255127, Discriminator Loss: 1.9274358749389648\n",
      "Epoch: 40/62, Generator Loss: 4.049685478210449, Discriminator Loss: 1.9190282821655273\n",
      "Epoch: 41/62, Generator Loss: 5.732102394104004, Discriminator Loss: 3.1056647300720215\n",
      "Epoch: 42/62, Generator Loss: 7.680307388305664, Discriminator Loss: 2.660285472869873\n",
      "Epoch: 43/62, Generator Loss: 3.053867816925049, Discriminator Loss: 2.8748106956481934\n",
      "Epoch: 44/62, Generator Loss: 2.6849491596221924, Discriminator Loss: 1.7946714162826538\n",
      "Epoch: 45/62, Generator Loss: 2.011249542236328, Discriminator Loss: 0.35291776061058044\n",
      "Epoch: 46/62, Generator Loss: 4.123587608337402, Discriminator Loss: 0.21032658219337463\n",
      "Epoch: 47/62, Generator Loss: 2.287118434906006, Discriminator Loss: 0.6952868103981018\n",
      "Epoch: 48/62, Generator Loss: 5.495840549468994, Discriminator Loss: 0.7939257025718689\n",
      "Epoch: 49/62, Generator Loss: 4.229331970214844, Discriminator Loss: 0.2830516993999481\n",
      "Epoch: 50/62, Generator Loss: 4.05817174911499, Discriminator Loss: 0.7273976802825928\n",
      "Epoch: 51/62, Generator Loss: 3.7272632122039795, Discriminator Loss: 0.5090712904930115\n",
      "Epoch: 52/62, Generator Loss: 2.15944766998291, Discriminator Loss: 0.7706007957458496\n",
      "Epoch: 53/62, Generator Loss: 1.7688169479370117, Discriminator Loss: 1.4705841541290283\n",
      "Epoch: 54/62, Generator Loss: 2.4102184772491455, Discriminator Loss: 0.20797088742256165\n",
      "Epoch: 55/62, Generator Loss: 3.130291700363159, Discriminator Loss: 0.7265005111694336\n",
      "Epoch: 56/62, Generator Loss: 7.584686756134033, Discriminator Loss: 1.1224613189697266\n",
      "Epoch: 57/62, Generator Loss: 3.4005486965179443, Discriminator Loss: 0.217678964138031\n",
      "Epoch: 58/62, Generator Loss: 3.9697329998016357, Discriminator Loss: 0.24950194358825684\n",
      "Epoch: 59/62, Generator Loss: 3.77248215675354, Discriminator Loss: 0.15948830544948578\n",
      "Epoch: 60/62, Generator Loss: 2.6597793102264404, Discriminator Loss: 0.5539419054985046\n",
      "Epoch: 61/62, Generator Loss: 2.9539902210235596, Discriminator Loss: 0.6346754431724548\n",
      "Epoch: 62/62, Generator Loss: 5.842911243438721, Discriminator Loss: 0.4505753815174103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.842911243438721"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator(noise_dim, label_dim, num_numerical, num_categorical, best_params[\"gen_hidden_dim\"]).to(device)\n",
    "discriminator = Discriminator(label_dim, num_numerical, num_categorical, best_params[\"disc_hidden_dim\"]).to(device)\n",
    "gen_optimizer = optim.Adam(generator.parameters(), lr = best_params[\"gen_lr\"], betas = (best_params[\"gen_beta1\"], 0.999))\n",
    "disc_optimizer = optim.Adam(discriminator.parameters(), lr = best_params[\"disc_lr\"], betas = (best_params[\"disc_beta1\"], 0.999))\n",
    "train_cgan(generator, discriminator, dataloader, device, gen_optimizer, disc_optimizer, best_params[\"num_epochs\"], noise_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_vehicles_involved</th>\n",
       "      <th>Number_of_casualties</th>\n",
       "      <th>Day_of_week_Friday</th>\n",
       "      <th>Day_of_week_Monday</th>\n",
       "      <th>Day_of_week_Saturday</th>\n",
       "      <th>Day_of_week_Sunday</th>\n",
       "      <th>Day_of_week_Thursday</th>\n",
       "      <th>Day_of_week_Tuesday</th>\n",
       "      <th>Day_of_week_Wednesday</th>\n",
       "      <th>Age_band_of_driver_18-30</th>\n",
       "      <th>...</th>\n",
       "      <th>Cause_of_accident_No distancing</th>\n",
       "      <th>Cause_of_accident_No priority to pedestrian</th>\n",
       "      <th>Cause_of_accident_No priority to vehicle</th>\n",
       "      <th>Cause_of_accident_Other</th>\n",
       "      <th>Cause_of_accident_Overloading</th>\n",
       "      <th>Cause_of_accident_Overspeed</th>\n",
       "      <th>Cause_of_accident_Overtaking</th>\n",
       "      <th>Cause_of_accident_Overturning</th>\n",
       "      <th>Cause_of_accident_Turnover</th>\n",
       "      <th>Cause_of_accident_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.862236</td>\n",
       "      <td>0.314728</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.999628</td>\n",
       "      <td>0.997055</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.004426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>9.844544e-10</td>\n",
       "      <td>8.947523e-13</td>\n",
       "      <td>1.027124e-11</td>\n",
       "      <td>2.624858e-07</td>\n",
       "      <td>1.921770e-10</td>\n",
       "      <td>6.855187e-10</td>\n",
       "      <td>1.612145e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.591467</td>\n",
       "      <td>-0.351569</td>\n",
       "      <td>0.014242</td>\n",
       "      <td>0.931642</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.961195</td>\n",
       "      <td>0.791875</td>\n",
       "      <td>0.005039</td>\n",
       "      <td>0.053097</td>\n",
       "      <td>0.108657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004963</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.007248</td>\n",
       "      <td>4.544248e-05</td>\n",
       "      <td>4.092712e-06</td>\n",
       "      <td>2.356983e-05</td>\n",
       "      <td>6.896421e-04</td>\n",
       "      <td>2.810486e-05</td>\n",
       "      <td>1.323759e-04</td>\n",
       "      <td>5.457035e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.897136</td>\n",
       "      <td>0.216100</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>0.984476</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.983784</td>\n",
       "      <td>0.974220</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>0.034255</td>\n",
       "      <td>0.061368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>2.166870e-05</td>\n",
       "      <td>1.643704e-06</td>\n",
       "      <td>4.494868e-06</td>\n",
       "      <td>9.782810e-04</td>\n",
       "      <td>1.175270e-05</td>\n",
       "      <td>1.235132e-05</td>\n",
       "      <td>2.854795e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.786114</td>\n",
       "      <td>-0.509481</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.980649</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.985239</td>\n",
       "      <td>0.961376</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>0.063569</td>\n",
       "      <td>0.117614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>0.025702</td>\n",
       "      <td>3.826208e-05</td>\n",
       "      <td>2.385434e-06</td>\n",
       "      <td>4.170127e-06</td>\n",
       "      <td>1.214636e-03</td>\n",
       "      <td>3.956045e-05</td>\n",
       "      <td>3.353018e-05</td>\n",
       "      <td>1.034839e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.454551</td>\n",
       "      <td>-0.283382</td>\n",
       "      <td>0.045924</td>\n",
       "      <td>0.988140</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.961925</td>\n",
       "      <td>0.985536</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.027544</td>\n",
       "      <td>0.068053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>6.424855e-05</td>\n",
       "      <td>1.777495e-06</td>\n",
       "      <td>4.837770e-06</td>\n",
       "      <td>1.413473e-04</td>\n",
       "      <td>3.770118e-05</td>\n",
       "      <td>1.140175e-05</td>\n",
       "      <td>1.706214e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>1.094808</td>\n",
       "      <td>-0.514644</td>\n",
       "      <td>0.017777</td>\n",
       "      <td>0.997952</td>\n",
       "      <td>0.002520</td>\n",
       "      <td>0.989780</td>\n",
       "      <td>0.996213</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.044092</td>\n",
       "      <td>0.023516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>2.357546e-06</td>\n",
       "      <td>1.288633e-07</td>\n",
       "      <td>1.217904e-07</td>\n",
       "      <td>4.492045e-05</td>\n",
       "      <td>3.203723e-06</td>\n",
       "      <td>8.518887e-07</td>\n",
       "      <td>3.710215e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>1.064333</td>\n",
       "      <td>-0.510557</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999835</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.013790</td>\n",
       "      <td>0.032024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>2.088818e-09</td>\n",
       "      <td>3.764311e-12</td>\n",
       "      <td>3.773213e-11</td>\n",
       "      <td>1.849023e-06</td>\n",
       "      <td>3.264612e-09</td>\n",
       "      <td>1.303485e-08</td>\n",
       "      <td>1.643039e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>1.760763</td>\n",
       "      <td>-0.410833</td>\n",
       "      <td>0.045880</td>\n",
       "      <td>0.995754</td>\n",
       "      <td>0.017687</td>\n",
       "      <td>0.997895</td>\n",
       "      <td>0.993481</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.048061</td>\n",
       "      <td>0.074450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.015875</td>\n",
       "      <td>7.483553e-06</td>\n",
       "      <td>7.308827e-07</td>\n",
       "      <td>5.690346e-07</td>\n",
       "      <td>2.485005e-04</td>\n",
       "      <td>8.614099e-06</td>\n",
       "      <td>1.619281e-05</td>\n",
       "      <td>2.672322e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>1.716145</td>\n",
       "      <td>-0.320154</td>\n",
       "      <td>0.132350</td>\n",
       "      <td>0.983105</td>\n",
       "      <td>0.019805</td>\n",
       "      <td>0.987521</td>\n",
       "      <td>0.984468</td>\n",
       "      <td>0.007389</td>\n",
       "      <td>0.052657</td>\n",
       "      <td>0.077499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>0.013472</td>\n",
       "      <td>0.067426</td>\n",
       "      <td>6.555028e-05</td>\n",
       "      <td>5.708485e-06</td>\n",
       "      <td>1.145095e-05</td>\n",
       "      <td>2.326905e-03</td>\n",
       "      <td>7.997155e-05</td>\n",
       "      <td>8.794091e-05</td>\n",
       "      <td>7.868479e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.810018</td>\n",
       "      <td>-0.386184</td>\n",
       "      <td>0.017184</td>\n",
       "      <td>0.989924</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>0.982387</td>\n",
       "      <td>0.983491</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.021503</td>\n",
       "      <td>0.062158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>4.493013e-06</td>\n",
       "      <td>1.582650e-07</td>\n",
       "      <td>4.455297e-07</td>\n",
       "      <td>1.401756e-04</td>\n",
       "      <td>2.307373e-06</td>\n",
       "      <td>1.108330e-05</td>\n",
       "      <td>5.065713e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows  158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number_of_vehicles_involved  Number_of_casualties  Day_of_week_Friday  \\\n",
       "0                       3.862236              0.314728            0.000591   \n",
       "1                       0.591467             -0.351569            0.014242   \n",
       "2                       1.897136              0.216100            0.007936   \n",
       "3                       0.786114             -0.509481            0.033600   \n",
       "4                       2.454551             -0.283382            0.045924   \n",
       "..                           ...                   ...                 ...   \n",
       "975                     1.094808             -0.514644            0.017777   \n",
       "976                     1.064333             -0.510557            0.002199   \n",
       "977                     1.760763             -0.410833            0.045880   \n",
       "978                     1.716145             -0.320154            0.132350   \n",
       "979                     0.810018             -0.386184            0.017184   \n",
       "\n",
       "     Day_of_week_Monday  Day_of_week_Saturday  Day_of_week_Sunday  \\\n",
       "0              0.999395              0.000068            0.999628   \n",
       "1              0.931642              0.003763            0.961195   \n",
       "2              0.984476              0.005439            0.983784   \n",
       "3              0.980649              0.003784            0.985239   \n",
       "4              0.988140              0.004733            0.961925   \n",
       "..                  ...                   ...                 ...   \n",
       "975            0.997952              0.002520            0.989780   \n",
       "976            0.999776              0.001131            0.999858   \n",
       "977            0.995754              0.017687            0.997895   \n",
       "978            0.983105              0.019805            0.987521   \n",
       "979            0.989924              0.005146            0.982387   \n",
       "\n",
       "     Day_of_week_Thursday  Day_of_week_Tuesday  Day_of_week_Wednesday  \\\n",
       "0                0.997055             0.000032               0.001829   \n",
       "1                0.791875             0.005039               0.053097   \n",
       "2                0.974220             0.004892               0.034255   \n",
       "3                0.961376             0.007045               0.063569   \n",
       "4                0.985536             0.001092               0.027544   \n",
       "..                    ...                  ...                    ...   \n",
       "975              0.996213             0.001213               0.044092   \n",
       "976              0.999835             0.000156               0.013790   \n",
       "977              0.993481             0.002130               0.048061   \n",
       "978              0.984468             0.007389               0.052657   \n",
       "979              0.983491             0.000389               0.021503   \n",
       "\n",
       "     Age_band_of_driver_18-30  ...  Cause_of_accident_No distancing  \\\n",
       "0                    0.004426  ...                         0.000006   \n",
       "1                    0.108657  ...                         0.004963   \n",
       "2                    0.061368  ...                         0.002148   \n",
       "3                    0.117614  ...                         0.003428   \n",
       "4                    0.068053  ...                         0.004019   \n",
       "..                        ...  ...                              ...   \n",
       "975                  0.023516  ...                         0.001197   \n",
       "976                  0.032024  ...                         0.000054   \n",
       "977                  0.074450  ...                         0.001406   \n",
       "978                  0.077499  ...                         0.010743   \n",
       "979                  0.062158  ...                         0.001175   \n",
       "\n",
       "     Cause_of_accident_No priority to pedestrian  \\\n",
       "0                                       0.000025   \n",
       "1                                       0.002103   \n",
       "2                                       0.002312   \n",
       "3                                       0.008517   \n",
       "4                                       0.000896   \n",
       "..                                           ...   \n",
       "975                                     0.001004   \n",
       "976                                     0.000018   \n",
       "977                                     0.002954   \n",
       "978                                     0.013472   \n",
       "979                                     0.001026   \n",
       "\n",
       "     Cause_of_accident_No priority to vehicle  Cause_of_accident_Other  \\\n",
       "0                                    0.000253             9.844544e-10   \n",
       "1                                    0.007248             4.544248e-05   \n",
       "2                                    0.005396             2.166870e-05   \n",
       "3                                    0.025702             3.826208e-05   \n",
       "4                                    0.005389             6.424855e-05   \n",
       "..                                        ...                      ...   \n",
       "975                                  0.003910             2.357546e-06   \n",
       "976                                  0.000267             2.088818e-09   \n",
       "977                                  0.015875             7.483553e-06   \n",
       "978                                  0.067426             6.555028e-05   \n",
       "979                                  0.004964             4.493013e-06   \n",
       "\n",
       "     Cause_of_accident_Overloading  Cause_of_accident_Overspeed  \\\n",
       "0                     8.947523e-13                 1.027124e-11   \n",
       "1                     4.092712e-06                 2.356983e-05   \n",
       "2                     1.643704e-06                 4.494868e-06   \n",
       "3                     2.385434e-06                 4.170127e-06   \n",
       "4                     1.777495e-06                 4.837770e-06   \n",
       "..                             ...                          ...   \n",
       "975                   1.288633e-07                 1.217904e-07   \n",
       "976                   3.764311e-12                 3.773213e-11   \n",
       "977                   7.308827e-07                 5.690346e-07   \n",
       "978                   5.708485e-06                 1.145095e-05   \n",
       "979                   1.582650e-07                 4.455297e-07   \n",
       "\n",
       "     Cause_of_accident_Overtaking  Cause_of_accident_Overturning  \\\n",
       "0                    2.624858e-07                   1.921770e-10   \n",
       "1                    6.896421e-04                   2.810486e-05   \n",
       "2                    9.782810e-04                   1.175270e-05   \n",
       "3                    1.214636e-03                   3.956045e-05   \n",
       "4                    1.413473e-04                   3.770118e-05   \n",
       "..                            ...                            ...   \n",
       "975                  4.492045e-05                   3.203723e-06   \n",
       "976                  1.849023e-06                   3.264612e-09   \n",
       "977                  2.485005e-04                   8.614099e-06   \n",
       "978                  2.326905e-03                   7.997155e-05   \n",
       "979                  1.401756e-04                   2.307373e-06   \n",
       "\n",
       "     Cause_of_accident_Turnover  Cause_of_accident_Unknown  \n",
       "0                  6.855187e-10               1.612145e-08  \n",
       "1                  1.323759e-04               5.457035e-04  \n",
       "2                  1.235132e-05               2.854795e-04  \n",
       "3                  3.353018e-05               1.034839e-03  \n",
       "4                  1.140175e-05               1.706214e-04  \n",
       "..                          ...                        ...  \n",
       "975                8.518887e-07               3.710215e-05  \n",
       "976                1.303485e-08               1.643039e-07  \n",
       "977                1.619281e-05               2.672322e-04  \n",
       "978                8.794091e-05               7.868479e-04  \n",
       "979                1.108330e-05               5.065713e-05  \n",
       "\n",
       "[980 rows x 158 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def round_one_hot(encoded_data):\n",
    "    max_indices = torch.argmax(encoded_data, dim = 1, keepdim = True)\n",
    "    one_hot = torch.zeros_like(encoded_data)\n",
    "    one_hot.scatter_(1, max_indices, 1)\n",
    "    return one_hot\n",
    "\n",
    "def generate_data(generator, num_data, noise_dim, label_dim, device):\n",
    "    noise = torch.randn(num_data, noise_dim).to(device)\n",
    "    labels = torch.zeros(num_data, label_dim).to(device)\n",
    "    labels[:, 0] = 1\n",
    "    fake_data = generator(noise, labels)\n",
    "    return fake_data.detach().cpu()\n",
    "\n",
    "fake_data = generate_data(generator, 1000, noise_dim, label_dim, device)\n",
    "fake_numerical = fake_data[:, :num_numerical]\n",
    "fake_categorical = fake_data[:, num_numerical:]\n",
    "\n",
    "fake_data = np.concatenate((fake_numerical, fake_categorical), axis = 1)\n",
    "fake_data = pd.DataFrame(fake_data, columns = X_cgan.columns)\n",
    "fake_data.head(-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_vehicles_involved</th>\n",
       "      <th>Number_of_casualties</th>\n",
       "      <th>Day_of_week_Friday</th>\n",
       "      <th>Day_of_week_Monday</th>\n",
       "      <th>Day_of_week_Saturday</th>\n",
       "      <th>Day_of_week_Sunday</th>\n",
       "      <th>Day_of_week_Thursday</th>\n",
       "      <th>Day_of_week_Tuesday</th>\n",
       "      <th>Day_of_week_Wednesday</th>\n",
       "      <th>Age_band_of_driver_18-30</th>\n",
       "      <th>...</th>\n",
       "      <th>Cause_of_accident_No distancing</th>\n",
       "      <th>Cause_of_accident_No priority to pedestrian</th>\n",
       "      <th>Cause_of_accident_No priority to vehicle</th>\n",
       "      <th>Cause_of_accident_Other</th>\n",
       "      <th>Cause_of_accident_Overloading</th>\n",
       "      <th>Cause_of_accident_Overspeed</th>\n",
       "      <th>Cause_of_accident_Overtaking</th>\n",
       "      <th>Cause_of_accident_Overturning</th>\n",
       "      <th>Cause_of_accident_Turnover</th>\n",
       "      <th>Cause_of_accident_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.055876</td>\n",
       "      <td>0.446105</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.055876</td>\n",
       "      <td>0.446105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.055876</td>\n",
       "      <td>-0.539413</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.055876</td>\n",
       "      <td>-0.539413</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.055876</td>\n",
       "      <td>-0.539413</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12309</th>\n",
       "      <td>-0.055876</td>\n",
       "      <td>0.446105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12312</th>\n",
       "      <td>-0.055876</td>\n",
       "      <td>-0.539413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12313</th>\n",
       "      <td>-1.524847</td>\n",
       "      <td>-0.539413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12314</th>\n",
       "      <td>-0.055876</td>\n",
       "      <td>-0.539413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12315</th>\n",
       "      <td>-0.055876</td>\n",
       "      <td>-0.539413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8439 rows  158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number_of_vehicles_involved  Number_of_casualties  Day_of_week_Friday  \\\n",
       "1                        -0.055876              0.446105                   0   \n",
       "3                        -0.055876              0.446105                   0   \n",
       "7                        -0.055876             -0.539413                   1   \n",
       "8                        -0.055876             -0.539413                   1   \n",
       "9                        -0.055876             -0.539413                   1   \n",
       "...                            ...                   ...                 ...   \n",
       "12309                    -0.055876              0.446105                   1   \n",
       "12312                    -0.055876             -0.539413                   0   \n",
       "12313                    -1.524847             -0.539413                   0   \n",
       "12314                    -0.055876             -0.539413                   0   \n",
       "12315                    -0.055876             -0.539413                   0   \n",
       "\n",
       "       Day_of_week_Monday  Day_of_week_Saturday  Day_of_week_Sunday  \\\n",
       "1                       1                     0                   0   \n",
       "3                       0                     0                   1   \n",
       "7                       0                     0                   0   \n",
       "8                       0                     0                   0   \n",
       "9                       0                     0                   0   \n",
       "...                   ...                   ...                 ...   \n",
       "12309                   0                     0                   0   \n",
       "12312                   0                     0                   1   \n",
       "12313                   0                     0                   1   \n",
       "12314                   0                     0                   1   \n",
       "12315                   0                     0                   1   \n",
       "\n",
       "       Day_of_week_Thursday  Day_of_week_Tuesday  Day_of_week_Wednesday  \\\n",
       "1                         0                    0                      0   \n",
       "3                         0                    0                      0   \n",
       "7                         0                    0                      0   \n",
       "8                         0                    0                      0   \n",
       "9                         0                    0                      0   \n",
       "...                     ...                  ...                    ...   \n",
       "12309                     0                    0                      0   \n",
       "12312                     0                    0                      0   \n",
       "12313                     0                    0                      0   \n",
       "12314                     0                    0                      0   \n",
       "12315                     0                    0                      0   \n",
       "\n",
       "       Age_band_of_driver_18-30  ...  Cause_of_accident_No distancing  \\\n",
       "1                             0  ...                                0   \n",
       "3                             1  ...                                0   \n",
       "7                             1  ...                                0   \n",
       "8                             1  ...                                0   \n",
       "9                             1  ...                                0   \n",
       "...                         ...  ...                              ...   \n",
       "12309                         0  ...                                0   \n",
       "12312                         0  ...                                1   \n",
       "12313                         0  ...                                0   \n",
       "12314                         1  ...                                0   \n",
       "12315                         1  ...                                0   \n",
       "\n",
       "       Cause_of_accident_No priority to pedestrian  \\\n",
       "1                                                0   \n",
       "3                                                0   \n",
       "7                                                0   \n",
       "8                                                0   \n",
       "9                                                0   \n",
       "...                                            ...   \n",
       "12309                                            0   \n",
       "12312                                            0   \n",
       "12313                                            0   \n",
       "12314                                            0   \n",
       "12315                                            0   \n",
       "\n",
       "       Cause_of_accident_No priority to vehicle  Cause_of_accident_Other  \\\n",
       "1                                             0                        0   \n",
       "3                                             0                        0   \n",
       "7                                             1                        0   \n",
       "8                                             0                        0   \n",
       "9                                             0                        0   \n",
       "...                                         ...                      ...   \n",
       "12309                                         0                        0   \n",
       "12312                                         0                        0   \n",
       "12313                                         0                        0   \n",
       "12314                                         0                        0   \n",
       "12315                                         0                        0   \n",
       "\n",
       "       Cause_of_accident_Overloading  Cause_of_accident_Overspeed  \\\n",
       "1                                  0                            0   \n",
       "3                                  0                            0   \n",
       "7                                  0                            0   \n",
       "8                                  0                            0   \n",
       "9                                  0                            0   \n",
       "...                              ...                          ...   \n",
       "12309                              0                            0   \n",
       "12312                              0                            0   \n",
       "12313                              0                            0   \n",
       "12314                              0                            0   \n",
       "12315                              0                            0   \n",
       "\n",
       "       Cause_of_accident_Overtaking  Cause_of_accident_Overturning  \\\n",
       "1                                 1                              0   \n",
       "3                                 0                              0   \n",
       "7                                 0                              0   \n",
       "8                                 0                              0   \n",
       "9                                 0                              0   \n",
       "...                             ...                            ...   \n",
       "12309                             0                              0   \n",
       "12312                             0                              0   \n",
       "12313                             0                              0   \n",
       "12314                             0                              0   \n",
       "12315                             0                              0   \n",
       "\n",
       "       Cause_of_accident_Turnover  Cause_of_accident_Unknown  \n",
       "1                               0                          0  \n",
       "3                               0                          0  \n",
       "7                               0                          0  \n",
       "8                               0                          0  \n",
       "9                               0                          0  \n",
       "...                           ...                        ...  \n",
       "12309                           0                          0  \n",
       "12312                           0                          0  \n",
       "12313                           0                          0  \n",
       "12314                           0                          0  \n",
       "12315                           0                          0  \n",
       "\n",
       "[8439 rows x 158 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cgan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (d) Feature Selection by AdaBoosting with Decision Stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state = 233)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 1), n_estimators = 100)\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred = ada.predict(X_test)\n",
    "\n",
    "feature_importance = np.mean([tree.feature_importances_ for tree in ada.estimators_], axis = 0)\n",
    "feature_importance = pd.DataFrame(feature_importance, index = X_train.columns, columns = [\"importance\"]).sort_values(\"importance\", ascending = False)\n",
    "aggregated_features = {}\n",
    "variable_index = categorical + numerical\n",
    "for feature in variable_index:\n",
    "    for i in range(len(feature_importance.index)):\n",
    "        if feature in feature_importance.index[i]:\n",
    "            if feature in aggregated_features:\n",
    "                aggregated_features[feature] += feature_importance.iloc[i, 0]\n",
    "            else:\n",
    "                aggregated_features[feature] = feature_importance.iloc[i, 0]\n",
    "        else:\n",
    "            if feature not in aggregated_features:\n",
    "                aggregated_features[feature] = 0\n",
    "aggregated_features = pd.DataFrame.from_dict(aggregated_features, orient = \"index\", columns = [\"importance\"]).sort_values(\"importance\", ascending = False)\n",
    "aggregated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "sns.barplot(x = aggregated_features[\"importance\"], y = aggregated_features.index).set(title = \"Feature Importance\", xlabel = \"Importance\", ylabel = \"Features\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area_accident_occured</th>\n",
       "      <th>Cause_of_accident</th>\n",
       "      <th>Type_of_vehicle</th>\n",
       "      <th>Vehicle_movement</th>\n",
       "      <th>Driving_experience</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Lanes_or_Medians</th>\n",
       "      <th>Type_of_collision</th>\n",
       "      <th>Age_band_of_driver</th>\n",
       "      <th>Number_of_casualties</th>\n",
       "      <th>Educational_level</th>\n",
       "      <th>Number_of_vehicles_involved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Office areas</td>\n",
       "      <td>Overtaking</td>\n",
       "      <td>Public (&gt; 45 seats)</td>\n",
       "      <td>Going straight</td>\n",
       "      <td>Above 10yr</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Undivided Two way</td>\n",
       "      <td>Vehicle with vehicle collision</td>\n",
       "      <td>31-50</td>\n",
       "      <td>2</td>\n",
       "      <td>Junior high school</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Office areas</td>\n",
       "      <td>Changing lane to the right</td>\n",
       "      <td>Public (&gt; 45 seats)</td>\n",
       "      <td>Going straight</td>\n",
       "      <td>5-10yr</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>other</td>\n",
       "      <td>Vehicle with vehicle collision</td>\n",
       "      <td>18-30</td>\n",
       "      <td>2</td>\n",
       "      <td>Junior high school</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Residential areas</td>\n",
       "      <td>No priority to vehicle</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>U-Turn</td>\n",
       "      <td>2-5yr</td>\n",
       "      <td>Friday</td>\n",
       "      <td>other</td>\n",
       "      <td>Vehicle with vehicle collision</td>\n",
       "      <td>18-30</td>\n",
       "      <td>1</td>\n",
       "      <td>Junior high school</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Industrial areas</td>\n",
       "      <td>Changing lane to the right</td>\n",
       "      <td>Lorry (41?100Q)</td>\n",
       "      <td>Going straight</td>\n",
       "      <td>Above 10yr</td>\n",
       "      <td>Friday</td>\n",
       "      <td>other</td>\n",
       "      <td>Collision with roadside-parked vehicles</td>\n",
       "      <td>18-30</td>\n",
       "      <td>1</td>\n",
       "      <td>Junior high school</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Residential areas</td>\n",
       "      <td>Moving Backward</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>U-Turn</td>\n",
       "      <td>1-2yr</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Undivided Two way</td>\n",
       "      <td>Collision with roadside-parked vehicles</td>\n",
       "      <td>18-30</td>\n",
       "      <td>1</td>\n",
       "      <td>Junior high school</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Area_accident_occured           Cause_of_accident      Type_of_vehicle  \\\n",
       "1          Office areas                  Overtaking  Public (> 45 seats)   \n",
       "3          Office areas  Changing lane to the right  Public (> 45 seats)   \n",
       "7     Residential areas      No priority to vehicle           Automobile   \n",
       "8      Industrial areas  Changing lane to the right      Lorry (41?100Q)   \n",
       "9     Residential areas             Moving Backward           Automobile   \n",
       "\n",
       "  Vehicle_movement Driving_experience Day_of_week   Lanes_or_Medians  \\\n",
       "1   Going straight         Above 10yr      Monday  Undivided Two way   \n",
       "3   Going straight             5-10yr      Sunday              other   \n",
       "7           U-Turn              2-5yr      Friday              other   \n",
       "8   Going straight         Above 10yr      Friday              other   \n",
       "9           U-Turn              1-2yr      Friday  Undivided Two way   \n",
       "\n",
       "                         Type_of_collision Age_band_of_driver  \\\n",
       "1           Vehicle with vehicle collision              31-50   \n",
       "3           Vehicle with vehicle collision              18-30   \n",
       "7           Vehicle with vehicle collision              18-30   \n",
       "8  Collision with roadside-parked vehicles              18-30   \n",
       "9  Collision with roadside-parked vehicles              18-30   \n",
       "\n",
       "   Number_of_casualties   Educational_level  Number_of_vehicles_involved  \n",
       "1                     2  Junior high school                            2  \n",
       "3                     2  Junior high school                            2  \n",
       "7                     1  Junior high school                            2  \n",
       "8                     1  Junior high school                            2  \n",
       "9                     1  Junior high school                            2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_feature = aggregated_features.index[:12].tolist()\n",
    "eta_new = eta[ada_feature]\n",
    "eta_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_new = [col for col in eta_new.columns]\n",
    "categorical_new.remove(\"Number_of_vehicles_involved\")\n",
    "categorical_new.remove(\"Number_of_casualties\")\n",
    "numerical_new = [\"Number_of_vehicles_involved\", \"Number_of_casualties\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Explanatory Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (d) Dimensionality Reduction by PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (e) Cluster Analysis by Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4. Data Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\26447\\AppData\\Local\\Temp\\ipykernel_20104\\2644754573.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eta_new[numerical_new] = standard.fit_transform(eta_new[numerical_new])\n"
     ]
    }
   ],
   "source": [
    "standard = StandardScaler()\n",
    "eta_new[numerical_new] = standard.fit_transform(eta_new[numerical_new])\n",
    "X = pd.get_dummies(eta_new, columns = categorical_new, drop_first = True)\n",
    "y = y_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size = 0.3, random_state = 233)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5. Model Selection\n",
    "#### (a) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n",
      "{'C': 100, 'degree': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "SVC(C=100, degree=1, gamma=1)\n",
      "Accuracy score:  0.9183325584999226\n",
      "Classification report:                  precision    recall  f1-score   support\n",
      "\n",
      "  Fatal injury       0.99      0.99      0.99      2169\n",
      "Serious Injury       0.98      0.78      0.87      2164\n",
      " Slight Injury       0.81      0.99      0.89      2120\n",
      "\n",
      "      accuracy                           0.92      6453\n",
      "     macro avg       0.93      0.92      0.92      6453\n",
      "  weighted avg       0.93      0.92      0.92      6453\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "param_svc = {\"C\": [0.1, 1, 10, 100], \"gamma\": [1, 0.1, 0.01, 0.001], \"kernel\": [\"rbf\", \"linear\", \"poly\", \"sigmoid\"], \"degree\": [1, 2, 3, 4]}\n",
    "svc = GridSearchCV(SVC(), param_svc, refit = True, verbose = 1, n_jobs = 12)\n",
    "svc.fit(X_train, y_train)\n",
    "print(svc.best_params_)\n",
    "print(svc.best_estimator_)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification report: \", classification_report(y_test, y_pred))\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat.T, square = True, annot = True, fmt = \"d\", cbar = False, xticklabels = [\"Fatal\", \"Serious\", \"Slight\"], yticklabels = [\"Fatal\", \"Serious\", \"Slight\"])\n",
    "plt.xlabel(\"True Label\")\n",
    "plt.ylabel(\"Predicted Label\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "param_gbc = {\"learning_rate\": [0.1, 0.01, 0.001], \"n_estimators\": [100, 200, 300], \"max_depth\": [1, 2, 3, 4, 5]}\n",
    "gbc = GridSearchCV(GradientBoostingClassifier(), param_gbc, refit = True, verbose = 1, n_jobs = 12)\n",
    "gbc.fit(X_train, y_train)\n",
    "print(gbc.best_params_)\n",
    "print(gbc.best_estimator_)\n",
    "y_pred = gbc.predict(X_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification report: \", classification_report(y_test, y_pred))\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat.T, square = True, annot = True, fmt = \"d\", cbar = False, xticklabels = [\"Fatal\", \"Serious\", \"Slight\"], yticklabels = [\"Fatal\", \"Serious\", \"Slight\"])\n",
    "plt.xlabel(\"True Label\")\n",
    "plt.ylabel(\"Predicted Label\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100, 100, 100, 100), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(100, 100, 100, 100, 100),\n",
      "              learning_rate='adaptive', solver='sgd')\n",
      "Accuracy score:  0.903300790330079\n",
      "Classification report:                  precision    recall  f1-score   support\n",
      "\n",
      "  Fatal injury       0.98      0.99      0.99      2169\n",
      "Serious Injury       0.90      0.82      0.86      2164\n",
      " Slight Injury       0.83      0.90      0.87      2120\n",
      "\n",
      "      accuracy                           0.90      6453\n",
      "     macro avg       0.90      0.90      0.90      6453\n",
      "  weighted avg       0.90      0.90      0.90      6453\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\26447\\anaconda3\\envs\\python\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "param_mlp = {\"hidden_layer_sizes\": [(100, 100, 100), (100, 100), (100, 100, 100, 100), (100, 100, 100, 100, 100)], \"activation\": [\"relu\", \"logistic\"], \"solver\": [\"adam\", \"sgd\"], \"alpha\": [0.0001, 0.05], \"learning_rate\": [\"constant\", \"adaptive\"]}\n",
    "mlp = GridSearchCV(MLPClassifier(), param_mlp, refit = True, verbose = 1, n_jobs = 12)\n",
    "mlp.fit(X_train, y_train)\n",
    "print(mlp.best_params_)\n",
    "print(mlp.best_estimator_)\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification report: \", classification_report(y_test, y_pred))\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat.T, square = True, annot = True, fmt = \"d\", cbar = False, xticklabels = [\"Fatal\", \"Serious\", \"Slight\"], yticklabels = [\"Fatal\", \"Serious\", \"Slight\"])\n",
    "plt.xlabel(\"True label\")\n",
    "plt.ylabel(\"Predicted label\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.918333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multi-layer Perceptron</td>\n",
       "      <td>0.903301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.883155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy\n",
       "0  Support Vector Machine  0.918333\n",
       "2  Multi-layer Perceptron  0.903301\n",
       "1           Random Forest  0.883155"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    \"Model\": [\"Support Vector Machine\", \"Gradient Boosting\", \"Multilayer Perceptron\"],\n",
    "    \"Accuracy\": [accuracy_score(y_test, svc.predict(X_test)), accuracy_score(y_test, gbc.predict(X_test)), accuracy_score(y_test, mlp.predict(X_test))]})\n",
    "models.sort_values(by = \"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.barplot(x = \"Model\", y = \"Accuracy\", data = models.sort_values(by = \"Accuracy\", ascending = False))\n",
    "for acc in ax.containers:\n",
    "    ax.bar_label(acc, label_type = \"center\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-mine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e3d6c2fd17c985616d208c207ad01a559fd73b1923d8aab6e801588cb03416b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
