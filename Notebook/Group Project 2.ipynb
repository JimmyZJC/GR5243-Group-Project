{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GR5243 Group Project\n",
    "##### Xingchen Ji, Yuting Wang, Hongyi Xu, and Jiacan Zhou"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = pd.read_csv(\"../Data/RTA.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Data Cleaning and Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) Handling Missing Data and Invalid Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'Histogram of Accident Severity'),\n",
       " Text(0.5, 0, 'Accident Severity')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eta[\"Accident_severity\"].value_counts()\n",
    "sns.histplot(eta[\"Accident_severity\"]).set(title = \"Histogram of Accident Severity\", xlabel = \"Accident Severity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta.drop([\"Service_year_of_vehicle\", \"Defect_of_vehicle\", \"Work_of_casuality\", \"Fitness_of_casuality\"], axis = 1, inplace = True)\n",
    "eta.drop([\"Time\", \"Weather_conditions\", \"Casualty_class\", \"Sex_of_casualty\", \"Age_band_of_casualty\", \"Casualty_severity\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [col for col in eta.columns]\n",
    "categorical.remove(\"Number_of_vehicles_involved\")\n",
    "categorical.remove(\"Number_of_casualties\")\n",
    "categorical.remove(\"Accident_severity\")\n",
    "numerical = [\"Number_of_vehicles_involved\", \"Number_of_casualties\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta.dropna(subset = categorical, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "eta_fs = eta.copy()\n",
    "eta_fs[numerical] = scaler.fit_transform(eta_fs[numerical])\n",
    "y_cgan = eta_fs[\"Accident_severity\"]\n",
    "y_cgan = pd.get_dummies(y_cgan, columns = [\"Accident_severity\"])\n",
    "y = y_cgan.to_numpy(dtype = np.float32)\n",
    "X_cgan = pd.get_dummies(eta_fs, columns = categorical)\n",
    "X_cgan = X_cgan.drop(\"Accident_severity\", axis = 1)\n",
    "X = X_cgan.to_numpy(dtype = np.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) Data Augmentation by CGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, label_dim, output_dim, hidden_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(noise_dim + label_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise, labels):\n",
    "        x = torch.cat([noise, labels], dim = 1)\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, label_dim, hidden_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim + label_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, labels):\n",
    "        x = torch.cat([x, labels], dim = 1)\n",
    "        return self.model(x)\n",
    "\n",
    "def train_cgan(generator, discriminator, train_loader, device, gen_opt, disc_opt, num_epochs, noise_dim):\n",
    "    criterion = nn.BCELoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (real_data, labels) in enumerate(train_loader):\n",
    "            real_data, labels = real_data.to(device), labels.to(device)\n",
    "            batch_size = real_data.size(0)\n",
    "\n",
    "            disc_opt.zero_grad()\n",
    "            real_output = discriminator(real_data, labels.to(device))\n",
    "            real_loss = criterion(real_output, torch.ones(batch_size, 1, device = device))\n",
    "\n",
    "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "            fake_data = generator(noise, labels.to(device))\n",
    "            fake_output = discriminator(fake_data.detach(), labels.to(device))\n",
    "            fake_loss = criterion(fake_output, torch.zeros(batch_size, 1, device = device))\n",
    "            \n",
    "            d_loss = real_loss + fake_loss\n",
    "            d_loss.backward()\n",
    "            disc_opt.step()\n",
    "\n",
    "            gen_opt.zero_grad()\n",
    "            fake_output = discriminator(fake_data, labels)\n",
    "            g_loss = criterion(fake_output, torch.ones(batch_size, 1, device=device))\n",
    "            g_loss.backward()\n",
    "            gen_opt.step()\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Generator Loss: {g_loss.item()}, Discriminator Loss: {d_loss.item()}\")\n",
    "    return g_loss.item()\n",
    "\n",
    "def bayesian_optimization_cgan(train_loader, device, noise_dim, label_dim, output_dim):\n",
    "    def objective(params):\n",
    "        num_epochs, gen_hidden_dim, disc_hidden_dim, gen_lr, gen_beta1, disc_lr, disc_beta1 = params\n",
    "\n",
    "        generator = Generator(noise_dim, label_dim, output_dim, gen_hidden_dim).to(device)\n",
    "        discriminator = Discriminator(output_dim, label_dim, disc_hidden_dim).to(device)\n",
    "\n",
    "        gen_optimizer = optim.Adam(generator.parameters(), gen_lr, betas = (gen_beta1, 0.999))\n",
    "        disc_optimizer = optim.Adam(discriminator.parameters(), lr = disc_lr, betas = (disc_beta1, 0.999))\n",
    "\n",
    "        gloss = train_cgan(generator, discriminator, train_loader, device, gen_optimizer, disc_optimizer, num_epochs, noise_dim)\n",
    "        return gloss\n",
    "\n",
    "    search_space = [\n",
    "        Integer(30, 100),\n",
    "        Integer(128, 512),\n",
    "        Integer(128, 512),\n",
    "        Real(1e-5, 1, prior=\"log-uniform\"),\n",
    "        Real(1e-5, 1, prior=\"log-uniform\"),\n",
    "        Real(0.0, 0.999),\n",
    "        Real(0.0, 0.999),\n",
    "    ]\n",
    "\n",
    "    result = gp_minimize(\n",
    "        func = objective,\n",
    "        dimensions = search_space,\n",
    "        n_calls = 50,\n",
    "        random_state = 233,\n",
    "        n_jobs = 12,\n",
    "        verbose = 3, \n",
    "    )\n",
    "    \n",
    "    best_params = {\n",
    "        \"num_epochs\": result.x[0],\n",
    "        \"gen_hidden_dim\": result.x[1],\n",
    "        \"disc_hidden_dim\": result.x[2],\n",
    "        \"gen_lr\": result.x[3],\n",
    "        \"disc_lr\": result.x[4],\n",
    "        \"gen_beta1\": result.x[5],\n",
    "        \"disc_beta1\": result.x[6],\n",
    "    }\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Epoch: 1/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/64, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/64, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 14/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/64, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 27/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/64, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 14.9835\n",
      "Function value obtained: 100.0000\n",
      "Current minimum: 100.0000\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Epoch: 1/84, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 2/84, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/84, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 20.7428\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Epoch: 1/46, Generator Loss: 1.8826380968093872, Discriminator Loss: 0.9281921982765198\n",
      "Epoch: 2/46, Generator Loss: 1.02932870388031, Discriminator Loss: 1.2230591773986816\n",
      "Epoch: 3/46, Generator Loss: 1.518324613571167, Discriminator Loss: 1.370525598526001\n",
      "Epoch: 4/46, Generator Loss: 2.8160970211029053, Discriminator Loss: 0.38721853494644165\n",
      "Epoch: 5/46, Generator Loss: 1.8958569765090942, Discriminator Loss: 0.7485489845275879\n",
      "Epoch: 6/46, Generator Loss: 1.6331626176834106, Discriminator Loss: 0.5953383445739746\n",
      "Epoch: 7/46, Generator Loss: 2.0154707431793213, Discriminator Loss: 0.5905475616455078\n",
      "Epoch: 8/46, Generator Loss: 2.3493740558624268, Discriminator Loss: 0.5530993938446045\n",
      "Epoch: 9/46, Generator Loss: 2.775087594985962, Discriminator Loss: 0.4599548876285553\n",
      "Epoch: 10/46, Generator Loss: 2.368492603302002, Discriminator Loss: 0.5290369987487793\n",
      "Epoch: 11/46, Generator Loss: 3.1197028160095215, Discriminator Loss: 0.3561056852340698\n",
      "Epoch: 12/46, Generator Loss: 2.7258553504943848, Discriminator Loss: 0.5667065382003784\n",
      "Epoch: 13/46, Generator Loss: 2.1222033500671387, Discriminator Loss: 0.5422161817550659\n",
      "Epoch: 14/46, Generator Loss: 2.2396469116210938, Discriminator Loss: 0.5161416530609131\n",
      "Epoch: 15/46, Generator Loss: 1.9521790742874146, Discriminator Loss: 0.4985220432281494\n",
      "Epoch: 16/46, Generator Loss: 1.993901252746582, Discriminator Loss: 0.5096365213394165\n",
      "Epoch: 17/46, Generator Loss: 1.8346117734909058, Discriminator Loss: 0.72245192527771\n",
      "Epoch: 18/46, Generator Loss: 1.5843483209609985, Discriminator Loss: 0.770681619644165\n",
      "Epoch: 19/46, Generator Loss: 1.6453371047973633, Discriminator Loss: 0.7413744926452637\n",
      "Epoch: 20/46, Generator Loss: 1.8377078771591187, Discriminator Loss: 0.7403493523597717\n",
      "Epoch: 21/46, Generator Loss: 1.9136748313903809, Discriminator Loss: 0.5727756023406982\n",
      "Epoch: 22/46, Generator Loss: 2.2775378227233887, Discriminator Loss: 0.43704092502593994\n",
      "Epoch: 23/46, Generator Loss: 2.075704336166382, Discriminator Loss: 0.6180325746536255\n",
      "Epoch: 24/46, Generator Loss: 2.068434476852417, Discriminator Loss: 0.571986198425293\n",
      "Epoch: 25/46, Generator Loss: 1.9313063621520996, Discriminator Loss: 0.7042217254638672\n",
      "Epoch: 26/46, Generator Loss: 2.1849327087402344, Discriminator Loss: 0.6055276989936829\n",
      "Epoch: 27/46, Generator Loss: 1.8660684823989868, Discriminator Loss: 0.6085278391838074\n",
      "Epoch: 28/46, Generator Loss: 2.047734022140503, Discriminator Loss: 0.7797431945800781\n",
      "Epoch: 29/46, Generator Loss: 1.8807646036148071, Discriminator Loss: 0.856544017791748\n",
      "Epoch: 30/46, Generator Loss: 2.0950374603271484, Discriminator Loss: 0.6921435594558716\n",
      "Epoch: 31/46, Generator Loss: 1.947001338005066, Discriminator Loss: 0.8947039842605591\n",
      "Epoch: 32/46, Generator Loss: 1.6484637260437012, Discriminator Loss: 1.0092453956604004\n",
      "Epoch: 33/46, Generator Loss: 1.6683162450790405, Discriminator Loss: 0.7291920185089111\n",
      "Epoch: 34/46, Generator Loss: 1.9719618558883667, Discriminator Loss: 0.5485326051712036\n",
      "Epoch: 35/46, Generator Loss: 1.52652907371521, Discriminator Loss: 0.8027530908584595\n",
      "Epoch: 36/46, Generator Loss: 1.7354674339294434, Discriminator Loss: 0.8176651000976562\n",
      "Epoch: 37/46, Generator Loss: 1.6604831218719482, Discriminator Loss: 1.1044514179229736\n",
      "Epoch: 38/46, Generator Loss: 1.868636965751648, Discriminator Loss: 0.5095282793045044\n",
      "Epoch: 39/46, Generator Loss: 1.3876465559005737, Discriminator Loss: 0.9884054064750671\n",
      "Epoch: 40/46, Generator Loss: 1.3107616901397705, Discriminator Loss: 1.0426855087280273\n",
      "Epoch: 41/46, Generator Loss: 1.5844833850860596, Discriminator Loss: 0.8072341680526733\n",
      "Epoch: 42/46, Generator Loss: 1.5196515321731567, Discriminator Loss: 0.839911699295044\n",
      "Epoch: 43/46, Generator Loss: 1.5398598909378052, Discriminator Loss: 0.7759720087051392\n",
      "Epoch: 44/46, Generator Loss: 1.5649980306625366, Discriminator Loss: 1.0701572895050049\n",
      "Epoch: 45/46, Generator Loss: 1.7637215852737427, Discriminator Loss: 1.0008606910705566\n",
      "Epoch: 46/46, Generator Loss: 2.0147385597229004, Discriminator Loss: 1.1568889617919922\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 10.5896\n",
      "Function value obtained: 2.0147\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Epoch: 1/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 8.9999\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Epoch: 1/96, Generator Loss: 100.00000762939453, Discriminator Loss: 94.1176528930664\n",
      "Epoch: 2/96, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 3/96, Generator Loss: 100.00000762939453, Discriminator Loss: 95.79832458496094\n",
      "Epoch: 4/96, Generator Loss: 100.00000762939453, Discriminator Loss: 98.3193359375\n",
      "Epoch: 5/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/96, Generator Loss: 100.00000762939453, Discriminator Loss: 98.3193359375\n",
      "Epoch: 7/96, Generator Loss: 100.00000762939453, Discriminator Loss: 93.27731323242188\n",
      "Epoch: 8/96, Generator Loss: 100.00000762939453, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 9/96, Generator Loss: 100.00000762939453, Discriminator Loss: 94.1176528930664\n",
      "Epoch: 10/96, Generator Loss: 100.00000762939453, Discriminator Loss: 95.79832458496094\n",
      "Epoch: 11/96, Generator Loss: 100.00000762939453, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 12/96, Generator Loss: 100.00000762939453, Discriminator Loss: 94.1176528930664\n",
      "Epoch: 13/96, Generator Loss: 100.00000762939453, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 14/96, Generator Loss: 100.00000762939453, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 15/96, Generator Loss: 100.00000762939453, Discriminator Loss: 98.3193359375\n",
      "Epoch: 16/96, Generator Loss: 100.00000762939453, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 17/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 95/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 96/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 20.1599\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "Epoch: 1/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 9.5829\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "Epoch: 1/47, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/47, Generator Loss: 1.6806724071502686, Discriminator Loss: 99.15966796875\n",
      "Epoch: 3/47, Generator Loss: 1.6806724071502686, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/47, Generator Loss: 0.8403362035751343, Discriminator Loss: 98.3193359375\n",
      "Epoch: 5/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/47, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 10.5967\n",
      "Function value obtained: 100.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "Epoch: 1/84, Generator Loss: 2.510653257369995, Discriminator Loss: 0.6730548143386841\n",
      "Epoch: 2/84, Generator Loss: 1.284989356994629, Discriminator Loss: 0.8623205423355103\n",
      "Epoch: 3/84, Generator Loss: 4.022767543792725, Discriminator Loss: 4.20279598236084\n",
      "Epoch: 4/84, Generator Loss: 1.6201791763305664, Discriminator Loss: 0.7670284509658813\n",
      "Epoch: 5/84, Generator Loss: 1.6453982591629028, Discriminator Loss: 0.8287543058395386\n",
      "Epoch: 6/84, Generator Loss: 1.8637268543243408, Discriminator Loss: 0.7125290632247925\n",
      "Epoch: 7/84, Generator Loss: 1.9723141193389893, Discriminator Loss: 0.6119800209999084\n",
      "Epoch: 8/84, Generator Loss: 1.6198612451553345, Discriminator Loss: 0.8914554119110107\n",
      "Epoch: 9/84, Generator Loss: 1.593798279762268, Discriminator Loss: 0.8937517404556274\n",
      "Epoch: 10/84, Generator Loss: 1.8417110443115234, Discriminator Loss: 0.7626118659973145\n",
      "Epoch: 11/84, Generator Loss: 1.6740844249725342, Discriminator Loss: 0.9702795743942261\n",
      "Epoch: 12/84, Generator Loss: 1.4406920671463013, Discriminator Loss: 0.8428837656974792\n",
      "Epoch: 13/84, Generator Loss: 1.1373893022537231, Discriminator Loss: 1.015688419342041\n",
      "Epoch: 14/84, Generator Loss: 1.4651672840118408, Discriminator Loss: 0.996128499507904\n",
      "Epoch: 15/84, Generator Loss: 1.1998957395553589, Discriminator Loss: 1.2274326086044312\n",
      "Epoch: 16/84, Generator Loss: 1.5939991474151611, Discriminator Loss: 1.1066639423370361\n",
      "Epoch: 17/84, Generator Loss: 1.3954378366470337, Discriminator Loss: 0.9919871687889099\n",
      "Epoch: 18/84, Generator Loss: 1.2815792560577393, Discriminator Loss: 0.9731734991073608\n",
      "Epoch: 19/84, Generator Loss: 1.252724051475525, Discriminator Loss: 1.0333360433578491\n",
      "Epoch: 20/84, Generator Loss: 1.3709481954574585, Discriminator Loss: 0.9459320306777954\n",
      "Epoch: 21/84, Generator Loss: 1.7529946565628052, Discriminator Loss: 1.0984470844268799\n",
      "Epoch: 22/84, Generator Loss: 1.496070146560669, Discriminator Loss: 0.8894745111465454\n",
      "Epoch: 23/84, Generator Loss: 1.3752275705337524, Discriminator Loss: 1.0836212635040283\n",
      "Epoch: 24/84, Generator Loss: 1.534477710723877, Discriminator Loss: 0.828998863697052\n",
      "Epoch: 25/84, Generator Loss: 1.6928722858428955, Discriminator Loss: 0.7324503660202026\n",
      "Epoch: 26/84, Generator Loss: 3.2100579738616943, Discriminator Loss: 0.9041885137557983\n",
      "Epoch: 27/84, Generator Loss: 1.5063552856445312, Discriminator Loss: 0.8678547143936157\n",
      "Epoch: 28/84, Generator Loss: 1.605809211730957, Discriminator Loss: 0.9057749509811401\n",
      "Epoch: 29/84, Generator Loss: 2.6853013038635254, Discriminator Loss: 1.3572287559509277\n",
      "Epoch: 30/84, Generator Loss: 1.859587550163269, Discriminator Loss: 0.7476975917816162\n",
      "Epoch: 31/84, Generator Loss: 1.5883723497390747, Discriminator Loss: 0.7006244659423828\n",
      "Epoch: 32/84, Generator Loss: 2.0962743759155273, Discriminator Loss: 0.6088742017745972\n",
      "Epoch: 33/84, Generator Loss: 6.860927581787109, Discriminator Loss: 0.6565946340560913\n",
      "Epoch: 34/84, Generator Loss: 2.0108072757720947, Discriminator Loss: 0.5542727708816528\n",
      "Epoch: 35/84, Generator Loss: 2.3555989265441895, Discriminator Loss: 0.5915112495422363\n",
      "Epoch: 36/84, Generator Loss: 2.131913661956787, Discriminator Loss: 0.5551130771636963\n",
      "Epoch: 37/84, Generator Loss: 1.9021230936050415, Discriminator Loss: 0.5640778541564941\n",
      "Epoch: 38/84, Generator Loss: 2.0515499114990234, Discriminator Loss: 0.6292535662651062\n",
      "Epoch: 39/84, Generator Loss: 2.228217124938965, Discriminator Loss: 0.4987817406654358\n",
      "Epoch: 40/84, Generator Loss: 2.180375099182129, Discriminator Loss: 0.3778972029685974\n",
      "Epoch: 41/84, Generator Loss: 2.21991229057312, Discriminator Loss: 0.39674830436706543\n",
      "Epoch: 42/84, Generator Loss: 2.1664223670959473, Discriminator Loss: 0.5073997378349304\n",
      "Epoch: 43/84, Generator Loss: 2.3019497394561768, Discriminator Loss: 0.5420403480529785\n",
      "Epoch: 44/84, Generator Loss: 2.286217451095581, Discriminator Loss: 0.4645170569419861\n",
      "Epoch: 45/84, Generator Loss: 2.3942081928253174, Discriminator Loss: 0.5871214866638184\n",
      "Epoch: 46/84, Generator Loss: 2.4671530723571777, Discriminator Loss: 0.4497677981853485\n",
      "Epoch: 47/84, Generator Loss: 2.5893259048461914, Discriminator Loss: 1.732323408126831\n",
      "Epoch: 48/84, Generator Loss: 1.827465534210205, Discriminator Loss: 1.2620233297348022\n",
      "Epoch: 49/84, Generator Loss: 1.842537522315979, Discriminator Loss: 0.5571481585502625\n",
      "Epoch: 50/84, Generator Loss: 2.182136058807373, Discriminator Loss: 0.797201931476593\n",
      "Epoch: 51/84, Generator Loss: 2.171031951904297, Discriminator Loss: 0.644626259803772\n",
      "Epoch: 52/84, Generator Loss: 1.7503621578216553, Discriminator Loss: 0.7279007434844971\n",
      "Epoch: 53/84, Generator Loss: 2.019514799118042, Discriminator Loss: 0.5911789536476135\n",
      "Epoch: 54/84, Generator Loss: 1.9400211572647095, Discriminator Loss: 0.6260256767272949\n",
      "Epoch: 55/84, Generator Loss: 2.069974899291992, Discriminator Loss: 0.6748170256614685\n",
      "Epoch: 56/84, Generator Loss: 1.8865476846694946, Discriminator Loss: 0.6795660257339478\n",
      "Epoch: 57/84, Generator Loss: 2.094758987426758, Discriminator Loss: 1.5271817445755005\n",
      "Epoch: 58/84, Generator Loss: 2.0944457054138184, Discriminator Loss: 0.6982007622718811\n",
      "Epoch: 59/84, Generator Loss: 2.001890182495117, Discriminator Loss: 0.5826842188835144\n",
      "Epoch: 60/84, Generator Loss: 2.109015703201294, Discriminator Loss: 0.6120936870574951\n",
      "Epoch: 61/84, Generator Loss: 1.9065730571746826, Discriminator Loss: 0.5441471338272095\n",
      "Epoch: 62/84, Generator Loss: 1.9157997369766235, Discriminator Loss: 0.6355190277099609\n",
      "Epoch: 63/84, Generator Loss: 2.220400810241699, Discriminator Loss: 0.7099470496177673\n",
      "Epoch: 64/84, Generator Loss: 2.039804458618164, Discriminator Loss: 0.5227354764938354\n",
      "Epoch: 65/84, Generator Loss: 2.0407204627990723, Discriminator Loss: 0.7496564388275146\n",
      "Epoch: 66/84, Generator Loss: 2.1264188289642334, Discriminator Loss: 0.4791521430015564\n",
      "Epoch: 67/84, Generator Loss: 2.2157793045043945, Discriminator Loss: 0.5048134326934814\n",
      "Epoch: 68/84, Generator Loss: 2.3960208892822266, Discriminator Loss: 0.6423038244247437\n",
      "Epoch: 69/84, Generator Loss: 2.2138655185699463, Discriminator Loss: 0.43840110301971436\n",
      "Epoch: 70/84, Generator Loss: 2.0971972942352295, Discriminator Loss: 0.515418529510498\n",
      "Epoch: 71/84, Generator Loss: 2.4748973846435547, Discriminator Loss: 0.5565808415412903\n",
      "Epoch: 72/84, Generator Loss: 2.2808947563171387, Discriminator Loss: 0.42509129643440247\n",
      "Epoch: 73/84, Generator Loss: 2.5454487800598145, Discriminator Loss: 0.49882304668426514\n",
      "Epoch: 74/84, Generator Loss: 2.2977445125579834, Discriminator Loss: 0.5221965312957764\n",
      "Epoch: 75/84, Generator Loss: 2.3509280681610107, Discriminator Loss: 0.43860924243927\n",
      "Epoch: 76/84, Generator Loss: 2.1696367263793945, Discriminator Loss: 0.4994391202926636\n",
      "Epoch: 77/84, Generator Loss: 2.2580645084381104, Discriminator Loss: 0.484585702419281\n",
      "Epoch: 78/84, Generator Loss: 2.3504767417907715, Discriminator Loss: 0.5416460037231445\n",
      "Epoch: 79/84, Generator Loss: 2.4052040576934814, Discriminator Loss: 0.5288859605789185\n",
      "Epoch: 80/84, Generator Loss: 2.3951611518859863, Discriminator Loss: 0.4575948119163513\n",
      "Epoch: 81/84, Generator Loss: 2.375089406967163, Discriminator Loss: 0.4394869804382324\n",
      "Epoch: 82/84, Generator Loss: 2.4909746646881104, Discriminator Loss: 1.390252709388733\n",
      "Epoch: 83/84, Generator Loss: 2.668323040008545, Discriminator Loss: 0.6891034245491028\n",
      "Epoch: 84/84, Generator Loss: 2.4003562927246094, Discriminator Loss: 0.43616580963134766\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 18.7401\n",
      "Function value obtained: 2.4004\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "Epoch: 1/41, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 2/41, Generator Loss: 99.15966796875, Discriminator Loss: 1.6806724071502686\n",
      "Epoch: 3/41, Generator Loss: 98.3193359375, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 4/41, Generator Loss: 98.3193359375, Discriminator Loss: 0.0\n",
      "Epoch: 5/41, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 6/41, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 7/41, Generator Loss: 98.3193359375, Discriminator Loss: 1.6806724071502686\n",
      "Epoch: 8/41, Generator Loss: 86.55462646484375, Discriminator Loss: 12.605042457580566\n",
      "Epoch: 9/41, Generator Loss: 100.00000762939453, Discriminator Loss: 3.361344814300537\n",
      "Epoch: 10/41, Generator Loss: 100.00000762939453, Discriminator Loss: 15.12605094909668\n",
      "Epoch: 11/41, Generator Loss: 100.00000762939453, Discriminator Loss: 13.445379257202148\n",
      "Epoch: 12/41, Generator Loss: 68.9075698852539, Discriminator Loss: 25.210084915161133\n",
      "Epoch: 13/41, Generator Loss: 91.59664154052734, Discriminator Loss: 9.243698120117188\n",
      "Epoch: 14/41, Generator Loss: 90.75630950927734, Discriminator Loss: 6.722689628601074\n",
      "Epoch: 15/41, Generator Loss: 92.43698120117188, Discriminator Loss: 12.605042457580566\n",
      "Epoch: 16/41, Generator Loss: 91.59664154052734, Discriminator Loss: 9.243698120117188\n",
      "Epoch: 17/41, Generator Loss: 93.27731323242188, Discriminator Loss: 9.243698120117188\n",
      "Epoch: 18/41, Generator Loss: 93.27731323242188, Discriminator Loss: 5.88235330581665\n",
      "Epoch: 19/41, Generator Loss: 90.75630950927734, Discriminator Loss: 13.445379257202148\n",
      "Epoch: 20/41, Generator Loss: 85.71428680419922, Discriminator Loss: 14.285715103149414\n",
      "Epoch: 21/41, Generator Loss: 87.39496612548828, Discriminator Loss: 9.243698120117188\n",
      "Epoch: 22/41, Generator Loss: 86.55462646484375, Discriminator Loss: 11.7647066116333\n",
      "Epoch: 23/41, Generator Loss: 91.59664154052734, Discriminator Loss: 10.924370765686035\n",
      "Epoch: 24/41, Generator Loss: 88.23529815673828, Discriminator Loss: 12.605042457580566\n",
      "Epoch: 25/41, Generator Loss: 91.59664154052734, Discriminator Loss: 11.7647066116333\n",
      "Epoch: 26/41, Generator Loss: 87.39496612548828, Discriminator Loss: 14.285715103149414\n",
      "Epoch: 27/41, Generator Loss: 93.27731323242188, Discriminator Loss: 11.7647066116333\n",
      "Epoch: 28/41, Generator Loss: 91.59664154052734, Discriminator Loss: 8.403361320495605\n",
      "Epoch: 29/41, Generator Loss: 92.43698120117188, Discriminator Loss: 6.722689628601074\n",
      "Epoch: 30/41, Generator Loss: 92.43698120117188, Discriminator Loss: 9.243698120117188\n",
      "Epoch: 31/41, Generator Loss: 91.59664154052734, Discriminator Loss: 9.243698120117188\n",
      "Epoch: 32/41, Generator Loss: 80.67227172851562, Discriminator Loss: 19.32773208618164\n",
      "Epoch: 33/41, Generator Loss: 87.0706787109375, Discriminator Loss: 17.64706039428711\n",
      "Epoch: 34/41, Generator Loss: 99.15966796875, Discriminator Loss: 47.0588264465332\n",
      "Epoch: 35/41, Generator Loss: 99.15966796875, Discriminator Loss: 48.739498138427734\n",
      "Epoch: 36/41, Generator Loss: 100.00000762939453, Discriminator Loss: 47.89916229248047\n",
      "Epoch: 37/41, Generator Loss: 100.00000762939453, Discriminator Loss: 10.924370765686035\n",
      "Epoch: 38/41, Generator Loss: 99.15966796875, Discriminator Loss: 6.722689628601074\n",
      "Epoch: 39/41, Generator Loss: 100.00000762939453, Discriminator Loss: 19.32773208618164\n",
      "Epoch: 40/41, Generator Loss: 99.15966796875, Discriminator Loss: 15.126051902770996\n",
      "Epoch: 41/41, Generator Loss: 95.79832458496094, Discriminator Loss: 14.285715103149414\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 8.6507\n",
      "Function value obtained: 95.7983\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "Epoch: 1/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 2/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 3/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 4/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 5/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 6/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 7/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 8/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 9/64, Generator Loss: 99.15966796875, Discriminator Loss: 0.0\n",
      "Epoch: 10/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 11/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 12/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 13/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 14/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 15/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 16/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 17/64, Generator Loss: 99.15966796875, Discriminator Loss: 0.0\n",
      "Epoch: 18/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 19/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 20/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 21/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 22/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 23/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 24/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 25/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 26/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 27/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 28/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 29/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 30/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 31/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 32/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 33/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 34/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 35/64, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 36/64, Generator Loss: 1.6806724071502686, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 37/64, Generator Loss: 1.6806724071502686, Discriminator Loss: 94.9579849243164\n",
      "Epoch: 38/64, Generator Loss: 2.5210084915161133, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 39/64, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/64, Generator Loss: 1.6806724071502686, Discriminator Loss: 99.15966796875\n",
      "Epoch: 41/64, Generator Loss: 0.8403362035751343, Discriminator Loss: 99.15966796875\n",
      "Epoch: 42/64, Generator Loss: 0.8403362035751343, Discriminator Loss: 99.15966796875\n",
      "Epoch: 43/64, Generator Loss: 1.6806724071502686, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/64, Generator Loss: 0.8403362035751343, Discriminator Loss: 99.15966796875\n",
      "Epoch: 47/64, Generator Loss: 2.5210084915161133, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/64, Generator Loss: 0.8403362035751343, Discriminator Loss: 99.15966796875\n",
      "Epoch: 49/64, Generator Loss: 0.8403362035751343, Discriminator Loss: 99.15966796875\n",
      "Epoch: 50/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/64, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 52/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/64, Generator Loss: 2.5210084915161133, Discriminator Loss: 99.15966796875\n",
      "Epoch: 55/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/64, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/64, Generator Loss: 1.6806724071502686, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/64, Generator Loss: 0.8403362035751343, Discriminator Loss: 98.3193359375\n",
      "Epoch: 59/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/64, Generator Loss: 1.6806724071502686, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/64, Generator Loss: 0.8403362035751343, Discriminator Loss: 99.15966796875\n",
      "Epoch: 63/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/64, Generator Loss: 1.6806724071502686, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 15.4059\n",
      "Function value obtained: 1.6807\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Epoch: 1/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.2921\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Epoch: 1/30, Generator Loss: 0.677545428276062, Discriminator Loss: 1.406079888343811\n",
      "Epoch: 2/30, Generator Loss: 0.6738451719284058, Discriminator Loss: 1.4047549962997437\n",
      "Epoch: 3/30, Generator Loss: 0.6654463410377502, Discriminator Loss: 1.4087774753570557\n",
      "Epoch: 4/30, Generator Loss: 0.6627365946769714, Discriminator Loss: 1.4159703254699707\n",
      "Epoch: 5/30, Generator Loss: 0.6590313911437988, Discriminator Loss: 1.4227912425994873\n",
      "Epoch: 6/30, Generator Loss: 0.6599678993225098, Discriminator Loss: 1.420626163482666\n",
      "Epoch: 7/30, Generator Loss: 0.655442476272583, Discriminator Loss: 1.427316665649414\n",
      "Epoch: 8/30, Generator Loss: 0.6459896564483643, Discriminator Loss: 1.4361603260040283\n",
      "Epoch: 9/30, Generator Loss: 0.6397054195404053, Discriminator Loss: 1.4428374767303467\n",
      "Epoch: 10/30, Generator Loss: 0.637346088886261, Discriminator Loss: 1.449002981185913\n",
      "Epoch: 11/30, Generator Loss: 0.6241728067398071, Discriminator Loss: 1.4611485004425049\n",
      "Epoch: 12/30, Generator Loss: 0.6262304186820984, Discriminator Loss: 1.465909719467163\n",
      "Epoch: 13/30, Generator Loss: 0.6155655980110168, Discriminator Loss: 1.4748533964157104\n",
      "Epoch: 14/30, Generator Loss: 0.6118602156639099, Discriminator Loss: 1.4812167882919312\n",
      "Epoch: 15/30, Generator Loss: 0.6003440022468567, Discriminator Loss: 1.4923479557037354\n",
      "Epoch: 16/30, Generator Loss: 0.5940320491790771, Discriminator Loss: 1.5137895345687866\n",
      "Epoch: 17/30, Generator Loss: 0.5889084935188293, Discriminator Loss: 1.512117862701416\n",
      "Epoch: 18/30, Generator Loss: 0.5749111175537109, Discriminator Loss: 1.5275031328201294\n",
      "Epoch: 19/30, Generator Loss: 0.5541359782218933, Discriminator Loss: 1.5361411571502686\n",
      "Epoch: 20/30, Generator Loss: 0.5532689690589905, Discriminator Loss: 1.5629723072052002\n",
      "Epoch: 21/30, Generator Loss: 0.5473425388336182, Discriminator Loss: 1.5650193691253662\n",
      "Epoch: 22/30, Generator Loss: 0.5355206727981567, Discriminator Loss: 1.5689918994903564\n",
      "Epoch: 23/30, Generator Loss: 0.5336582064628601, Discriminator Loss: 1.579160451889038\n",
      "Epoch: 24/30, Generator Loss: 0.5256516933441162, Discriminator Loss: 1.6064016819000244\n",
      "Epoch: 25/30, Generator Loss: 0.5010793805122375, Discriminator Loss: 1.6259186267852783\n",
      "Epoch: 26/30, Generator Loss: 0.5115882158279419, Discriminator Loss: 1.618823766708374\n",
      "Epoch: 27/30, Generator Loss: 0.508992075920105, Discriminator Loss: 1.6270116567611694\n",
      "Epoch: 28/30, Generator Loss: 0.5019859075546265, Discriminator Loss: 1.6299844980239868\n",
      "Epoch: 29/30, Generator Loss: 0.4951038658618927, Discriminator Loss: 1.6473982334136963\n",
      "Epoch: 30/30, Generator Loss: 0.4818158447742462, Discriminator Loss: 1.6628937721252441\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.4399\n",
      "Function value obtained: 0.4818\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Epoch: 1/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 95/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 96/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 97/97, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 20.5395\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Epoch: 1/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/88, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 18.0518\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Epoch: 1/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/98, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 12/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/98, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 20/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/98, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 28/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/98, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 30/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/98, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 34/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/98, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 43/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/98, Generator Loss: 100.00000762939453, Discriminator Loss: 98.3193359375\n",
      "Epoch: 45/98, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 46/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/98, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 54/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/98, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 64/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/98, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/98, Generator Loss: 77.31092834472656, Discriminator Loss: 22.689077377319336\n",
      "Epoch: 79/98, Generator Loss: 78.9916000366211, Discriminator Loss: 26.0504207611084\n",
      "Epoch: 80/98, Generator Loss: 75.63025665283203, Discriminator Loss: 22.689077377319336\n",
      "Epoch: 81/98, Generator Loss: 77.31092834472656, Discriminator Loss: 21.84874153137207\n",
      "Epoch: 82/98, Generator Loss: 73.9495849609375, Discriminator Loss: 31.932775497436523\n",
      "Epoch: 83/98, Generator Loss: 80.67227172851562, Discriminator Loss: 24.369749069213867\n",
      "Epoch: 84/98, Generator Loss: 84.87395477294922, Discriminator Loss: 20.168067932128906\n",
      "Epoch: 85/98, Generator Loss: 31.092437744140625, Discriminator Loss: 65.54621887207031\n",
      "Epoch: 86/98, Generator Loss: 31.092437744140625, Discriminator Loss: 72.26891326904297\n",
      "Epoch: 87/98, Generator Loss: 33.61344528198242, Discriminator Loss: 66.38655853271484\n",
      "Epoch: 88/98, Generator Loss: 34.45378494262695, Discriminator Loss: 64.70588684082031\n",
      "Epoch: 89/98, Generator Loss: 15.12605094909668, Discriminator Loss: 92.43698120117188\n",
      "Epoch: 90/98, Generator Loss: 15.12605094909668, Discriminator Loss: 86.55462646484375\n",
      "Epoch: 91/98, Generator Loss: 15.12605094909668, Discriminator Loss: 80.67227172851562\n",
      "Epoch: 92/98, Generator Loss: 18.487396240234375, Discriminator Loss: 76.47058868408203\n",
      "Epoch: 93/98, Generator Loss: 11.7647066116333, Discriminator Loss: 80.67227172851562\n",
      "Epoch: 94/98, Generator Loss: 14.285715103149414, Discriminator Loss: 88.23529815673828\n",
      "Epoch: 95/98, Generator Loss: 17.64706039428711, Discriminator Loss: 85.71428680419922\n",
      "Epoch: 96/98, Generator Loss: 21.008403778076172, Discriminator Loss: 84.87395477294922\n",
      "Epoch: 97/98, Generator Loss: 3.361344814300537, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 98/98, Generator Loss: 8.403361320495605, Discriminator Loss: 92.43698120117188\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 22.3787\n",
      "Function value obtained: 8.4034\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Epoch: 1/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/96, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 95/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 96/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 22.0940\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Epoch: 1/43, Generator Loss: 3.7473015785217285, Discriminator Loss: 0.6491128206253052\n",
      "Epoch: 2/43, Generator Loss: 1.4127980470657349, Discriminator Loss: 1.3370412588119507\n",
      "Epoch: 3/43, Generator Loss: 2.407278537750244, Discriminator Loss: 1.0365859270095825\n",
      "Epoch: 4/43, Generator Loss: 2.2212071418762207, Discriminator Loss: 0.5896486043930054\n",
      "Epoch: 5/43, Generator Loss: 2.275299072265625, Discriminator Loss: 0.7220669984817505\n",
      "Epoch: 6/43, Generator Loss: 2.1363906860351562, Discriminator Loss: 2.918041229248047\n",
      "Epoch: 7/43, Generator Loss: 1.6634200811386108, Discriminator Loss: 0.7590389847755432\n",
      "Epoch: 8/43, Generator Loss: 1.5945937633514404, Discriminator Loss: 0.9028277397155762\n",
      "Epoch: 9/43, Generator Loss: 1.8868498802185059, Discriminator Loss: 1.1917686462402344\n",
      "Epoch: 10/43, Generator Loss: 1.6543289422988892, Discriminator Loss: 0.886481523513794\n",
      "Epoch: 11/43, Generator Loss: 1.472228765487671, Discriminator Loss: 0.8152287006378174\n",
      "Epoch: 12/43, Generator Loss: 1.6900972127914429, Discriminator Loss: 0.7951985597610474\n",
      "Epoch: 13/43, Generator Loss: 1.6222525835037231, Discriminator Loss: 0.9063634872436523\n",
      "Epoch: 14/43, Generator Loss: 1.883554458618164, Discriminator Loss: 0.684623122215271\n",
      "Epoch: 15/43, Generator Loss: 1.2803194522857666, Discriminator Loss: 0.8335527181625366\n",
      "Epoch: 16/43, Generator Loss: 1.4828314781188965, Discriminator Loss: 0.7970068454742432\n",
      "Epoch: 17/43, Generator Loss: 1.7025747299194336, Discriminator Loss: 0.9109651446342468\n",
      "Epoch: 18/43, Generator Loss: 1.598496437072754, Discriminator Loss: 0.8322652578353882\n",
      "Epoch: 19/43, Generator Loss: 1.4083794355392456, Discriminator Loss: 0.8801632523536682\n",
      "Epoch: 20/43, Generator Loss: 9.021141052246094, Discriminator Loss: 0.7266339063644409\n",
      "Epoch: 21/43, Generator Loss: 1.7202385663986206, Discriminator Loss: 1.003166675567627\n",
      "Epoch: 22/43, Generator Loss: 1.7645941972732544, Discriminator Loss: 0.6190364360809326\n",
      "Epoch: 23/43, Generator Loss: 1.7865734100341797, Discriminator Loss: 0.6390256881713867\n",
      "Epoch: 24/43, Generator Loss: 1.9040255546569824, Discriminator Loss: 0.8050842881202698\n",
      "Epoch: 25/43, Generator Loss: 1.8454939126968384, Discriminator Loss: 0.6780637502670288\n",
      "Epoch: 26/43, Generator Loss: 2.146716594696045, Discriminator Loss: 0.9095358848571777\n",
      "Epoch: 27/43, Generator Loss: 1.8621647357940674, Discriminator Loss: 0.6658349633216858\n",
      "Epoch: 28/43, Generator Loss: 1.832484483718872, Discriminator Loss: 0.7379510998725891\n",
      "Epoch: 29/43, Generator Loss: 2.1297199726104736, Discriminator Loss: 0.5574970841407776\n",
      "Epoch: 30/43, Generator Loss: 1.8363735675811768, Discriminator Loss: 0.5787819623947144\n",
      "Epoch: 31/43, Generator Loss: 2.671501636505127, Discriminator Loss: 0.6501219272613525\n",
      "Epoch: 32/43, Generator Loss: 1.965293288230896, Discriminator Loss: 0.6898845434188843\n",
      "Epoch: 33/43, Generator Loss: 2.2155544757843018, Discriminator Loss: 0.5084194540977478\n",
      "Epoch: 34/43, Generator Loss: 1.8418058156967163, Discriminator Loss: 0.8078140020370483\n",
      "Epoch: 35/43, Generator Loss: 2.0332529544830322, Discriminator Loss: 0.4624255299568176\n",
      "Epoch: 36/43, Generator Loss: 3.760315179824829, Discriminator Loss: 0.6042248010635376\n",
      "Epoch: 37/43, Generator Loss: 2.2589216232299805, Discriminator Loss: 0.531467854976654\n",
      "Epoch: 38/43, Generator Loss: 2.398434638977051, Discriminator Loss: 0.5610496997833252\n",
      "Epoch: 39/43, Generator Loss: 3.1053268909454346, Discriminator Loss: 0.4197056293487549\n",
      "Epoch: 40/43, Generator Loss: 2.240722179412842, Discriminator Loss: 0.630564272403717\n",
      "Epoch: 41/43, Generator Loss: 2.5009567737579346, Discriminator Loss: 0.513524055480957\n",
      "Epoch: 42/43, Generator Loss: 2.398530960083008, Discriminator Loss: 0.5079472661018372\n",
      "Epoch: 43/43, Generator Loss: 2.464205503463745, Discriminator Loss: 0.44964638352394104\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.1812\n",
      "Function value obtained: 2.4642\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Epoch: 1/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/51, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/51, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.8486\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Epoch: 1/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/36, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.1596\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Epoch: 1/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 52/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 90/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 95/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 96/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 97/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 98/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 99/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 100/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 23.0586\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "Epoch: 1/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 95/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 96/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 97/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 98/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 99/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 100/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 24.2150\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "Epoch: 1/100, Generator Loss: 0.5130095481872559, Discriminator Loss: 1.6800353527069092\n",
      "Epoch: 2/100, Generator Loss: 0.5120283365249634, Discriminator Loss: 1.6740646362304688\n",
      "Epoch: 3/100, Generator Loss: 0.5023547410964966, Discriminator Loss: 1.6677266359329224\n",
      "Epoch: 4/100, Generator Loss: 0.49762657284736633, Discriminator Loss: 1.65822172164917\n",
      "Epoch: 5/100, Generator Loss: 0.5040553212165833, Discriminator Loss: 1.6709073781967163\n",
      "Epoch: 6/100, Generator Loss: 0.503549337387085, Discriminator Loss: 1.6701630353927612\n",
      "Epoch: 7/100, Generator Loss: 0.5081511735916138, Discriminator Loss: 1.6605595350265503\n",
      "Epoch: 8/100, Generator Loss: 0.5001137852668762, Discriminator Loss: 1.6242190599441528\n",
      "Epoch: 9/100, Generator Loss: 0.5145674347877502, Discriminator Loss: 1.6683801412582397\n",
      "Epoch: 10/100, Generator Loss: 0.5216454267501831, Discriminator Loss: 1.6496821641921997\n",
      "Epoch: 11/100, Generator Loss: 0.5066859126091003, Discriminator Loss: 1.6730403900146484\n",
      "Epoch: 12/100, Generator Loss: 0.5143851637840271, Discriminator Loss: 1.6919238567352295\n",
      "Epoch: 13/100, Generator Loss: 0.5090784430503845, Discriminator Loss: 1.6594716310501099\n",
      "Epoch: 14/100, Generator Loss: 0.5078568458557129, Discriminator Loss: 1.675269365310669\n",
      "Epoch: 15/100, Generator Loss: 0.5167514681816101, Discriminator Loss: 1.6588900089263916\n",
      "Epoch: 16/100, Generator Loss: 0.5180630087852478, Discriminator Loss: 1.6440174579620361\n",
      "Epoch: 17/100, Generator Loss: 0.49907615780830383, Discriminator Loss: 1.6631443500518799\n",
      "Epoch: 18/100, Generator Loss: 0.5006445050239563, Discriminator Loss: 1.6818598508834839\n",
      "Epoch: 19/100, Generator Loss: 0.5035532116889954, Discriminator Loss: 1.692394495010376\n",
      "Epoch: 20/100, Generator Loss: 0.5152692794799805, Discriminator Loss: 1.6901353597640991\n",
      "Epoch: 21/100, Generator Loss: 0.5011419057846069, Discriminator Loss: 1.6687648296356201\n",
      "Epoch: 22/100, Generator Loss: 0.5080579519271851, Discriminator Loss: 1.641101360321045\n",
      "Epoch: 23/100, Generator Loss: 0.4901832342147827, Discriminator Loss: 1.6636155843734741\n",
      "Epoch: 24/100, Generator Loss: 0.5043003559112549, Discriminator Loss: 1.6586180925369263\n",
      "Epoch: 25/100, Generator Loss: 0.5244263410568237, Discriminator Loss: 1.6694289445877075\n",
      "Epoch: 26/100, Generator Loss: 0.5060833096504211, Discriminator Loss: 1.6581318378448486\n",
      "Epoch: 27/100, Generator Loss: 0.49602261185646057, Discriminator Loss: 1.672286868095398\n",
      "Epoch: 28/100, Generator Loss: 0.49926087260246277, Discriminator Loss: 1.6618976593017578\n",
      "Epoch: 29/100, Generator Loss: 0.49841347336769104, Discriminator Loss: 1.6728436946868896\n",
      "Epoch: 30/100, Generator Loss: 0.5062013864517212, Discriminator Loss: 1.6495883464813232\n",
      "Epoch: 31/100, Generator Loss: 0.5029345154762268, Discriminator Loss: 1.6713905334472656\n",
      "Epoch: 32/100, Generator Loss: 0.5008833408355713, Discriminator Loss: 1.6704466342926025\n",
      "Epoch: 33/100, Generator Loss: 0.5104805827140808, Discriminator Loss: 1.660412073135376\n",
      "Epoch: 34/100, Generator Loss: 0.519404947757721, Discriminator Loss: 1.6394766569137573\n",
      "Epoch: 35/100, Generator Loss: 0.5075910687446594, Discriminator Loss: 1.6663098335266113\n",
      "Epoch: 36/100, Generator Loss: 0.5140647292137146, Discriminator Loss: 1.6645021438598633\n",
      "Epoch: 37/100, Generator Loss: 0.5148462653160095, Discriminator Loss: 1.6487314701080322\n",
      "Epoch: 38/100, Generator Loss: 0.5151208639144897, Discriminator Loss: 1.6782478094100952\n",
      "Epoch: 39/100, Generator Loss: 0.514089822769165, Discriminator Loss: 1.6390407085418701\n",
      "Epoch: 40/100, Generator Loss: 0.4973750412464142, Discriminator Loss: 1.677886962890625\n",
      "Epoch: 41/100, Generator Loss: 0.5099004507064819, Discriminator Loss: 1.6495041847229004\n",
      "Epoch: 42/100, Generator Loss: 0.5028892755508423, Discriminator Loss: 1.6972768306732178\n",
      "Epoch: 43/100, Generator Loss: 0.522925078868866, Discriminator Loss: 1.6662817001342773\n",
      "Epoch: 44/100, Generator Loss: 0.5092287063598633, Discriminator Loss: 1.6860170364379883\n",
      "Epoch: 45/100, Generator Loss: 0.5003343820571899, Discriminator Loss: 1.6593958139419556\n",
      "Epoch: 46/100, Generator Loss: 0.5098351240158081, Discriminator Loss: 1.6749475002288818\n",
      "Epoch: 47/100, Generator Loss: 0.5220439434051514, Discriminator Loss: 1.670952558517456\n",
      "Epoch: 48/100, Generator Loss: 0.5044220089912415, Discriminator Loss: 1.6486384868621826\n",
      "Epoch: 49/100, Generator Loss: 0.5151954293251038, Discriminator Loss: 1.6453076601028442\n",
      "Epoch: 50/100, Generator Loss: 0.5090774297714233, Discriminator Loss: 1.6544690132141113\n",
      "Epoch: 51/100, Generator Loss: 0.5001950263977051, Discriminator Loss: 1.6860158443450928\n",
      "Epoch: 52/100, Generator Loss: 0.5048896670341492, Discriminator Loss: 1.6760377883911133\n",
      "Epoch: 53/100, Generator Loss: 0.5138266086578369, Discriminator Loss: 1.6915161609649658\n",
      "Epoch: 54/100, Generator Loss: 0.515387237071991, Discriminator Loss: 1.6442832946777344\n",
      "Epoch: 55/100, Generator Loss: 0.49292880296707153, Discriminator Loss: 1.636215329170227\n",
      "Epoch: 56/100, Generator Loss: 0.5000711679458618, Discriminator Loss: 1.6743268966674805\n",
      "Epoch: 57/100, Generator Loss: 0.48983126878738403, Discriminator Loss: 1.6631700992584229\n",
      "Epoch: 58/100, Generator Loss: 0.5056812763214111, Discriminator Loss: 1.6712442636489868\n",
      "Epoch: 59/100, Generator Loss: 0.5080918669700623, Discriminator Loss: 1.6503548622131348\n",
      "Epoch: 60/100, Generator Loss: 0.5130884051322937, Discriminator Loss: 1.6553173065185547\n",
      "Epoch: 61/100, Generator Loss: 0.5158289074897766, Discriminator Loss: 1.6266043186187744\n",
      "Epoch: 62/100, Generator Loss: 0.5234225392341614, Discriminator Loss: 1.6256449222564697\n",
      "Epoch: 63/100, Generator Loss: 0.5121504664421082, Discriminator Loss: 1.6468307971954346\n",
      "Epoch: 64/100, Generator Loss: 0.5280044078826904, Discriminator Loss: 1.6399115324020386\n",
      "Epoch: 65/100, Generator Loss: 0.5229284763336182, Discriminator Loss: 1.6406586170196533\n",
      "Epoch: 66/100, Generator Loss: 0.5156251192092896, Discriminator Loss: 1.6545186042785645\n",
      "Epoch: 67/100, Generator Loss: 0.5241053104400635, Discriminator Loss: 1.6289491653442383\n",
      "Epoch: 68/100, Generator Loss: 0.5042279958724976, Discriminator Loss: 1.6387362480163574\n",
      "Epoch: 69/100, Generator Loss: 0.5172713994979858, Discriminator Loss: 1.6437947750091553\n",
      "Epoch: 70/100, Generator Loss: 0.5170050263404846, Discriminator Loss: 1.6331448554992676\n",
      "Epoch: 71/100, Generator Loss: 0.5105957984924316, Discriminator Loss: 1.6539826393127441\n",
      "Epoch: 72/100, Generator Loss: 0.5246776938438416, Discriminator Loss: 1.6437976360321045\n",
      "Epoch: 73/100, Generator Loss: 0.5179576277732849, Discriminator Loss: 1.6415996551513672\n",
      "Epoch: 74/100, Generator Loss: 0.49302592873573303, Discriminator Loss: 1.6498777866363525\n",
      "Epoch: 75/100, Generator Loss: 0.5169556140899658, Discriminator Loss: 1.6203877925872803\n",
      "Epoch: 76/100, Generator Loss: 0.5052292346954346, Discriminator Loss: 1.66047203540802\n",
      "Epoch: 77/100, Generator Loss: 0.5174763202667236, Discriminator Loss: 1.6480063199996948\n",
      "Epoch: 78/100, Generator Loss: 0.5150996446609497, Discriminator Loss: 1.6310815811157227\n",
      "Epoch: 79/100, Generator Loss: 0.5243716239929199, Discriminator Loss: 1.668400526046753\n",
      "Epoch: 80/100, Generator Loss: 0.5116304159164429, Discriminator Loss: 1.63517427444458\n",
      "Epoch: 81/100, Generator Loss: 0.510307788848877, Discriminator Loss: 1.6789677143096924\n",
      "Epoch: 82/100, Generator Loss: 0.5160742998123169, Discriminator Loss: 1.639915943145752\n",
      "Epoch: 83/100, Generator Loss: 0.5072377920150757, Discriminator Loss: 1.6488147974014282\n",
      "Epoch: 84/100, Generator Loss: 0.5236891508102417, Discriminator Loss: 1.6853805780410767\n",
      "Epoch: 85/100, Generator Loss: 0.5153401494026184, Discriminator Loss: 1.6637351512908936\n",
      "Epoch: 86/100, Generator Loss: 0.5256752967834473, Discriminator Loss: 1.6762443780899048\n",
      "Epoch: 87/100, Generator Loss: 0.526964545249939, Discriminator Loss: 1.6572531461715698\n",
      "Epoch: 88/100, Generator Loss: 0.5177205204963684, Discriminator Loss: 1.6595923900604248\n",
      "Epoch: 89/100, Generator Loss: 0.5134668946266174, Discriminator Loss: 1.6403696537017822\n",
      "Epoch: 90/100, Generator Loss: 0.5286819338798523, Discriminator Loss: 1.652907133102417\n",
      "Epoch: 91/100, Generator Loss: 0.5228455066680908, Discriminator Loss: 1.6487793922424316\n",
      "Epoch: 92/100, Generator Loss: 0.5125418901443481, Discriminator Loss: 1.6527477502822876\n",
      "Epoch: 93/100, Generator Loss: 0.518815279006958, Discriminator Loss: 1.6462452411651611\n",
      "Epoch: 94/100, Generator Loss: 0.5391849875450134, Discriminator Loss: 1.6448142528533936\n",
      "Epoch: 95/100, Generator Loss: 0.5222875475883484, Discriminator Loss: 1.6677944660186768\n",
      "Epoch: 96/100, Generator Loss: 0.5109830498695374, Discriminator Loss: 1.6204478740692139\n",
      "Epoch: 97/100, Generator Loss: 0.5121116042137146, Discriminator Loss: 1.6502234935760498\n",
      "Epoch: 98/100, Generator Loss: 0.5077077150344849, Discriminator Loss: 1.6997549533843994\n",
      "Epoch: 99/100, Generator Loss: 0.5236312747001648, Discriminator Loss: 1.6328966617584229\n",
      "Epoch: 100/100, Generator Loss: 0.502794623374939, Discriminator Loss: 1.65782630443573\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 23.2824\n",
      "Function value obtained: 0.5028\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "Epoch: 1/100, Generator Loss: 0.4657932221889496, Discriminator Loss: 1.6939828395843506\n",
      "Epoch: 2/100, Generator Loss: 0.46080589294433594, Discriminator Loss: 1.6755948066711426\n",
      "Epoch: 3/100, Generator Loss: 0.48282286524772644, Discriminator Loss: 1.6835243701934814\n",
      "Epoch: 4/100, Generator Loss: 0.47719404101371765, Discriminator Loss: 1.6772880554199219\n",
      "Epoch: 5/100, Generator Loss: 0.4780237078666687, Discriminator Loss: 1.6760379076004028\n",
      "Epoch: 6/100, Generator Loss: 0.47795218229293823, Discriminator Loss: 1.6918582916259766\n",
      "Epoch: 7/100, Generator Loss: 0.46912717819213867, Discriminator Loss: 1.678594708442688\n",
      "Epoch: 8/100, Generator Loss: 0.47515198588371277, Discriminator Loss: 1.6578936576843262\n",
      "Epoch: 9/100, Generator Loss: 0.4899859130382538, Discriminator Loss: 1.6613459587097168\n",
      "Epoch: 10/100, Generator Loss: 0.4720625877380371, Discriminator Loss: 1.6830220222473145\n",
      "Epoch: 11/100, Generator Loss: 0.4732027053833008, Discriminator Loss: 1.6803380250930786\n",
      "Epoch: 12/100, Generator Loss: 0.476561576128006, Discriminator Loss: 1.6742268800735474\n",
      "Epoch: 13/100, Generator Loss: 0.4824131429195404, Discriminator Loss: 1.6689682006835938\n",
      "Epoch: 14/100, Generator Loss: 0.47742560505867004, Discriminator Loss: 1.667752742767334\n",
      "Epoch: 15/100, Generator Loss: 0.4693681001663208, Discriminator Loss: 1.6827914714813232\n",
      "Epoch: 16/100, Generator Loss: 0.4615442156791687, Discriminator Loss: 1.6943166255950928\n",
      "Epoch: 17/100, Generator Loss: 0.46654853224754333, Discriminator Loss: 1.6796541213989258\n",
      "Epoch: 18/100, Generator Loss: 0.47053268551826477, Discriminator Loss: 1.689178228378296\n",
      "Epoch: 19/100, Generator Loss: 0.4762282967567444, Discriminator Loss: 1.671760082244873\n",
      "Epoch: 20/100, Generator Loss: 0.46384888887405396, Discriminator Loss: 1.6684895753860474\n",
      "Epoch: 21/100, Generator Loss: 0.4676916003227234, Discriminator Loss: 1.6961028575897217\n",
      "Epoch: 22/100, Generator Loss: 0.4822637438774109, Discriminator Loss: 1.7001607418060303\n",
      "Epoch: 23/100, Generator Loss: 0.46991604566574097, Discriminator Loss: 1.680644154548645\n",
      "Epoch: 24/100, Generator Loss: 0.46948128938674927, Discriminator Loss: 1.678746223449707\n",
      "Epoch: 25/100, Generator Loss: 0.47945189476013184, Discriminator Loss: 1.692544937133789\n",
      "Epoch: 26/100, Generator Loss: 0.47681716084480286, Discriminator Loss: 1.6703097820281982\n",
      "Epoch: 27/100, Generator Loss: 0.46134045720100403, Discriminator Loss: 1.7021138668060303\n",
      "Epoch: 28/100, Generator Loss: 0.4637906849384308, Discriminator Loss: 1.6608450412750244\n",
      "Epoch: 29/100, Generator Loss: 0.46038010716438293, Discriminator Loss: 1.6815757751464844\n",
      "Epoch: 30/100, Generator Loss: 0.4657531976699829, Discriminator Loss: 1.6842129230499268\n",
      "Epoch: 31/100, Generator Loss: 0.4644835293292999, Discriminator Loss: 1.6893301010131836\n",
      "Epoch: 32/100, Generator Loss: 0.4710572361946106, Discriminator Loss: 1.6738853454589844\n",
      "Epoch: 33/100, Generator Loss: 0.47090524435043335, Discriminator Loss: 1.684005618095398\n",
      "Epoch: 34/100, Generator Loss: 0.46877816319465637, Discriminator Loss: 1.677433967590332\n",
      "Epoch: 35/100, Generator Loss: 0.47519367933273315, Discriminator Loss: 1.6616483926773071\n",
      "Epoch: 36/100, Generator Loss: 0.47141480445861816, Discriminator Loss: 1.6691951751708984\n",
      "Epoch: 37/100, Generator Loss: 0.4767492711544037, Discriminator Loss: 1.6872626543045044\n",
      "Epoch: 38/100, Generator Loss: 0.4657982885837555, Discriminator Loss: 1.6732327938079834\n",
      "Epoch: 39/100, Generator Loss: 0.4714663326740265, Discriminator Loss: 1.6922707557678223\n",
      "Epoch: 40/100, Generator Loss: 0.4647706151008606, Discriminator Loss: 1.6957621574401855\n",
      "Epoch: 41/100, Generator Loss: 0.4705527126789093, Discriminator Loss: 1.681381106376648\n",
      "Epoch: 42/100, Generator Loss: 0.4687614440917969, Discriminator Loss: 1.6850686073303223\n",
      "Epoch: 43/100, Generator Loss: 0.4749177098274231, Discriminator Loss: 1.6630698442459106\n",
      "Epoch: 44/100, Generator Loss: 0.45338666439056396, Discriminator Loss: 1.670367956161499\n",
      "Epoch: 45/100, Generator Loss: 0.4775649905204773, Discriminator Loss: 1.6661946773529053\n",
      "Epoch: 46/100, Generator Loss: 0.46403011679649353, Discriminator Loss: 1.6863765716552734\n",
      "Epoch: 47/100, Generator Loss: 0.4625839293003082, Discriminator Loss: 1.6787045001983643\n",
      "Epoch: 48/100, Generator Loss: 0.4607292711734772, Discriminator Loss: 1.6889361143112183\n",
      "Epoch: 49/100, Generator Loss: 0.4819469153881073, Discriminator Loss: 1.6705749034881592\n",
      "Epoch: 50/100, Generator Loss: 0.4705134332180023, Discriminator Loss: 1.6660330295562744\n",
      "Epoch: 51/100, Generator Loss: 0.4767214059829712, Discriminator Loss: 1.6549623012542725\n",
      "Epoch: 52/100, Generator Loss: 0.4604882597923279, Discriminator Loss: 1.6852188110351562\n",
      "Epoch: 53/100, Generator Loss: 0.476827472448349, Discriminator Loss: 1.6514170169830322\n",
      "Epoch: 54/100, Generator Loss: 0.4777663052082062, Discriminator Loss: 1.6594202518463135\n",
      "Epoch: 55/100, Generator Loss: 0.481383353471756, Discriminator Loss: 1.6998882293701172\n",
      "Epoch: 56/100, Generator Loss: 0.46961450576782227, Discriminator Loss: 1.667709231376648\n",
      "Epoch: 57/100, Generator Loss: 0.4755970537662506, Discriminator Loss: 1.6776578426361084\n",
      "Epoch: 58/100, Generator Loss: 0.4682508111000061, Discriminator Loss: 1.6898999214172363\n",
      "Epoch: 59/100, Generator Loss: 0.4720304012298584, Discriminator Loss: 1.692786455154419\n",
      "Epoch: 60/100, Generator Loss: 0.4745436906814575, Discriminator Loss: 1.6759904623031616\n",
      "Epoch: 61/100, Generator Loss: 0.4892387390136719, Discriminator Loss: 1.6638175249099731\n",
      "Epoch: 62/100, Generator Loss: 0.4726845622062683, Discriminator Loss: 1.6906547546386719\n",
      "Epoch: 63/100, Generator Loss: 0.4820442497730255, Discriminator Loss: 1.671642541885376\n",
      "Epoch: 64/100, Generator Loss: 0.4780266284942627, Discriminator Loss: 1.6793768405914307\n",
      "Epoch: 65/100, Generator Loss: 0.4746856987476349, Discriminator Loss: 1.6668701171875\n",
      "Epoch: 66/100, Generator Loss: 0.48588326573371887, Discriminator Loss: 1.66408371925354\n",
      "Epoch: 67/100, Generator Loss: 0.46810629963874817, Discriminator Loss: 1.6658973693847656\n",
      "Epoch: 68/100, Generator Loss: 0.46601414680480957, Discriminator Loss: 1.6829469203948975\n",
      "Epoch: 69/100, Generator Loss: 0.48401379585266113, Discriminator Loss: 1.6705408096313477\n",
      "Epoch: 70/100, Generator Loss: 0.48997724056243896, Discriminator Loss: 1.6616106033325195\n",
      "Epoch: 71/100, Generator Loss: 0.47433704137802124, Discriminator Loss: 1.6746759414672852\n",
      "Epoch: 72/100, Generator Loss: 0.46962234377861023, Discriminator Loss: 1.6632897853851318\n",
      "Epoch: 73/100, Generator Loss: 0.46137726306915283, Discriminator Loss: 1.6716985702514648\n",
      "Epoch: 74/100, Generator Loss: 0.47921761870384216, Discriminator Loss: 1.6898540258407593\n",
      "Epoch: 75/100, Generator Loss: 0.4777001440525055, Discriminator Loss: 1.68465256690979\n",
      "Epoch: 76/100, Generator Loss: 0.4827122986316681, Discriminator Loss: 1.6668282747268677\n",
      "Epoch: 77/100, Generator Loss: 0.46768900752067566, Discriminator Loss: 1.6875646114349365\n",
      "Epoch: 78/100, Generator Loss: 0.483582079410553, Discriminator Loss: 1.6666386127471924\n",
      "Epoch: 79/100, Generator Loss: 0.47822412848472595, Discriminator Loss: 1.6552693843841553\n",
      "Epoch: 80/100, Generator Loss: 0.4852752983570099, Discriminator Loss: 1.6556065082550049\n",
      "Epoch: 81/100, Generator Loss: 0.47998639941215515, Discriminator Loss: 1.6478573083877563\n",
      "Epoch: 82/100, Generator Loss: 0.47475895285606384, Discriminator Loss: 1.6649537086486816\n",
      "Epoch: 83/100, Generator Loss: 0.4772423803806305, Discriminator Loss: 1.6853854656219482\n",
      "Epoch: 84/100, Generator Loss: 0.4719740152359009, Discriminator Loss: 1.6642394065856934\n",
      "Epoch: 85/100, Generator Loss: 0.4724038541316986, Discriminator Loss: 1.661264419555664\n",
      "Epoch: 86/100, Generator Loss: 0.4701319634914398, Discriminator Loss: 1.6568024158477783\n",
      "Epoch: 87/100, Generator Loss: 0.4823054075241089, Discriminator Loss: 1.6758278608322144\n",
      "Epoch: 88/100, Generator Loss: 0.48304057121276855, Discriminator Loss: 1.6487231254577637\n",
      "Epoch: 89/100, Generator Loss: 0.47315025329589844, Discriminator Loss: 1.6539757251739502\n",
      "Epoch: 90/100, Generator Loss: 0.4827350974082947, Discriminator Loss: 1.6564033031463623\n",
      "Epoch: 91/100, Generator Loss: 0.48782050609588623, Discriminator Loss: 1.6410791873931885\n",
      "Epoch: 92/100, Generator Loss: 0.4767472445964813, Discriminator Loss: 1.6652214527130127\n",
      "Epoch: 93/100, Generator Loss: 0.48308640718460083, Discriminator Loss: 1.6689863204956055\n",
      "Epoch: 94/100, Generator Loss: 0.48803770542144775, Discriminator Loss: 1.6568005084991455\n",
      "Epoch: 95/100, Generator Loss: 0.4851025640964508, Discriminator Loss: 1.6662375926971436\n",
      "Epoch: 96/100, Generator Loss: 0.48779311776161194, Discriminator Loss: 1.679260492324829\n",
      "Epoch: 97/100, Generator Loss: 0.4783168137073517, Discriminator Loss: 1.6666147708892822\n",
      "Epoch: 98/100, Generator Loss: 0.4801205098628998, Discriminator Loss: 1.663201928138733\n",
      "Epoch: 99/100, Generator Loss: 0.4747944176197052, Discriminator Loss: 1.669842004776001\n",
      "Epoch: 100/100, Generator Loss: 0.4922052323818207, Discriminator Loss: 1.6954339742660522\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 23.1892\n",
      "Function value obtained: 0.4922\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "Epoch: 1/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/30, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.5181\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "Epoch: 1/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/77, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 17.9005\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "Epoch: 1/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 5/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 9/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/100, Generator Loss: 99.15966796875, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/100, Generator Loss: 99.15966796875, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/100, Generator Loss: 99.15966796875, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/100, Generator Loss: 99.15966796875, Discriminator Loss: 100.84034729003906\n",
      "Epoch: 32/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/100, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 39/100, Generator Loss: 99.15966796875, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.84034729003906\n",
      "Epoch: 56/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/100, Generator Loss: 99.15966796875, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.84034729003906\n",
      "Epoch: 80/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/100, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 83/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.84034729003906\n",
      "Epoch: 84/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/100, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 87/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 95/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 96/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 97/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 98/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 99/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 100/100, Generator Loss: 99.15966796875, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 21.7669\n",
      "Function value obtained: 99.1597\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "Epoch: 1/48, Generator Loss: 100.00000762939453, Discriminator Loss: 37.815128326416016\n",
      "Epoch: 2/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 3/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 4/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 5/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 6/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 7/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 8/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 9/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 10/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 11/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 12/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 13/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 14/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 15/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 16/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 17/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 18/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 19/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 20/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 21/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 22/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 23/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 24/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 25/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 26/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 27/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 28/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 29/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 30/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 31/48, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 32/48, Generator Loss: 86.55462646484375, Discriminator Loss: 8.403361320495605\n",
      "Epoch: 33/48, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/48, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/48, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/48, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/48, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/48, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/48, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/48, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/48, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/48, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/48, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/48, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/48, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/48, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/48, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/48, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.5731\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "Epoch: 1/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/59, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/59, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 7/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/59, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.7412\n",
      "Function value obtained: 100.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "Epoch: 1/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/94, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 20.7175\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "Epoch: 1/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.7504\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "Epoch: 1/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/65, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 14.7232\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "Epoch: 1/44, Generator Loss: 91.01937103271484, Discriminator Loss: 49.067962646484375\n",
      "Epoch: 2/44, Generator Loss: 0.8403362035751343, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 3/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/44, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.8962\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "Epoch: 1/98, Generator Loss: 22.689077377319336, Discriminator Loss: 78.9916000366211\n",
      "Epoch: 2/98, Generator Loss: 19.32773208618164, Discriminator Loss: 83.19328308105469\n",
      "Epoch: 3/98, Generator Loss: 12.605042457580566, Discriminator Loss: 80.67227172851562\n",
      "Epoch: 4/98, Generator Loss: 19.32773208618164, Discriminator Loss: 81.51261138916016\n",
      "Epoch: 5/98, Generator Loss: 17.64706039428711, Discriminator Loss: 86.55462646484375\n",
      "Epoch: 6/98, Generator Loss: 16.80672264099121, Discriminator Loss: 80.67227172851562\n",
      "Epoch: 7/98, Generator Loss: 18.487396240234375, Discriminator Loss: 78.1512680053711\n",
      "Epoch: 8/98, Generator Loss: 13.445379257202148, Discriminator Loss: 82.35294342041016\n",
      "Epoch: 9/98, Generator Loss: 14.285715103149414, Discriminator Loss: 79.83193969726562\n",
      "Epoch: 10/98, Generator Loss: 21.84874153137207, Discriminator Loss: 73.10924530029297\n",
      "Epoch: 11/98, Generator Loss: 19.32773208618164, Discriminator Loss: 78.9916000366211\n",
      "Epoch: 12/98, Generator Loss: 19.32773208618164, Discriminator Loss: 82.35294342041016\n",
      "Epoch: 13/98, Generator Loss: 21.008403778076172, Discriminator Loss: 86.55462646484375\n",
      "Epoch: 14/98, Generator Loss: 15.12605094909668, Discriminator Loss: 81.51261138916016\n",
      "Epoch: 15/98, Generator Loss: 25.210084915161133, Discriminator Loss: 80.67227172851562\n",
      "Epoch: 16/98, Generator Loss: 7.56302547454834, Discriminator Loss: 89.07563781738281\n",
      "Epoch: 17/98, Generator Loss: 15.966387748718262, Discriminator Loss: 81.51261138916016\n",
      "Epoch: 18/98, Generator Loss: 20.168067932128906, Discriminator Loss: 90.75630950927734\n",
      "Epoch: 19/98, Generator Loss: 16.80672264099121, Discriminator Loss: 78.1512680053711\n",
      "Epoch: 20/98, Generator Loss: 20.168067932128906, Discriminator Loss: 79.83193969726562\n",
      "Epoch: 21/98, Generator Loss: 20.168067932128906, Discriminator Loss: 81.51261138916016\n",
      "Epoch: 22/98, Generator Loss: 15.966387748718262, Discriminator Loss: 79.83193969726562\n",
      "Epoch: 23/98, Generator Loss: 15.966387748718262, Discriminator Loss: 81.51261138916016\n",
      "Epoch: 24/98, Generator Loss: 19.32773208618164, Discriminator Loss: 79.83193969726562\n",
      "Epoch: 25/98, Generator Loss: 10.924370765686035, Discriminator Loss: 87.39496612548828\n",
      "Epoch: 26/98, Generator Loss: 20.168067932128906, Discriminator Loss: 82.35294342041016\n",
      "Epoch: 27/98, Generator Loss: 21.008403778076172, Discriminator Loss: 79.83193969726562\n",
      "Epoch: 28/98, Generator Loss: 13.445379257202148, Discriminator Loss: 82.35294342041016\n",
      "Epoch: 29/98, Generator Loss: 20.168067932128906, Discriminator Loss: 83.19328308105469\n",
      "Epoch: 30/98, Generator Loss: 16.80672264099121, Discriminator Loss: 78.9916000366211\n",
      "Epoch: 31/98, Generator Loss: 20.168067932128906, Discriminator Loss: 81.51261138916016\n",
      "Epoch: 32/98, Generator Loss: 18.487396240234375, Discriminator Loss: 85.71428680419922\n",
      "Epoch: 33/98, Generator Loss: 23.5294132232666, Discriminator Loss: 87.39496612548828\n",
      "Epoch: 34/98, Generator Loss: 20.168067932128906, Discriminator Loss: 78.1512680053711\n",
      "Epoch: 35/98, Generator Loss: 15.966387748718262, Discriminator Loss: 77.31092834472656\n",
      "Epoch: 36/98, Generator Loss: 20.168067932128906, Discriminator Loss: 78.9916000366211\n",
      "Epoch: 37/98, Generator Loss: 8.403361320495605, Discriminator Loss: 78.9916000366211\n",
      "Epoch: 38/98, Generator Loss: 19.32773208618164, Discriminator Loss: 80.67227172851562\n",
      "Epoch: 39/98, Generator Loss: 14.285715103149414, Discriminator Loss: 81.51261138916016\n",
      "Epoch: 40/98, Generator Loss: 17.64706039428711, Discriminator Loss: 83.19328308105469\n",
      "Epoch: 41/98, Generator Loss: 14.285715103149414, Discriminator Loss: 83.19328308105469\n",
      "Epoch: 42/98, Generator Loss: 17.64706039428711, Discriminator Loss: 83.19328308105469\n",
      "Epoch: 43/98, Generator Loss: 23.5294132232666, Discriminator Loss: 81.51261138916016\n",
      "Epoch: 44/98, Generator Loss: 15.12605094909668, Discriminator Loss: 79.83193969726562\n",
      "Epoch: 45/98, Generator Loss: 16.80672264099121, Discriminator Loss: 78.1512680053711\n",
      "Epoch: 46/98, Generator Loss: 18.487396240234375, Discriminator Loss: 83.19328308105469\n",
      "Epoch: 47/98, Generator Loss: 16.80672264099121, Discriminator Loss: 81.51261138916016\n",
      "Epoch: 48/98, Generator Loss: 11.7647066116333, Discriminator Loss: 80.67227172851562\n",
      "Epoch: 49/98, Generator Loss: 15.966387748718262, Discriminator Loss: 84.87395477294922\n",
      "Epoch: 50/98, Generator Loss: 19.32773208618164, Discriminator Loss: 83.19328308105469\n",
      "Epoch: 51/98, Generator Loss: 14.285715103149414, Discriminator Loss: 78.9916000366211\n",
      "Epoch: 52/98, Generator Loss: 15.966387748718262, Discriminator Loss: 80.67227172851562\n",
      "Epoch: 53/98, Generator Loss: 22.689077377319336, Discriminator Loss: 78.1512680053711\n",
      "Epoch: 54/98, Generator Loss: 17.64706039428711, Discriminator Loss: 79.83193969726562\n",
      "Epoch: 55/98, Generator Loss: 15.12605094909668, Discriminator Loss: 82.35294342041016\n",
      "Epoch: 56/98, Generator Loss: 19.32773208618164, Discriminator Loss: 84.03361511230469\n",
      "Epoch: 57/98, Generator Loss: 11.7647066116333, Discriminator Loss: 89.07563781738281\n",
      "Epoch: 58/98, Generator Loss: 18.487396240234375, Discriminator Loss: 77.31092834472656\n",
      "Epoch: 59/98, Generator Loss: 16.80672264099121, Discriminator Loss: 80.67227172851562\n",
      "Epoch: 60/98, Generator Loss: 12.605042457580566, Discriminator Loss: 81.51261138916016\n",
      "Epoch: 61/98, Generator Loss: 21.008403778076172, Discriminator Loss: 75.63025665283203\n",
      "Epoch: 62/98, Generator Loss: 15.12605094909668, Discriminator Loss: 79.83193969726562\n",
      "Epoch: 63/98, Generator Loss: 15.12605094909668, Discriminator Loss: 84.87395477294922\n",
      "Epoch: 64/98, Generator Loss: 18.487396240234375, Discriminator Loss: 78.9916000366211\n",
      "Epoch: 65/98, Generator Loss: 21.008403778076172, Discriminator Loss: 84.87395477294922\n",
      "Epoch: 66/98, Generator Loss: 15.12605094909668, Discriminator Loss: 76.47058868408203\n",
      "Epoch: 67/98, Generator Loss: 15.966387748718262, Discriminator Loss: 85.71428680419922\n",
      "Epoch: 68/98, Generator Loss: 15.12605094909668, Discriminator Loss: 84.87395477294922\n",
      "Epoch: 69/98, Generator Loss: 15.12605094909668, Discriminator Loss: 84.03361511230469\n",
      "Epoch: 70/98, Generator Loss: 12.605042457580566, Discriminator Loss: 82.35294342041016\n",
      "Epoch: 71/98, Generator Loss: 16.80672264099121, Discriminator Loss: 78.9916000366211\n",
      "Epoch: 72/98, Generator Loss: 15.12605094909668, Discriminator Loss: 81.51261138916016\n",
      "Epoch: 73/98, Generator Loss: 17.64706039428711, Discriminator Loss: 85.71428680419922\n",
      "Epoch: 74/98, Generator Loss: 23.5294132232666, Discriminator Loss: 84.87395477294922\n",
      "Epoch: 75/98, Generator Loss: 15.966387748718262, Discriminator Loss: 79.83193969726562\n",
      "Epoch: 76/98, Generator Loss: 15.12605094909668, Discriminator Loss: 74.7899169921875\n",
      "Epoch: 77/98, Generator Loss: 15.12605094909668, Discriminator Loss: 84.03361511230469\n",
      "Epoch: 78/98, Generator Loss: 22.689077377319336, Discriminator Loss: 87.39496612548828\n",
      "Epoch: 79/98, Generator Loss: 15.12605094909668, Discriminator Loss: 80.67227172851562\n",
      "Epoch: 80/98, Generator Loss: 19.32773208618164, Discriminator Loss: 84.87395477294922\n",
      "Epoch: 81/98, Generator Loss: 19.32773208618164, Discriminator Loss: 89.07563781738281\n",
      "Epoch: 82/98, Generator Loss: 20.168067932128906, Discriminator Loss: 86.55462646484375\n",
      "Epoch: 83/98, Generator Loss: 20.168067932128906, Discriminator Loss: 80.67227172851562\n",
      "Epoch: 84/98, Generator Loss: 15.966387748718262, Discriminator Loss: 80.67227172851562\n",
      "Epoch: 85/98, Generator Loss: 20.168067932128906, Discriminator Loss: 74.7899169921875\n",
      "Epoch: 86/98, Generator Loss: 16.80672264099121, Discriminator Loss: 80.67227172851562\n",
      "Epoch: 87/98, Generator Loss: 22.689077377319336, Discriminator Loss: 78.1512680053711\n",
      "Epoch: 88/98, Generator Loss: 27.731094360351562, Discriminator Loss: 81.51261138916016\n",
      "Epoch: 89/98, Generator Loss: 16.80672264099121, Discriminator Loss: 83.19328308105469\n",
      "Epoch: 90/98, Generator Loss: 20.168067932128906, Discriminator Loss: 83.19328308105469\n",
      "Epoch: 91/98, Generator Loss: 20.168067932128906, Discriminator Loss: 77.31092834472656\n",
      "Epoch: 92/98, Generator Loss: 15.12605094909668, Discriminator Loss: 84.03361511230469\n",
      "Epoch: 93/98, Generator Loss: 14.285715103149414, Discriminator Loss: 83.19328308105469\n",
      "Epoch: 94/98, Generator Loss: 18.487396240234375, Discriminator Loss: 77.31092834472656\n",
      "Epoch: 95/98, Generator Loss: 17.64706039428711, Discriminator Loss: 83.19328308105469\n",
      "Epoch: 96/98, Generator Loss: 12.605042457580566, Discriminator Loss: 81.51261138916016\n",
      "Epoch: 97/98, Generator Loss: 15.12605094909668, Discriminator Loss: 83.19328308105469\n",
      "Epoch: 98/98, Generator Loss: 15.12605094909668, Discriminator Loss: 75.63025665283203\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 21.5916\n",
      "Function value obtained: 15.1261\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "Epoch: 1/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 73/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 82/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 83/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 95/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 96/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 97/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 98/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 99/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 100/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 21.8448\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "Epoch: 1/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/100, Generator Loss: 0.13174110651016235, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 95/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 96/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 97/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 98/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 99/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 100/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 21.4655\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "Epoch: 1/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 4/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 5/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 8/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 47/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 48/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 71/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 72/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 95/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 96/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 97/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 98/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 99/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 100/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 22.5473\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "Epoch: 1/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/96, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 43/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/96, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 50/96, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 51/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/96, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 62/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/96, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 89/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 95/96, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 96/96, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 22.5650\n",
      "Function value obtained: 100.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "Epoch: 1/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 95/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 96/96, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 21.2599\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "Epoch: 1/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 95/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 96/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 97/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 98/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 99/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 100/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 23.7180\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "Epoch: 1/100, Generator Loss: 4.201680660247803, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 2/100, Generator Loss: 3.361344814300537, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 3/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 95.79832458496094\n",
      "Epoch: 4/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 98.3193359375\n",
      "Epoch: 5/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 6/100, Generator Loss: 3.361344814300537, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 7/100, Generator Loss: 6.722689628601074, Discriminator Loss: 94.9579849243164\n",
      "Epoch: 8/100, Generator Loss: 3.361344814300537, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 9/100, Generator Loss: 3.361344814300537, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 10/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 11/100, Generator Loss: 5.042016983032227, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 12/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 13/100, Generator Loss: 3.361344814300537, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 14/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 98.3193359375\n",
      "Epoch: 15/100, Generator Loss: 3.361344814300537, Discriminator Loss: 94.9579849243164\n",
      "Epoch: 16/100, Generator Loss: 3.361344814300537, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 17/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 18/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 19/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 98.3193359375\n",
      "Epoch: 20/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 21/100, Generator Loss: 3.361344814300537, Discriminator Loss: 95.79832458496094\n",
      "Epoch: 22/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 23/100, Generator Loss: 3.361344814300537, Discriminator Loss: 95.79832458496094\n",
      "Epoch: 24/100, Generator Loss: 5.042016983032227, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 25/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 26/100, Generator Loss: 3.361344814300537, Discriminator Loss: 94.9579849243164\n",
      "Epoch: 27/100, Generator Loss: 6.722689628601074, Discriminator Loss: 99.15966796875\n",
      "Epoch: 28/100, Generator Loss: 4.201680660247803, Discriminator Loss: 95.79832458496094\n",
      "Epoch: 29/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 99.15966796875\n",
      "Epoch: 30/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 98.3193359375\n",
      "Epoch: 31/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 32/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 99.15966796875\n",
      "Epoch: 33/100, Generator Loss: 4.201680660247803, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/100, Generator Loss: 4.201680660247803, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 35/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 98.3193359375\n",
      "Epoch: 36/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 93.27731323242188\n",
      "Epoch: 37/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 94.9579849243164\n",
      "Epoch: 39/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 98.3193359375\n",
      "Epoch: 40/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 99.15966796875\n",
      "Epoch: 41/100, Generator Loss: 5.042016983032227, Discriminator Loss: 95.79832458496094\n",
      "Epoch: 42/100, Generator Loss: 4.201680660247803, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 43/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 44/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 45/100, Generator Loss: 3.361344814300537, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 46/100, Generator Loss: 5.88235330581665, Discriminator Loss: 94.95799255371094\n",
      "Epoch: 47/100, Generator Loss: 0.0, Discriminator Loss: 98.3193359375\n",
      "Epoch: 48/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 98.3193359375\n",
      "Epoch: 49/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 52/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 98.3193359375\n",
      "Epoch: 53/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 54/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 55/100, Generator Loss: 3.361344814300537, Discriminator Loss: 99.15966796875\n",
      "Epoch: 56/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 99.15966796875\n",
      "Epoch: 57/100, Generator Loss: 5.88235330581665, Discriminator Loss: 98.3193359375\n",
      "Epoch: 58/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 95.79832458496094\n",
      "Epoch: 59/100, Generator Loss: 5.88235330581665, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 60/100, Generator Loss: 3.361344814300537, Discriminator Loss: 95.79832458496094\n",
      "Epoch: 61/100, Generator Loss: 5.88235330581665, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 62/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 63/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 64/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 96.63866424560547\n",
      "Epoch: 65/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 66/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/100, Generator Loss: 6.722689628601074, Discriminator Loss: 99.15966796875\n",
      "Epoch: 68/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 69/100, Generator Loss: 4.201680660247803, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 70/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 71/100, Generator Loss: 4.201680660247803, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 72/100, Generator Loss: 7.56302547454834, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 73/100, Generator Loss: 5.88235330581665, Discriminator Loss: 99.15966796875\n",
      "Epoch: 74/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 98.3193359375\n",
      "Epoch: 75/100, Generator Loss: 5.042016983032227, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/100, Generator Loss: 5.042016983032227, Discriminator Loss: 95.79832458496094\n",
      "Epoch: 77/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 98.3193359375\n",
      "Epoch: 79/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 80/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 94.9579849243164\n",
      "Epoch: 81/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 99.15966796875\n",
      "Epoch: 82/100, Generator Loss: 3.361344814300537, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 83/100, Generator Loss: 3.361344814300537, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 84/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 85/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 86/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 87/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 95.79832458496094\n",
      "Epoch: 88/100, Generator Loss: 4.201680660247803, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 89/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 90/100, Generator Loss: 3.361344814300537, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 91/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 92/100, Generator Loss: 4.201680660247803, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 93/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 95.79832458496094\n",
      "Epoch: 94/100, Generator Loss: 2.5210084915161133, Discriminator Loss: 97.47899627685547\n",
      "Epoch: 95/100, Generator Loss: 5.042016983032227, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 96/100, Generator Loss: 4.201680660247803, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 97/100, Generator Loss: 5.88235330581665, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 98/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 98.3193359375\n",
      "Epoch: 99/100, Generator Loss: 3.361344814300537, Discriminator Loss: 96.63865661621094\n",
      "Epoch: 100/100, Generator Loss: 1.6806724071502686, Discriminator Loss: 95.79832458496094\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 23.7642\n",
      "Function value obtained: 1.6807\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n",
      "Epoch: 1/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/42, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 14/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/42, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.9705\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "Epoch: 1/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 7/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 8/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 99.15966796875\n",
      "Epoch: 30/100, Generator Loss: 0.0, Discriminator Loss: 98.3193359375\n",
      "Epoch: 31/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 37/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 39/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/100, Generator Loss: 0.8403362035751343, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 59/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 62/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 65/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 79/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/100, Generator Loss: 0.0, Discriminator Loss: 98.3193359375\n",
      "Epoch: 81/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 92/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 93/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Epoch: 95/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 96/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 97/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 98/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 99/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 100/100, Generator Loss: 0.0, Discriminator Loss: 99.15966796875\n",
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 23.8949\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "Epoch: 1/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/64, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 14.7546\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n",
      "Epoch: 1/61, Generator Loss: 0.8403362035751343, Discriminator Loss: 99.15966796875\n",
      "Epoch: 2/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/61, Generator Loss: 1.6806724071502686, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/61, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 14.6864\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "Epoch: 1/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/100, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/100, Generator Loss: 100.00000762939453, Discriminator Loss: 99.15966796875\n",
      "Epoch: 29/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 95/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 96/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 97/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 98/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 99/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 100/100, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 22.8802\n",
      "Function value obtained: 100.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "Epoch: 1/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/98, Generator Loss: 0.8403362035751343, Discriminator Loss: 99.15966796875\n",
      "Epoch: 3/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 66/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 67/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 68/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 69/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 70/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 71/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 72/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 73/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 74/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 75/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 76/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 77/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 78/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 79/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 80/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 81/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 82/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 83/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 84/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 85/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 86/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 87/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 88/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 89/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 90/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 91/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 92/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 93/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 94/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 95/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 96/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 97/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 98/98, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 21.9100\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n",
      "Epoch: 1/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/65, Generator Loss: 0.0, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 14.3457\n",
      "Function value obtained: 0.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n",
      "Epoch: 1/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 2/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 3/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 4/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 5/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 6/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 7/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 8/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 9/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 10/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 11/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 12/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 13/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 14/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 15/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 16/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 17/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 18/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 19/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 20/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 21/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 22/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 23/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 24/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 25/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 26/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 27/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 28/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 29/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 30/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 31/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 32/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 33/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 34/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 35/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 36/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 37/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 38/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 39/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 40/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 41/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 42/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 43/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 44/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 45/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 46/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 47/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 48/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 49/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.8403362035751343\n",
      "Epoch: 50/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 51/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 52/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 53/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 54/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 55/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 56/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 57/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 58/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 59/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 60/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 61/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 62/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 63/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 64/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 65/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 66/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 67/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 68/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 69/69, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 15.2488\n",
      "Function value obtained: 100.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n",
      "Epoch: 1/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 2/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 3/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 4/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 5/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 6/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 7/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 8/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 9/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 10/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 11/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 12/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 13/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 14/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 15/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 16/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 17/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 18/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 19/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 20/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 21/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 22/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 23/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 24/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 25/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 26/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 27/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 28/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 29/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 30/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 31/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 32/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 33/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 34/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 35/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 36/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 37/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 38/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 39/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 40/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 41/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 42/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 43/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 44/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 45/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 46/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 47/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 48/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 49/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 50/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 51/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 52/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 53/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 54/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 55/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 56/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 57/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 58/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 59/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 60/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 61/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 62/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 63/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 64/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 65/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 66/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 67/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 68/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 69/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 70/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 71/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Epoch: 72/72, Generator Loss: 100.00000762939453, Discriminator Loss: 0.0\n",
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 16.8863\n",
      "Function value obtained: 100.0000\n",
      "Current minimum: 0.0000\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n",
      "Epoch: 1/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 2/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 3/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 4/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 5/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 6/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 7/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 8/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 9/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 10/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 11/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 12/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 13/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 14/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 15/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 16/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 17/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 18/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 19/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 20/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 21/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 22/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 23/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 24/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 25/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 26/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 27/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 28/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 29/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 30/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 31/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 32/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 33/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 34/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 35/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 36/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 37/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 38/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 39/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 40/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 41/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 42/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 43/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 44/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 45/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 46/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 47/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 48/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 49/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 50/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 51/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 52/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 53/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 54/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 55/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 56/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 57/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 58/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 59/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 60/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 61/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 62/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 63/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 64/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Epoch: 65/65, Generator Loss: 100.00000762939453, Discriminator Loss: 100.00000762939453\n",
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 15.0365\n",
      "Function value obtained: 100.0000\n",
      "Current minimum: 0.0000\n",
      "Best Parameters: {'num_epochs': 84, 'gen_hidden_dim': 388, 'disc_hidden_dim': 500, 'gen_lr': 0.3541447475589537, 'disc_lr': 0.004889196346276748, 'gen_beta1': 0.5043910067587798, 'disc_beta1': 0.5418089024714836}\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(torch.tensor(X, dtype = torch.float32), torch.tensor(y, dtype = torch.float32))\n",
    "dataloader = DataLoader(dataset, batch_size = 128, shuffle = True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "noise_dim = 100\n",
    "label_dim = y_cgan.shape[1]\n",
    "input_dim = X_cgan.shape[1]\n",
    "output_dim = X_cgan.shape[1]\n",
    "best_params = bayesian_optimization_cgan(dataloader, device, noise_dim, label_dim, output_dim)\n",
    "print(f\"Best Parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (d) Feature Selection by AdaBoosting with Decision Stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size = 0.2, random_state = 233)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 1), n_estimators = 100)\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred = ada.predict(X_test)\n",
    "\n",
    "feature_importance = np.mean([tree.feature_importances_ for tree in ada.estimators_], axis = 0)\n",
    "feature_importance = pd.DataFrame(feature_importance, index = X_train.columns, columns = [\"importance\"]).sort_values(\"importance\", ascending = False)\n",
    "aggregated_features = {}\n",
    "variable_index = categorical + numerical\n",
    "for feature in variable_index:\n",
    "    for i in range(len(feature_importance.index)):\n",
    "        if feature in feature_importance.index[i]:\n",
    "            if feature in aggregated_features:\n",
    "                aggregated_features[feature] += feature_importance.iloc[i, 0]\n",
    "            else:\n",
    "                aggregated_features[feature] = feature_importance.iloc[i, 0]\n",
    "        else:\n",
    "            if feature not in aggregated_features:\n",
    "                aggregated_features[feature] = 0\n",
    "aggregated_features = pd.DataFrame.from_dict(aggregated_features, orient = \"index\", columns = [\"importance\"]).sort_values(\"importance\", ascending = False)\n",
    "aggregated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "sns.barplot(x = aggregated_features[\"importance\"], y = aggregated_features.index).set(title = \"Feature Importance\", xlabel = \"Importance\", ylabel = \"Features\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area_accident_occured</th>\n",
       "      <th>Cause_of_accident</th>\n",
       "      <th>Type_of_vehicle</th>\n",
       "      <th>Vehicle_movement</th>\n",
       "      <th>Driving_experience</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Lanes_or_Medians</th>\n",
       "      <th>Type_of_collision</th>\n",
       "      <th>Age_band_of_driver</th>\n",
       "      <th>Number_of_casualties</th>\n",
       "      <th>Educational_level</th>\n",
       "      <th>Number_of_vehicles_involved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Office areas</td>\n",
       "      <td>Overtaking</td>\n",
       "      <td>Public (&gt; 45 seats)</td>\n",
       "      <td>Going straight</td>\n",
       "      <td>Above 10yr</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Undivided Two way</td>\n",
       "      <td>Vehicle with vehicle collision</td>\n",
       "      <td>31-50</td>\n",
       "      <td>2</td>\n",
       "      <td>Junior high school</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Office areas</td>\n",
       "      <td>Changing lane to the right</td>\n",
       "      <td>Public (&gt; 45 seats)</td>\n",
       "      <td>Going straight</td>\n",
       "      <td>5-10yr</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>other</td>\n",
       "      <td>Vehicle with vehicle collision</td>\n",
       "      <td>18-30</td>\n",
       "      <td>2</td>\n",
       "      <td>Junior high school</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Residential areas</td>\n",
       "      <td>No priority to vehicle</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>U-Turn</td>\n",
       "      <td>2-5yr</td>\n",
       "      <td>Friday</td>\n",
       "      <td>other</td>\n",
       "      <td>Vehicle with vehicle collision</td>\n",
       "      <td>18-30</td>\n",
       "      <td>1</td>\n",
       "      <td>Junior high school</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Industrial areas</td>\n",
       "      <td>Changing lane to the right</td>\n",
       "      <td>Lorry (41?100Q)</td>\n",
       "      <td>Going straight</td>\n",
       "      <td>Above 10yr</td>\n",
       "      <td>Friday</td>\n",
       "      <td>other</td>\n",
       "      <td>Collision with roadside-parked vehicles</td>\n",
       "      <td>18-30</td>\n",
       "      <td>1</td>\n",
       "      <td>Junior high school</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Residential areas</td>\n",
       "      <td>Moving Backward</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>U-Turn</td>\n",
       "      <td>1-2yr</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Undivided Two way</td>\n",
       "      <td>Collision with roadside-parked vehicles</td>\n",
       "      <td>18-30</td>\n",
       "      <td>1</td>\n",
       "      <td>Junior high school</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Area_accident_occured           Cause_of_accident      Type_of_vehicle  \\\n",
       "1          Office areas                  Overtaking  Public (> 45 seats)   \n",
       "3          Office areas  Changing lane to the right  Public (> 45 seats)   \n",
       "7     Residential areas      No priority to vehicle           Automobile   \n",
       "8      Industrial areas  Changing lane to the right      Lorry (41?100Q)   \n",
       "9     Residential areas             Moving Backward           Automobile   \n",
       "\n",
       "  Vehicle_movement Driving_experience Day_of_week   Lanes_or_Medians  \\\n",
       "1   Going straight         Above 10yr      Monday  Undivided Two way   \n",
       "3   Going straight             5-10yr      Sunday              other   \n",
       "7           U-Turn              2-5yr      Friday              other   \n",
       "8   Going straight         Above 10yr      Friday              other   \n",
       "9           U-Turn              1-2yr      Friday  Undivided Two way   \n",
       "\n",
       "                         Type_of_collision Age_band_of_driver  \\\n",
       "1           Vehicle with vehicle collision              31-50   \n",
       "3           Vehicle with vehicle collision              18-30   \n",
       "7           Vehicle with vehicle collision              18-30   \n",
       "8  Collision with roadside-parked vehicles              18-30   \n",
       "9  Collision with roadside-parked vehicles              18-30   \n",
       "\n",
       "   Number_of_casualties   Educational_level  Number_of_vehicles_involved  \n",
       "1                     2  Junior high school                            2  \n",
       "3                     2  Junior high school                            2  \n",
       "7                     1  Junior high school                            2  \n",
       "8                     1  Junior high school                            2  \n",
       "9                     1  Junior high school                            2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_feature = aggregated_features.index[:12].tolist()\n",
    "eta_new = eta[ada_feature]\n",
    "eta_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_new = [col for col in eta_new.columns]\n",
    "categorical_new.remove(\"Number_of_vehicles_involved\")\n",
    "categorical_new.remove(\"Number_of_casualties\")\n",
    "numerical_new = [\"Number_of_vehicles_involved\", \"Number_of_casualties\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Explanatory Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) Descriptive Statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) Data Visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) Correlation Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (d) Dimensionality Reduction by PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (e) Cluster Analysis by Hierarchical Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4. Data Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\26447\\AppData\\Local\\Temp\\ipykernel_20104\\2644754573.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eta_new[numerical_new] = standard.fit_transform(eta_new[numerical_new])\n"
     ]
    }
   ],
   "source": [
    "standard = StandardScaler()\n",
    "eta_new[numerical_new] = standard.fit_transform(eta_new[numerical_new])\n",
    "X = pd.get_dummies(eta_new, columns = categorical_new, drop_first = True)\n",
    "y = y_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size = 0.3, random_state = 233)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5. Model Selection\n",
    "#### (a) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n",
      "{'C': 100, 'degree': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "SVC(C=100, degree=1, gamma=1)\n",
      "Accuracy score:  0.9183325584999226\n",
      "Classification report:                  precision    recall  f1-score   support\n",
      "\n",
      "  Fatal injury       0.99      0.99      0.99      2169\n",
      "Serious Injury       0.98      0.78      0.87      2164\n",
      " Slight Injury       0.81      0.99      0.89      2120\n",
      "\n",
      "      accuracy                           0.92      6453\n",
      "     macro avg       0.93      0.92      0.92      6453\n",
      "  weighted avg       0.93      0.92      0.92      6453\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "param_svc = {\"C\": [0.1, 1, 10, 100], \"gamma\": [1, 0.1, 0.01, 0.001], \"kernel\": [\"rbf\", \"linear\", \"poly\", \"sigmoid\"], \"degree\": [1, 2, 3, 4]}\n",
    "svc = GridSearchCV(SVC(), param_svc, refit = True, verbose = 3, n_jobs = 12)\n",
    "svc.fit(X_train, y_train)\n",
    "print(svc.best_params_)\n",
    "print(svc.best_estimator_)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification report: \", classification_report(y_test, y_pred))\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat.T, square = True, annot = True, fmt = \"d\", cbar = False, xticklabels = [\"Fatal\", \"Serious\", \"Slight\"], yticklabels = [\"Fatal\", \"Serious\", \"Slight\"])\n",
    "plt.xlabel(\"True Label\")\n",
    "plt.ylabel(\"Predicted Label\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "param_gbc = {\"learning_rate\": [0.1, 0.01, 0.001], \"n_estimators\": [100, 200, 300], \"max_depth\": [1, 2, 3, 4, 5]}\n",
    "gbc = GridSearchCV(GradientBoostingClassifier(), param_gbc, refit = True, verbose = 3, n_jobs = 12)\n",
    "gbc.fit(X_train, y_train)\n",
    "print(gbc.best_params_)\n",
    "print(gbc.best_estimator_)\n",
    "y_pred = gbc.predict(X_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification report: \", classification_report(y_test, y_pred))\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat.T, square = True, annot = True, fmt = \"d\", cbar = False, xticklabels = [\"Fatal\", \"Serious\", \"Slight\"], yticklabels = [\"Fatal\", \"Serious\", \"Slight\"])\n",
    "plt.xlabel(\"True Label\")\n",
    "plt.ylabel(\"Predicted Label\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100, 100, 100, 100), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(100, 100, 100, 100, 100),\n",
      "              learning_rate='adaptive', solver='sgd')\n",
      "Accuracy score:  0.903300790330079\n",
      "Classification report:                  precision    recall  f1-score   support\n",
      "\n",
      "  Fatal injury       0.98      0.99      0.99      2169\n",
      "Serious Injury       0.90      0.82      0.86      2164\n",
      " Slight Injury       0.83      0.90      0.87      2120\n",
      "\n",
      "      accuracy                           0.90      6453\n",
      "     macro avg       0.90      0.90      0.90      6453\n",
      "  weighted avg       0.90      0.90      0.90      6453\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\26447\\anaconda3\\envs\\python\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "param_mlp = {\"hidden_layer_sizes\": [(100, 100, 100), (100, 100), (100, 100, 100, 100), (100, 100, 100, 100, 100)], \"activation\": [\"relu\", \"logistic\"], \"solver\": [\"adam\", \"sgd\"], \"alpha\": [0.0001, 0.05], \"learning_rate\": [\"constant\", \"adaptive\"]}\n",
    "mlp = GridSearchCV(MLPClassifier(), param_mlp, refit = True, verbose = 3, n_jobs = 12)\n",
    "mlp.fit(X_train, y_train)\n",
    "print(mlp.best_params_)\n",
    "print(mlp.best_estimator_)\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification report: \", classification_report(y_test, y_pred))\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat.T, square = True, annot = True, fmt = \"d\", cbar = False, xticklabels = [\"Fatal\", \"Serious\", \"Slight\"], yticklabels = [\"Fatal\", \"Serious\", \"Slight\"])\n",
    "plt.xlabel(\"True label\")\n",
    "plt.ylabel(\"Predicted label\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.918333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multi-layer Perceptron</td>\n",
       "      <td>0.903301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.883155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy\n",
       "0  Support Vector Machine  0.918333\n",
       "2  Multi-layer Perceptron  0.903301\n",
       "1           Random Forest  0.883155"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    \"Model\": [\"Support Vector Machine\", \"Gradient Boosting\", \"Multilayer Perceptron\"],\n",
    "    \"Accuracy\": [accuracy_score(y_test, svc.predict(X_test)), accuracy_score(y_test, gbc.predict(X_test)), accuracy_score(y_test, mlp.predict(X_test))]})\n",
    "models.sort_values(by = \"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.barplot(x = \"Model\", y = \"Accuracy\", data = models.sort_values(by = \"Accuracy\", ascending = False))\n",
    "for acc in ax.containers:\n",
    "    ax.bar_label(acc, label_type = \"center\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-mine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e3d6c2fd17c985616d208c207ad01a559fd73b1923d8aab6e801588cb03416b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
